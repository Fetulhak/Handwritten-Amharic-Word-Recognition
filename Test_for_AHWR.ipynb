{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "q30eA8raIbJp",
        "dbRW1lBdIQjF",
        "CH0hXTEf1U3n",
        "TlMJhfakPkEm",
        "IKx14fU3FBNw",
        "gI8mXeaxfxsU",
        "A9ZibmAkS6SU",
        "Km2GyDuBI1sv"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq860rXEZVNd"
      },
      "source": [
        "# Setup Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ox1PwByfQzfS"
      },
      "source": [
        "pip install keras_tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqzL1C7lUgKf"
      },
      "source": [
        "pip install watermark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEK_GCnJITTj"
      },
      "source": [
        "!pip install keras==2.3.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HMBR2CH-esG"
      },
      "source": [
        "!pip install tensorflow==2.1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf-hT1v9W1fa"
      },
      "source": [
        "from tensorflow.python.keras import regularizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwxCnx4VT62S"
      },
      "source": [
        "# code for loading the format for the notebook\n",
        "import os\n",
        "\n",
        "\n",
        "# 1. magic to print version\n",
        "# 2. magic so that the notebook will reload external python modules\n",
        "%load_ext watermark\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from tensorflow.python.keras import regularizers\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers.advanced_activations import PReLU\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import pandas as pd\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Dropout,Bidirectional, RNN,Reshape,Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D,MaxPooling2D, GlobalMaxPooling2D,Concatenate,GlobalAveragePooling2D,Lambda, GRU\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.applications import VGG19,VGG16, ResNet50, MobileNet, Xception\n",
        "from keras.optimizers import SGD, Adam, RMSprop, Adamax, Adadelta, Adagrad\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Lambda, GRU, BatchNormalization\n",
        "from keras.layers.convolutional import Convolution2D, Cropping2D, ZeroPadding2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.layers import LSTM, Reshape, Input, Conv2D, MaxPool2D, Bidirectional, RNN, Concatenate\n",
        "from keras.models import Model\n",
        "from keras.activations import relu, sigmoid, softmax\n",
        "import keras.backend as K\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras_tqdm import TQDMNotebookCallback\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "%watermark -a 'Ethen' -d -t -v -p numpy,pandas,keras,sklearn,tensorflow,cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXVIMJ4AZkWb"
      },
      "source": [
        "# Connect My Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Skgf2fAZ8oZo"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhtHh6RNZsyb",
        "outputId": "5f560d49-390c-4701-b55c-7c8932889cec"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ODyFyYVaxOH",
        "outputId": "b51eaf6f-98f5-4e5d-aa19-b64b1affe59e"
      },
      "source": [
        "cd /content/drive/Shared drives/PolypDB/AWR_Test 7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/Shared drives/PolypDB/AWR_Test 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SL8cpRpka0Cd"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFBHLDXcaBDa"
      },
      "source": [
        "#with open('parser/words.txt') as f:\n",
        "with open('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/words.txt') as f:\n",
        "    contents = f.readlines()\n",
        "\n",
        "lines = [line.strip() for line in contents]\n",
        "lines[7]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj1DVPlIXWlt"
      },
      "source": [
        "# tf-GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPptsb4yRI_J"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#ignore warnings in the output\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqRVqsAIXmcv"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "# Check all available devices if GPU is available\n",
        "print(device_lib.list_local_devices())\n",
        "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "GIZM03yWXm2v",
        "outputId": "a0f84a63-cccc-42b2-cfc6-3a2045447d7e"
      },
      "source": [
        "tf.compat.v1.config.experimental.list_physical_devices('GPU')\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "print(\"Num GPUs:\", len(physical_devices))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUs: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uTvwa83bSrl"
      },
      "source": [
        "# Initializing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPAtd2LJameC"
      },
      "source": [
        "max_label_len = 11\n",
        "RECORDS_COUNT = 8486\n",
        "char_list = \"ሀሁሂሃሄህሆለሉሊላሌልሎሏሐሑሒሓሔሕሖመሙሚማሜምሞሟሠሡሢሣሤሥሦሧረሩሪራሬርሮሯሰሱሲሳሴስሶሷሸሹሺሻሼሽሾሿቀቁቂቃቄቅቆቋበቡቢባቤብቦቧቨቩቪቫቬቭቮቯተቱቲታቴትቶቷቸቹቺቻቼችቾቿኀኁኂኃኄኅኋነኑኒናኔንኖኗኘኙኚኛኜኝኞኟአኡኢኣኤእኦኧከኩኪካኬክኮኳኸኹኺኻኼኽኾዀዂወዉዊዋዌውዎዏዐዑዒዓዔዕዖዘዙዚዛዜዝዞዟዠዡዢዣዤዥዦዧየዩዪያዬይዮደዱዲዳዴድዶዷጀጁጂጃጄጅጆጇገጉጊጋጌግጎጐጓጠጡጢጣጤጥጦጧጨጩጪጫጬጭጮጯጰጱጲጳጴጵጶጷጸጹጺጻጼጽጾጿፀፁፂፃፄፅፆፈፉፊፋፌፍፎፏፐፑፒፓፔፕፖፗ!፦‹(«፥%»)›.+፣-።/0123456789፡፤…*#?\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Z-PSOvQ2ckC"
      },
      "source": [
        "#images = []\n",
        "#labels = []\n",
        "\n",
        "RECORDS_COUNT = 8486\n",
        "X_train = []\n",
        "train_labels = []\n",
        "train_input_length = []\n",
        "train_label_length = []\n",
        "train_original_text = []\n",
        "\n",
        "X_val = []\n",
        "valid_labels = []\n",
        "valid_input_length = []\n",
        "valid_label_length = []\n",
        "valid_original_text = []\n",
        "\n",
        "X_test = []\n",
        "test_labels = []\n",
        "test_input_length = []\n",
        "test_label_length = []\n",
        "test_original_text = []\n",
        "\n",
        "inputs_length = []\n",
        "labels_length = []\n",
        "max_label_len = 11"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5TOpn1q3C0m"
      },
      "source": [
        "for index, line in enumerate(lines):\n",
        "    splits = line.split(' ')\n",
        "    status = splits[1]\n",
        "\n",
        "    if status == 'ok':\n",
        "        word_id = splits[0]\n",
        "        word = \"\".join(splits[8:])\n",
        "\n",
        "        splits_id = word_id.split('-')\n",
        "\n",
        "\n",
        "        if index % 5 == 0:\n",
        "          valid_original_text.append(word)\n",
        "\n",
        "        if index % 6 == 0:\n",
        "          test_original_text.append(word)\n",
        "\n",
        "        else:\n",
        "            train_original_text.append(word)\n",
        "\n",
        "\n",
        "        if len(word) > max_label_len:\n",
        "            max_label_len = len(word)\n",
        "\n",
        "    if index >= RECORDS_COUNT:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "sauvax_BbwMk",
        "outputId": "7001712d-e841-4f2d-b37b-ecb5f436d0b2"
      },
      "source": [
        "print(max_label_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6lPopkmdgG5"
      },
      "source": [
        "# Generate train & validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmjsHKkeHv9q"
      },
      "source": [
        "#This notebook cell is used to load the numpy data for original data of 32 x 128 size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAkKQdRCE8Ri",
        "outputId": "7b9a657e-53d3-4385-ce55-d7ee0e69e851"
      },
      "source": [
        "# the training, validation and test set\n",
        "# X_train = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npy/X_train.npy')\n",
        "# train_input_length = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npy/train_input_length.npy')\n",
        "# train_label_length = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npy/train_label_length.npy')\n",
        "# X_val = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npy/X_val.npy')\n",
        "# valid_input_length = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npy/valid_input_length.npy')\n",
        "# valid_label_length = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npy/valid_label_length.npy')\n",
        "X_test = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npy/X_test.npy')\n",
        "test_input_length = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npy/test_input_length.npy')\n",
        "test_label_length = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npy/test_label_length.npy')\n",
        "\n",
        "# y_train = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npy/y_train.npy')\n",
        "# y_val = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npy/y_val.npy')\n",
        "y_test = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npy/y_test.npy')\n",
        "\n",
        "# print(train_label_length[0])\n",
        "# print('number of training images: ', X_train.shape[0])\n",
        "# print('number of validation images: ', X_val.shape[0])\n",
        "print('number of testing images: ', X_test.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of testing images:  1200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6yunEXeFUNJ",
        "outputId": "dcfb9177-8e4f-438c-dbb1-8b93ac9a2644"
      },
      "source": [
        "X_test.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1200, 64, 256, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWeUUUoCoCmY",
        "outputId": "17db77e3-c016-4b93-9324-30ec3f3e95c4"
      },
      "source": [
        "print(y_test[0])\n",
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[153 112 300 300 300 300 300 300 300 300 300]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1200, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFWkKXR8BtMu"
      },
      "source": [
        "#augmented data for size 32x128"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ehgc-e5leie3",
        "outputId": "822d72d1-bcd6-4449-e3ce-70ea821271b1"
      },
      "source": [
        "# the training, validation and test set\n",
        "X_train = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npys/X_train.npy')\n",
        "train_input_length = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npys/train_input_length.npy')\n",
        "train_label_length = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npys/train_label_length.npy')\n",
        "X_val = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npys/X_val.npy')\n",
        "valid_input_length = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npys/valid_input_length.npy')\n",
        "valid_label_length = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npys/valid_label_length.npy')\n",
        "# X_test = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npy/X_test.npy')\n",
        "# test_input_length = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npy/test_input_length.npy')\n",
        "# test_label_length = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npy/test_label_length.npy')\n",
        "\n",
        "y_train = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npys/y_train.npy')\n",
        "y_val = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npys/y_val.npy')\n",
        "# y_test = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npy/y_test.npy')\n",
        "\n",
        "print(train_label_length[0])\n",
        "print('number of training images: ', X_train.shape[0])\n",
        "print('number of validation images: ', X_val.shape[0])\n",
        "# print('number of testing images: ', X_test.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n",
            "number of training images:  29224\n",
            "number of validation images:  3248\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeRmg2ynBzIi"
      },
      "source": [
        "#augmented data for size 64x256"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StGv2WOvBsC5",
        "outputId": "47e7d511-3530-48f9-d2a6-eba2f8126880"
      },
      "source": [
        "# the training, validation and test set\n",
        "X_train = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npys2/X_train.npy')\n",
        "train_input_length = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npys2/train_input_length.npy')\n",
        "train_label_length = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npys2/train_label_length.npy')\n",
        "X_val = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npys2/X_val.npy')\n",
        "valid_input_length = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npys2/valid_input_length.npy')\n",
        "valid_label_length = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npys2/valid_label_length.npy')\n",
        "\n",
        "\n",
        "y_train = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npys2/y_train.npy')\n",
        "y_val = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npys2/y_val.npy')\n",
        "\n",
        "\n",
        "print(train_label_length[0])\n",
        "print('number of training images: ', X_train.shape[0])\n",
        "print('number of validation images: ', X_val.shape[0])\n",
        "# print('number of testing images: ', X_test.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n",
            "number of training images:  29224\n",
            "number of validation images:  3248\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ApgHfVJTrA3"
      },
      "source": [
        "print(len(train_input_length))\n",
        "print(train_input_length[9])\n",
        "print(len(X_train))\n",
        "print(len(y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24MfB6kzixbe",
        "outputId": "2240c88f-9a99-4abd-8203-9603cf7d0078"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29224, 64, 256, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap9tLXxQQStm"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5X-pzfVRHtW"
      },
      "source": [
        "for x in range (0,len(y_train)):\n",
        "  #print(x)\n",
        "  train_input_length[x]= 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDteyh3bUIGe"
      },
      "source": [
        "for x in range (0,len(y_val)):\n",
        "  valid_input_length[x]= 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E5HGZ4dUJS_"
      },
      "source": [
        "for x in range (0,len(y_test)):\n",
        "  test_input_length[x]= 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyhIj1lZ6Hs6",
        "outputId": "2fbe3d19-97ad-46fe-b8fe-35febe8f8dc7"
      },
      "source": [
        "print(y_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[181  22  66 194 114 184 300 300 300 300 300]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxwydtw3TkpP",
        "outputId": "a62cf73c-0d43-47d2-cdc5-a324f0af854a"
      },
      "source": [
        "train_original_text=[]\n",
        "\n",
        "for label in y_train:\n",
        "    str1= \"\"\n",
        "    for i in label:\n",
        "        if i != 300:\n",
        "            str1+=char_list[i]\n",
        "    #print(str)\n",
        "    train_original_text.append(str1)\n",
        "print(train_original_text[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "የመቄዶንያ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIsgTd4l6bgU",
        "outputId": "08704769-f874-4237-962e-d56d81707bec"
      },
      "source": [
        "\n",
        "print(len(train_original_text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9622\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-DvVpD_4wWt",
        "outputId": "85dcccc5-3b11-484d-ce1d-1bb23fca17e8"
      },
      "source": [
        "valid_original_text=[]\n",
        "\n",
        "for label in y_val:\n",
        "    str1= \"\"\n",
        "    for i in label:\n",
        "        if i != 300:\n",
        "            str1+=char_list[i]\n",
        "    #print(str)\n",
        "    valid_original_text.append(str1)\n",
        "print(valid_original_text[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "አሪስቶትል\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6fCDXfC6YX0",
        "outputId": "3cb77f1f-a14f-4196-b03b-43f5cbe04d9a"
      },
      "source": [
        "print(valid_original_text[5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "እንዲረግጥ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1osWKeFv42Um",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ee6bedd-463b-43c9-b16b-2bf6503aee02"
      },
      "source": [
        "test_original_text = []\n",
        "\n",
        "for label in y_test:\n",
        "    str1= \"\"\n",
        "    for i in label:\n",
        "        if i != 300:\n",
        "            str1+=char_list[i]\n",
        "    #print(str)\n",
        "    test_original_text.append(str1)\n",
        "print(test_original_text[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ዋና\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcUEUuip6-Jq"
      },
      "source": [
        "INPUT_SHAPE = (64, 256, 1)\n",
        "POOL_SIZE = (2, 2)\n",
        "KERNEL_SIZE = (3, 3)\n",
        "\n",
        "KERNEL_SIZE1 = (5, 5)\n",
        "KERNEL_SIZE_BN = (2, 2)\n",
        "REG = 0.01\n",
        "\n",
        "base_model = ResNet50(include_top=False, weights=None, input_tensor=None, input_shape=INPUT_SHAPE)\n",
        "\n",
        "x = base_model.layers[38].output\n",
        "model = Model(base_model.inputs, x)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biov5jcapxYA"
      },
      "source": [
        "INPUT_SHAPE = (32, 128, 1)\n",
        "POOL_SIZE = (2, 2)\n",
        "KERNEL_SIZE = (3, 3)\n",
        "\n",
        "KERNEL_SIZE1 = (5, 5)\n",
        "KERNEL_SIZE_BN = (2, 2)\n",
        "REG = 0.01\n",
        "\n",
        "base_model = ResNet50(include_top=False, weights=None, input_tensor=None, input_shape=INPUT_SHAPE)\n",
        "base_model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AGh9icveWuh"
      },
      "source": [
        "# Build Models\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q30eA8raIbJp"
      },
      "source": [
        "#This cell holds an old version of custom model with 7 convolution layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bim-kFyHylCC"
      },
      "source": [
        "INPUT_SHAPE = (32, 128, 1)\n",
        "POOL_SIZE = (2, 2)\n",
        "KERNEL_SIZE = (3, 3)\n",
        "KERNEL_SIZE1 = (5, 5)\n",
        "KERNEL_SIZE_BN = (2, 2)\n",
        "REG = 0.01\n",
        "\n",
        "def create_model():\n",
        "  # Initialise a model\n",
        "  model = Sequential()\n",
        "\n",
        "  # First conv layer - input layer\n",
        "  model.add(Convolution2D(filters=64, kernel_size = KERNEL_SIZE, input_shape=INPUT_SHAPE,\n",
        "                 use_bias=True,\n",
        "                 #strides=1,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv1'))\n",
        "  model.add(Activation('relu', name='activation1'))\n",
        "  #model.add(Dropout(0.25))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), name='pool1'))\n",
        "\n",
        "  model.add(Convolution2D(filters=128, kernel_size = KERNEL_SIZE,\n",
        "                 #strides=1,\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv2'))\n",
        "  model.add(Activation('relu', name='activation2'))\n",
        "  #model.add(Dropout(0.25))\n",
        "  model.add(MaxPooling2D(pool_size=POOL_SIZE, strides=(2,2), name='pool2'))\n",
        "\n",
        "  model.add(Convolution2D(filters=256, kernel_size = KERNEL_SIZE,\n",
        "                 #strides=1,\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv3'))\n",
        "  model.add(Activation('relu', name='activation3'))\n",
        "  #model.add(Dropout(0.25))\n",
        "  #model.add(MaxPooling2D(pool_size=(2, 2), name='pool3'))\n",
        "\n",
        "  model.add(Convolution2D(filters=256, kernel_size = KERNEL_SIZE,\n",
        "                 #strides=1,\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv4'))\n",
        "  model.add(Activation('relu', name='activation4'))\n",
        "  #model.add(Dropout(0.2))\n",
        "  # pooling layer with kernel size (2,1)\n",
        "  model.add(MaxPooling2D(pool_size=(2, 1), name='pool4'))\n",
        "\n",
        "  model.add(Convolution2D(filters=512, kernel_size = KERNEL_SIZE,\n",
        "                 #strides=1,\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv5'))\n",
        "  model.add(Activation('relu', name='activation5'))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "  model.add(Convolution2D(filters=512, kernel_size = KERNEL_SIZE,\n",
        "                 #strides=1,\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv6'))\n",
        "  model.add(Activation('relu', name='activation6'))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(BatchNormalization())\n",
        "  # pooling layer with kernel size (2,1)\n",
        "  model.add(MaxPooling2D(pool_size=(2, 1), name='pool5'))\n",
        "\n",
        "\n",
        "  model.add(  Reshape((32, 1024), name=\"reshape\") )\n",
        "  model.summary()\n",
        "  #model.add(Convolution2D(filters=512, kernel_size = KERNEL_SIZE_BN, kernel_regularizer=regularizers.l2(REG), name='conv7'))\n",
        "  #model.add(Activation('relu', name='activation7'))\n",
        "  #model.add(Dense(64, activation='relu', name='dense1'))\n",
        "\n",
        "  #model.add(Lambda(lambda x: K.squeeze(x, 1)))\n",
        "  #model.add(Dropout(0.2))\n",
        "\n",
        "  # bidirectional LSTM layers with units=128\n",
        "  #model.add(Bidirectional(LSTM(256, return_sequences=True,\n",
        "  #                             kernel_regularizer=regularizers.l2(REG), name='blstm1')))\n",
        "  #model.add(Dropout(0.2))\n",
        "  model.add(Bidirectional(GRU(512, return_sequences=True,\n",
        "                kernel_regularizer=regularizers.l2(REG), name='gru1')))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  #model.add(Bidirectional(LSTM(256, return_sequences=True,\n",
        "  #                             kernel_regularizer=regularizers.l2(REG), name='blstm2')))\n",
        "  #model.add(Dropout(0.2))\n",
        "  model.add(Bidirectional(GRU(256, return_sequences=True,\n",
        "                kernel_regularizer=regularizers.l2(REG), name='gru2')))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  # transforms RNN output to character activations\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  model.add(Dense(len(char_list)+1,\n",
        "                  kernel_regularizer=regularizers.l2(REG), name='outputs'))\n",
        "  model.add(Activation('softmax', name='softmax'))\n",
        "\n",
        "  return model\n",
        "\n",
        "my_model = create_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbRW1lBdIQjF"
      },
      "source": [
        "#This code cell holds Eyob's best performing custom model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqXjaQSjIODh",
        "outputId": "e355764e-6e0d-4704-df94-1e22235f9b21"
      },
      "source": [
        "INPUT_SHAPE = (64, 256, 1)\n",
        "POOL_SIZE = (2, 2)\n",
        "KERNEL_SIZE = (3, 3)\n",
        "KERNEL_SIZE_BN = (2, 2)\n",
        "REG = 0.00001\n",
        "\n",
        "def create_model():\n",
        "  # Initialise a model\n",
        "  model = Sequential()\n",
        "\n",
        "  # First conv layer - input layer\n",
        "  model.add(Convolution2D(filters=64, kernel_size = KERNEL_SIZE, input_shape=INPUT_SHAPE,\n",
        "                 use_bias=True,\n",
        "                 strides=(1, 1),\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv1'))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(BatchNormalization(name='bn1'))\n",
        "\n",
        "  model.add(Convolution2D(filters=64, kernel_size = KERNEL_SIZE,\n",
        "                 strides=(1, 1),\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv2'))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), name='pool1'))\n",
        "\n",
        "  model.add(Convolution2D(filters=128, kernel_size = KERNEL_SIZE,\n",
        "                 strides=(1, 1),\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv3'))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(BatchNormalization(name='bn2'))\n",
        "\n",
        "  model.add(Convolution2D(filters=128, kernel_size = KERNEL_SIZE,\n",
        "                 strides=(1, 1),\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv4'))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), name='pool2'))\n",
        "\n",
        "  model.add(Convolution2D(filters=256, kernel_size = KERNEL_SIZE,\n",
        "                 strides=(1, 1),\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv5'))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(BatchNormalization(name='bn3'))\n",
        "\n",
        "  model.add(Convolution2D(filters=256, kernel_size = KERNEL_SIZE,\n",
        "                 strides=(1, 1),\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv6'))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), name='pool3'))\n",
        "\n",
        "  model.add(Convolution2D(filters=256, kernel_size = KERNEL_SIZE,\n",
        "                 strides=(1, 1),\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv7'))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(BatchNormalization(name='bn4'))\n",
        "\n",
        "  model.add(Convolution2D(filters=256, kernel_size = KERNEL_SIZE,\n",
        "                 strides=(1, 1),\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv8'))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 1), name='pool4'))\n",
        "\n",
        "  model.add(Convolution2D(filters=512, kernel_size = KERNEL_SIZE,\n",
        "                 strides=(1, 1),\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv9'))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(BatchNormalization(name='bn5'))\n",
        "\n",
        "  model.add(Convolution2D(filters=512, kernel_size = KERNEL_SIZE,\n",
        "                 strides=(1, 1),\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv10'))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(BatchNormalization(name='bn6'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 1), name='pool5'))\n",
        "\n",
        "  model.add(Convolution2D(filters=512, kernel_size = KERNEL_SIZE,\n",
        "                 strides=(1, 1),\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv11'))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(BatchNormalization(name='bn7'))\n",
        "\n",
        "  model.add(Convolution2D(filters=512, kernel_size = KERNEL_SIZE_BN,  padding='same',\n",
        "                          kernel_regularizer=regularizers.l2(REG), name='conv12'))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  #model.add(Dense(64, activation='relu', name='dense1'))\n",
        "  model.summary()\n",
        "\n",
        "  #model.add(Lambda(lambda x: K.squeeze(x, 1)))\n",
        "  model.add(  Reshape((32, 1024), name=\"reshape\") )\n",
        "\n",
        "  # bidirectional LSTM layers with units=128\n",
        "  #model.add(Bidirectional(LSTM(256, return_sequences=True,\n",
        "  #                             kernel_regularizer=regularizers.l2(REG), name='blstm1')))\n",
        "  #model.add(Dropout(0.2))\n",
        "  #with tf.device('/gpu:0'):\n",
        "  model.add(Bidirectional(GRU(512, return_sequences=True,\n",
        "                kernel_regularizer=regularizers.l2(REG), reset_after=True, name='gru1')))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  #model.add(Bidirectional(LSTM(256, return_sequences=True,\n",
        "  #                             kernel_regularizer=regularizers.l2(REG), name='blstm2')))\n",
        "  #model.add(Dropout(0.2))\n",
        "  #with tf.device('/gpu:1'):\n",
        "  model.add(Bidirectional(GRU(512, return_sequences=True,\n",
        "                kernel_regularizer=regularizers.l2(REG), reset_after=True, name='gru2')))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  # transforms RNN output to character activations\n",
        "  model.add(Dense(len(char_list)+1,\n",
        "                  kernel_regularizer=regularizers.l2(REG), name='outputs'))\n",
        "  model.add(Activation('softmax', name='softmax'))\n",
        "\n",
        "  return model\n",
        "\n",
        "my_model = create_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1 (Conv2D)               (None, 64, 256, 64)       640       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 64, 256, 64)       0         \n",
            "_________________________________________________________________\n",
            "bn1 (BatchNormalization)     (None, 64, 256, 64)       256       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 64, 256, 64)       36928     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 64, 256, 64)       0         \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 32, 128, 64)       0         \n",
            "_________________________________________________________________\n",
            "conv3 (Conv2D)               (None, 32, 128, 128)      73856     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 32, 128, 128)      0         \n",
            "_________________________________________________________________\n",
            "bn2 (BatchNormalization)     (None, 32, 128, 128)      512       \n",
            "_________________________________________________________________\n",
            "conv4 (Conv2D)               (None, 32, 128, 128)      147584    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 32, 128, 128)      0         \n",
            "_________________________________________________________________\n",
            "pool2 (MaxPooling2D)         (None, 16, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv5 (Conv2D)               (None, 16, 64, 256)       295168    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 16, 64, 256)       0         \n",
            "_________________________________________________________________\n",
            "bn3 (BatchNormalization)     (None, 16, 64, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv6 (Conv2D)               (None, 16, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 16, 64, 256)       0         \n",
            "_________________________________________________________________\n",
            "pool3 (MaxPooling2D)         (None, 8, 32, 256)        0         \n",
            "_________________________________________________________________\n",
            "conv7 (Conv2D)               (None, 8, 32, 256)        590080    \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 8, 32, 256)        0         \n",
            "_________________________________________________________________\n",
            "bn4 (BatchNormalization)     (None, 8, 32, 256)        1024      \n",
            "_________________________________________________________________\n",
            "conv8 (Conv2D)               (None, 8, 32, 256)        590080    \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 8, 32, 256)        0         \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 4, 32, 256)        0         \n",
            "_________________________________________________________________\n",
            "conv9 (Conv2D)               (None, 4, 32, 512)        1180160   \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 4, 32, 512)        0         \n",
            "_________________________________________________________________\n",
            "bn5 (BatchNormalization)     (None, 4, 32, 512)        2048      \n",
            "_________________________________________________________________\n",
            "conv10 (Conv2D)              (None, 4, 32, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 4, 32, 512)        0         \n",
            "_________________________________________________________________\n",
            "bn6 (BatchNormalization)     (None, 4, 32, 512)        2048      \n",
            "_________________________________________________________________\n",
            "pool5 (MaxPooling2D)         (None, 2, 32, 512)        0         \n",
            "_________________________________________________________________\n",
            "conv11 (Conv2D)              (None, 2, 32, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 2, 32, 512)        0         \n",
            "_________________________________________________________________\n",
            "bn7 (BatchNormalization)     (None, 2, 32, 512)        2048      \n",
            "_________________________________________________________________\n",
            "conv12 (Conv2D)              (None, 2, 32, 512)        1049088   \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 2, 32, 512)        0         \n",
            "=================================================================\n",
            "Total params: 9,282,240\n",
            "Trainable params: 9,277,760\n",
            "Non-trainable params: 4,480\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yOl8niXpIYc",
        "outputId": "d6423732-06f4-4161-8999-02ee71372151"
      },
      "source": [
        "my_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1 (Conv2D)               (None, 64, 256, 64)       640       \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 64, 256, 64)       0         \n",
            "_________________________________________________________________\n",
            "bn1 (BatchNormalization)     (None, 64, 256, 64)       256       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 64, 256, 64)       36928     \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 64, 256, 64)       0         \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 32, 128, 64)       0         \n",
            "_________________________________________________________________\n",
            "conv3 (Conv2D)               (None, 32, 128, 128)      73856     \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 32, 128, 128)      0         \n",
            "_________________________________________________________________\n",
            "bn2 (BatchNormalization)     (None, 32, 128, 128)      512       \n",
            "_________________________________________________________________\n",
            "conv4 (Conv2D)               (None, 32, 128, 128)      147584    \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 32, 128, 128)      0         \n",
            "_________________________________________________________________\n",
            "pool2 (MaxPooling2D)         (None, 16, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv5 (Conv2D)               (None, 16, 64, 256)       295168    \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 16, 64, 256)       0         \n",
            "_________________________________________________________________\n",
            "bn3 (BatchNormalization)     (None, 16, 64, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv6 (Conv2D)               (None, 16, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 16, 64, 256)       0         \n",
            "_________________________________________________________________\n",
            "pool3 (MaxPooling2D)         (None, 8, 32, 256)        0         \n",
            "_________________________________________________________________\n",
            "conv7 (Conv2D)               (None, 8, 32, 256)        590080    \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 8, 32, 256)        0         \n",
            "_________________________________________________________________\n",
            "bn4 (BatchNormalization)     (None, 8, 32, 256)        1024      \n",
            "_________________________________________________________________\n",
            "conv8 (Conv2D)               (None, 8, 32, 256)        590080    \n",
            "_________________________________________________________________\n",
            "activation_20 (Activation)   (None, 8, 32, 256)        0         \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 4, 32, 256)        0         \n",
            "_________________________________________________________________\n",
            "conv9 (Conv2D)               (None, 4, 32, 512)        1180160   \n",
            "_________________________________________________________________\n",
            "activation_21 (Activation)   (None, 4, 32, 512)        0         \n",
            "_________________________________________________________________\n",
            "bn5 (BatchNormalization)     (None, 4, 32, 512)        2048      \n",
            "_________________________________________________________________\n",
            "conv10 (Conv2D)              (None, 4, 32, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "activation_22 (Activation)   (None, 4, 32, 512)        0         \n",
            "_________________________________________________________________\n",
            "bn6 (BatchNormalization)     (None, 4, 32, 512)        2048      \n",
            "_________________________________________________________________\n",
            "pool5 (MaxPooling2D)         (None, 2, 32, 512)        0         \n",
            "_________________________________________________________________\n",
            "conv11 (Conv2D)              (None, 2, 32, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "activation_23 (Activation)   (None, 2, 32, 512)        0         \n",
            "_________________________________________________________________\n",
            "bn7 (BatchNormalization)     (None, 2, 32, 512)        2048      \n",
            "_________________________________________________________________\n",
            "conv12 (Conv2D)              (None, 2, 32, 512)        1049088   \n",
            "_________________________________________________________________\n",
            "activation_24 (Activation)   (None, 2, 32, 512)        0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 32, 1024)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 32, 1024)          4724736   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 32, 1024)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 32, 1024)          4724736   \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32, 1024)          0         \n",
            "_________________________________________________________________\n",
            "outputs (Dense)              (None, 32, 301)           308525    \n",
            "_________________________________________________________________\n",
            "softmax (Activation)         (None, 32, 301)           0         \n",
            "=================================================================\n",
            "Total params: 19,040,237\n",
            "Trainable params: 19,035,757\n",
            "Non-trainable params: 4,480\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUAXzClnb_fi"
      },
      "source": [
        "###ResNet Model with some layers added"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEsSxUv_b89U"
      },
      "source": [
        "INPUT_SHAPE = (32, 128, 1) # (img_rows, img_cols, img_channel)\n",
        "POOL_SIZE = (2, 2)\n",
        "POOL_SIZE2 = (2, 1)\n",
        "POOL_SIZE3 = (1, 2)\n",
        "KERNEL_SIZE = (3, 3)\n",
        "KERNEL_SIZE_F = (2, 2)\n",
        "REG = 0.0001\n",
        "from keras.layers import LSTM, Reshape, Input, Conv2D, MaxPool2D, Bidirectional\n",
        "\n",
        "def make_model():\n",
        "  base_model = ResNet50(include_top=False, weights=None, input_tensor=None, input_shape=INPUT_SHAPE)\n",
        "\n",
        "  x = MaxPooling2D((2, 1),\n",
        "                  #strides=(2, 2),\n",
        "                  name='block3_pool')(base_model.layers[38].output)\n",
        "\n",
        "\n",
        "  # Block 4\n",
        "  x = Conv2D(\n",
        "      512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
        "  x = Dropout(0.25)(x)\n",
        "  x = BatchNormalization(name='block4_BN')(x)\n",
        "  x = Conv2D(\n",
        "      512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
        "  x = Dropout(0.25)(x)\n",
        "  x = BatchNormalization(name='block5_BN')(x)\n",
        "  x = Conv2D(\n",
        "      512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
        "  #x = MaxPooling2D((2, 1),\n",
        "  #                 #strides=(2, 2),\n",
        "  #                 name='block4_pool')(x)\n",
        "  x = Dropout(0.25)(x)\n",
        "\n",
        "  x = BatchNormalization(name='block6_BN')(x)\n",
        "\n",
        "  # Block 5\n",
        "  x = Conv2D(\n",
        "      512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
        "  x = Dropout(0.25)(x)\n",
        "\n",
        "  x = BatchNormalization(name='block7_BN')(x)\n",
        "  x = Conv2D(\n",
        "      512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
        "  x = Conv2D(\n",
        "      512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
        "  x = BatchNormalization(name='block8_BN')(x)\n",
        "  x = MaxPooling2D((2, 1),\n",
        "                   #strides=(2, 2),\n",
        "                   name='block5_pool')(x)\n",
        "\n",
        "  # Block 6\n",
        "  conv_7 = Conv2D(512, (1, 1), activation = 'relu', name='block6_conv')(x)\n",
        "  #x = BatchNormalization(name='block6_BN')(x)\n",
        "\n",
        "  reshaped=  Reshape((32, 1024), name=\"reshape\") (conv_7)\n",
        "  #model.summary()\n",
        "    #squeezed = Lambda(lambda x: K.squeeze(x, 1), name='squeeze')(conv_7)\n",
        "\n",
        "  # bidirectional LSTM layers with units=128\n",
        "  #blstm_1 = Bidirectional(LSTM(512, return_sequences=True, dropout = 0.2,\n",
        "  #                kernel_regularizer=regularizers.l2(REG)))(squeezed)\n",
        "  gru_1 =  Bidirectional(GRU(512, return_sequences=True, dropout = 0.4,\n",
        "                  kernel_regularizer=regularizers.l2(REG)),\n",
        "                  name='bi_gru1')(reshaped)\n",
        "  x = Dropout(0.5)(gru_1)\n",
        "  #blstm_2 = Bidirectional(LSTM(512, return_sequences=True, dropout = 0.2,\n",
        "  #                kernel_regularizer=regularizers.l2(REG)))(blstm_1)\n",
        "  gru_2 =  Bidirectional(GRU(256, return_sequences=True, dropout = 0.2,\n",
        "                  kernel_regularizer=regularizers.l2(REG)),\n",
        "                  name='bi_gru2')(x)\n",
        "\n",
        "  x = Dropout(0.5)(gru_2)\n",
        "\n",
        "  outputs = Dense(len(char_list)+1, activation = 'softmax',\n",
        "                  kernel_regularizer=regularizers.l2(REG),\n",
        "                  name='dense1')(x)\n",
        "  #x = Dropout(0.25)(gru_2)\n",
        "  # model to be used at test time\n",
        "  model = Model(base_model.inputs, outputs)\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "\n",
        "my_model = make_model()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-60Eq0SDLlw"
      },
      "source": [
        "INPUT_SHAPE = (32, 128, 1)\n",
        "POOL_SIZE = (2, 2)\n",
        "KERNEL_SIZE = (3, 3)\n",
        "KERNEL_SIZE1 = (5, 5)\n",
        "KERNEL_SIZE_BN = (2, 2)\n",
        "REG = 0.01\n",
        "def create_model():\n",
        "  # Initialise a model\n",
        "  model = Sequential()\n",
        "  model.add(Convolution2D(filters=64, kernel_size = KERNEL_SIZE, input_shape=INPUT_SHAPE,\n",
        "                 use_bias=True,\n",
        "                 #strides=1,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv1'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 1), name='pool1'))\n",
        "\n",
        "  model.add(Convolution2D(filters=512, kernel_size = KERNEL_SIZE,\n",
        "                 #strides=1,\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv1'))\n",
        "  model.add(Activation('relu', name='activation1'))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "\n",
        "  model.add(Convolution2D(filters=512, kernel_size = KERNEL_SIZE,\n",
        "                 #strides=1,\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv2'))\n",
        "\n",
        "  model.add(Activation('relu', name='activation2'))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Convolution2D(filters=512, kernel_size = KERNEL_SIZE,\n",
        "                 #strides=1,\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv3'))\n",
        "\n",
        "  model.add(Activation('relu', name='activation3'))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Convolution2D(filters=512, kernel_size = KERNEL_SIZE,\n",
        "                 #strides=1,\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv4'))\n",
        "\n",
        "  model.add(Activation('relu', name='activation4'))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Convolution2D(filters=512, kernel_size = KERNEL_SIZE,\n",
        "                 #strides=1,\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv5'))\n",
        "  model.add(Activation('relu', name='activation5'))\n",
        "  model.add(Convolution2D(filters=512, kernel_size = KERNEL_SIZE,\n",
        "                 #strides=1,\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv6'))\n",
        "\n",
        "  model.add(Activation('relu', name='activation6'))\n",
        "  #model.add(Dropout(0.25))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 1), name='pool2'))\n",
        "\n",
        "  model.add(Convolution2D(filters=512, kernel_size = (1, 1),\n",
        "                 #strides=1,\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv7'))\n",
        "\n",
        "  model.add(Activation('relu', name='activation7'))\n",
        "  model.summary()\n",
        "\n",
        "  model.add(  Reshape((32, 1024), name=\"reshape\") )\n",
        "  #reshaped=  Reshape((32, 1024), name=\"reshape\") (conv_7)\n",
        "  #model.summary()\n",
        "    #squeezed = Lambda(lambda x: K.squeeze(x, 1), name='squeeze')(conv_7)\n",
        "\n",
        "  model.add(Bidirectional(GRU(512, return_sequences=True,\n",
        "                kernel_regularizer=regularizers.l2(REG), name='gru1')))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "\n",
        "  model.add(Bidirectional(GRU(512, return_sequences=True,\n",
        "                kernel_regularizer=regularizers.l2(REG), name='gru2')))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Dense(len(char_list)+1,\n",
        "                  kernel_regularizer=regularizers.l2(REG), name='outputs'))\n",
        "  model.add(Activation('softmax', name='softmax'))\n",
        "\n",
        "\n",
        "  #x = Dropout(0.25)(gru_2)\n",
        "  # model to be used at test time\n",
        "\n",
        " # model.summary()\n",
        "  return model\n",
        "\n",
        "\n",
        "my_model = make_model()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH0hXTEf1U3n"
      },
      "source": [
        "# This is the model which I have been trying to make the input length 16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtL6H_yEbtjj"
      },
      "source": [
        "INPUT_SHAPE = (32, 128, 1) # (img_rows, img_cols, img_channel)\n",
        "POOL_SIZE = (2, 2)\n",
        "POOL_SIZE2 = (2, 1)\n",
        "POOL_SIZE3 = (1, 2)\n",
        "KERNEL_SIZE = (3, 3)\n",
        "KERNEL_SIZE_F = (2, 2)\n",
        "REG = 0.0001\n",
        "from keras.layers import LSTM, Reshape, Input, Conv2D, MaxPool2D, Bidirectional\n",
        "\n",
        "def make_model():\n",
        "  base_model = ResNet50(include_top=False, weights=None, input_tensor=None, input_shape=INPUT_SHAPE)\n",
        "\n",
        "  x = base_model.layers[60].output\n",
        "\n",
        "\n",
        "  X = convolutional_block(x, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = (2,1))\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "\n",
        "      # Stage 5 (≈3 lines)\n",
        "  X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = (2,1))\n",
        "  X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "  X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "  reshaped=  Reshape((16, 2048), name=\"reshape\") (X)\n",
        "  #model.summary()\n",
        "    #squeezed = Lambda(lambda x: K.squeeze(x, 1), name='squeeze')(conv_7)\n",
        "\n",
        "  # bidirectional LSTM layers with units=128\n",
        "  #blstm_1 = Bidirectional(LSTM(512, return_sequences=True, dropout = 0.2,\n",
        "  #                kernel_regularizer=regularizers.l2(REG)))(squeezed)\n",
        "  gru_1 =  Bidirectional(GRU(512, return_sequences=True, dropout = 0.4,\n",
        "                  kernel_regularizer=regularizers.l2(REG)),\n",
        "                  name='bi_gru1')(reshaped)\n",
        "  #x = Dropout(0.5)(gru_1)\n",
        "  #blstm_2 = Bidirectional(LSTM(512, return_sequences=True, dropout = 0.2,\n",
        "  #                kernel_regularizer=regularizers.l2(REG)))(blstm_1)\n",
        "  gru_2 =  Bidirectional(GRU(256, return_sequences=True, dropout = 0.4,\n",
        "                  kernel_regularizer=regularizers.l2(REG)),\n",
        "                  name='bi_gru2')(gru_1)\n",
        "\n",
        "  #x = Dropout(0.5)(gru_2)\n",
        "\n",
        "  outputs = Dense(len(char_list)+1, activation = 'softmax',\n",
        "                  kernel_regularizer=regularizers.l2(REG),\n",
        "                  name='dense1')(gru_2)\n",
        "  #x = Dropout(0.25)(gru_2)\n",
        "  # model to be used at test time\n",
        "  model = Model(base_model.inputs, outputs)\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "\n",
        "my_model = make_model()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlMJhfakPkEm"
      },
      "source": [
        "#Pure ResNet Model including all layers except the TOP layer and the one achieved best performjance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpcVhjGymjlr"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhcaRm-Yb7p7"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dropout,Bidirectional, RNN,Reshape,Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D,MaxPooling2D, GlobalMaxPooling2D,Concatenate,GlobalAveragePooling2D,Lambda, GRU\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop, Adamax, Adadelta, Adagrad\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "\n",
        "#from resnets_utils import *\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow.keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_geOiF8zyB08"
      },
      "source": [
        "from tensorflow.keras.applications import VGG19,VGG16, ResNet50, MobileNet, Xception\n",
        "from tensorflow.python.keras import regularizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6sQHQkUWwEx"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ej48ceWXHAY"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIS0t0mbSaPW"
      },
      "source": [
        "!pip install keras==2.2.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx9tieObyOfR"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = (2,1)):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block as defined in Figure 4\n",
        "\n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "\n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "\n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path\n",
        "    X = Conv2D(F1, (1, 1), strides = s, name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Second component of main path (≈3 lines)\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "\n",
        "    # Third component of main path (≈2 lines)\n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "\n",
        "    ##### SHORTCUT PATH #### (≈2 lines)\n",
        "    X_shortcut = Conv2D(filters = F3, kernel_size = (1, 1), strides = s, padding = 'valid', name = conv_name_base + '1',\n",
        "                        kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROnlrzpLyVu0"
      },
      "source": [
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block as defined in Figure 3\n",
        "\n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "\n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "\n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    # Save the input value. You'll need this later to add back to the main path.\n",
        "    X_shortcut = X\n",
        "\n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "\n",
        "    # Second component of main path (≈3 lines)\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path (≈2 lines)\n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEPqnzONPijm",
        "outputId": "2150aa86-2667-47ad-c9a4-c419d38b771c"
      },
      "source": [
        "INPUT_SHAPE = (32, 128, 1) # (img_rows, img_cols, img_channel)\n",
        "POOL_SIZE = (2, 2)\n",
        "POOL_SIZE2 = (2, 1)\n",
        "POOL_SIZE3 = (1, 2)\n",
        "KERNEL_SIZE = (3, 3)\n",
        "KERNEL_SIZE_F = (2, 2)\n",
        "REG = 0.0001\n",
        "#from keras.layers import LSTM, Reshape, Input, Conv2D, MaxPool2D, Bidirectional\n",
        "\n",
        "def make_model():\n",
        "  base_model = ResNet50(include_top=False, weights=None, input_tensor=None, input_shape=INPUT_SHAPE)\n",
        "\n",
        "  X = base_model.layers[38].output\n",
        "\n",
        "\n",
        "  X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = (2,1))\n",
        "  X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "  X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "  X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "\n",
        "      # Stage 4 (≈6 lines)\n",
        "  X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = (2,1))\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "\n",
        "      # Stage 5 (≈3 lines)\n",
        "  X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = (2,1))\n",
        "  X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "  X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "  #X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
        "\n",
        "  reshaped=  Reshape((32, 2048), name=\"reshape\") (X)\n",
        "\n",
        "  gru_1 =  Bidirectional(GRU(512, return_sequences=True, dropout = 0.4,\n",
        "                  kernel_regularizer=regularizers.l2(REG)),\n",
        "                  name='bi_gru1')(reshaped)\n",
        "  x = Dropout(0.25)(gru_1)\n",
        "  #blstm_2 = Bidirectional(LSTM(512, return_sequences=True, dropout = 0.2,\n",
        "  #                kernel_regularizer=regularizers.l2(REG)))(blstm_1)\n",
        "  gru_2 =  Bidirectional(GRU(512, return_sequences=True, dropout = 0.4,\n",
        "                  kernel_regularizer=regularizers.l2(REG)),\n",
        "                  name='bi_gru2')(gru_1)\n",
        "\n",
        "  x = Dropout(0.25)(gru_2)\n",
        "\n",
        "  outputs = Dense(len(char_list)+1, activation = 'softmax',\n",
        "                  kernel_regularizer=regularizers.l2(REG),\n",
        "                  name='dense1')(gru_2)\n",
        "\n",
        "  model = Model(base_model.inputs, outputs)\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "my_model = make_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 128, 1)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 38, 134, 1)   0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 16, 64, 64)   3200        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 16, 64, 64)   256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 16, 64, 64)   0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 18, 66, 64)   0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 8, 32, 64)    0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 8, 32, 64)    4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 8, 32, 64)    256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 8, 32, 64)    0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 8, 32, 64)    36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 8, 32, 64)    256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 8, 32, 64)    0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 8, 32, 256)   16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 8, 32, 256)   16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 8, 32, 256)   1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 8, 32, 256)   1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 8, 32, 256)   0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 8, 32, 256)   0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 8, 32, 64)    16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 8, 32, 64)    256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 8, 32, 64)    0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 8, 32, 64)    36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 8, 32, 64)    256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 8, 32, 64)    0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 8, 32, 256)   16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 8, 32, 256)   1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 8, 32, 256)   0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 8, 32, 256)   0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 8, 32, 64)    16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 8, 32, 64)    256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 8, 32, 64)    0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 8, 32, 64)    36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 8, 32, 64)    256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 8, 32, 64)    0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 8, 32, 256)   16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 8, 32, 256)   1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 8, 32, 256)   0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 8, 32, 256)   0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 4, 32, 128)   32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 4, 32, 128)   512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 4, 32, 128)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 4, 32, 128)   147584      activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 4, 32, 128)   512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 4, 32, 128)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 4, 32, 512)   66048       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 4, 32, 512)   131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 4, 32, 512)   2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 4, 32, 512)   2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 4, 32, 512)   0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 4, 32, 512)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 4, 32, 128)   65664       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 4, 32, 128)   512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 4, 32, 128)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 4, 32, 128)   147584      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 4, 32, 128)   512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 4, 32, 128)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 4, 32, 512)   66048       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 4, 32, 512)   2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 4, 32, 512)   0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 4, 32, 512)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 4, 32, 128)   65664       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 4, 32, 128)   512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 4, 32, 128)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 4, 32, 128)   147584      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 4, 32, 128)   512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 4, 32, 128)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 4, 32, 512)   66048       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 4, 32, 512)   2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 4, 32, 512)   0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 4, 32, 512)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 4, 32, 128)   65664       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 4, 32, 128)   512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 4, 32, 128)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 4, 32, 128)   147584      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 4, 32, 128)   512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 4, 32, 128)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 4, 32, 512)   66048       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 4, 32, 512)   2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 4, 32, 512)   0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 4, 32, 512)   0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 2, 32, 256)   131328      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 2, 32, 256)   1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 2, 32, 256)   0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 2, 32, 256)   590080      activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 2, 32, 256)   1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 2, 32, 256)   0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 2, 32, 1024)  263168      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 2, 32, 1024)  525312      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 2, 32, 1024)  4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 2, 32, 1024)  4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 2, 32, 1024)  0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 2, 32, 1024)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 2, 32, 256)   262400      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 2, 32, 256)   1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 2, 32, 256)   0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 2, 32, 256)   590080      activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 2, 32, 256)   1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 2, 32, 256)   0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 2, 32, 1024)  263168      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 2, 32, 1024)  4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 2, 32, 1024)  0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 2, 32, 1024)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 2, 32, 256)   262400      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 2, 32, 256)   1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 2, 32, 256)   0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 2, 32, 256)   590080      activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 2, 32, 256)   1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 2, 32, 256)   0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 2, 32, 1024)  263168      activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 2, 32, 1024)  4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 2, 32, 1024)  0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 2, 32, 1024)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 2, 32, 256)   262400      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 2, 32, 256)   1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 2, 32, 256)   0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 2, 32, 256)   590080      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 2, 32, 256)   1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 2, 32, 256)   0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 2, 32, 1024)  263168      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 2, 32, 1024)  4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 2, 32, 1024)  0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 2, 32, 1024)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 2, 32, 256)   262400      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 2, 32, 256)   1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 2, 32, 256)   0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 2, 32, 256)   590080      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 2, 32, 256)   1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 2, 32, 256)   0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 2, 32, 1024)  263168      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 2, 32, 1024)  4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 2, 32, 1024)  0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 2, 32, 1024)  0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 2, 32, 256)   262400      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 2, 32, 256)   1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 2, 32, 256)   0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 2, 32, 256)   590080      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 2, 32, 256)   1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 2, 32, 256)   0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 2, 32, 1024)  263168      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 2, 32, 1024)  4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 2, 32, 1024)  0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 2, 32, 1024)  0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 1, 32, 512)   524800      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 1, 32, 512)   2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 1, 32, 512)   0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 1, 32, 512)   2359808     activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 1, 32, 512)   2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 1, 32, 512)   0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 1, 32, 2048)  1050624     activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 1, 32, 2048)  2099200     activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 1, 32, 2048)  8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 1, 32, 2048)  8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 1, 32, 2048)  0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 1, 32, 2048)  0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 1, 32, 512)   1049088     activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 1, 32, 512)   2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 1, 32, 512)   0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 1, 32, 512)   2359808     activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 1, 32, 512)   2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 1, 32, 512)   0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 1, 32, 2048)  1050624     activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 1, 32, 2048)  8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 1, 32, 2048)  0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 1, 32, 2048)  0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 1, 32, 512)   1049088     activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 1, 32, 512)   2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 1, 32, 512)   0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 1, 32, 512)   2359808     activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 1, 32, 512)   2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 1, 32, 512)   0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 1, 32, 2048)  1050624     activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 1, 32, 2048)  8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 1, 32, 2048)  0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 1, 32, 2048)  0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 32, 2048)     0           activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bi_gru1 (Bidirectional)         (None, 32, 1024)     7870464     reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bi_gru2 (Bidirectional)         (None, 32, 1024)     4724736     bi_gru1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense1 (Dense)                  (None, 32, 301)      308525      bi_gru2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 36,485,165\n",
            "Trainable params: 36,432,045\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbzUUJrASaVm"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKx14fU3FBNw"
      },
      "source": [
        "#This Resnet50 is the one developed from scratch since due to compatibility issue I cannot use the imported version from keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSbbqF-aE_8a"
      },
      "source": [
        "INPUT_SHAPE = (32, 128, 1) # (img_rows, img_cols, img_channel)\n",
        "POOL_SIZE = (2, 2)\n",
        "POOL_SIZE2 = (2, 1)\n",
        "POOL_SIZE3 = (1, 2)\n",
        "KERNEL_SIZE = (3, 3)\n",
        "KERNEL_SIZE_F = (2, 2)\n",
        "REG = 0.0001\n",
        "#from keras.layers import LSTM, Reshape, Input, Conv2D, MaxPool2D, Bidirectional\n",
        "\n",
        "def make_model():\n",
        "  #base_model = ResNet50(include_top=False, weights=None, input_tensor=None, input_shape=INPUT_SHAPE)\n",
        "\n",
        "  #X = base_model.layers[38].output\n",
        "  X_input = Input(INPUT_SHAPE)\n",
        "\n",
        "  X = ZeroPadding2D((3, 3))(X_input)\n",
        "  X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(X)\n",
        "  X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = ZeroPadding2D((1, 1), name='pool1_pad')(X)\n",
        "  X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "\n",
        "  X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=(1, 1))\n",
        "  X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "  X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "  X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = (2,1))\n",
        "  X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "  X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "  X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "\n",
        "      # Stage 4 (≈6 lines)\n",
        "  X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = (2,1))\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "\n",
        "      # Stage 5 (≈3 lines)\n",
        "  X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = (2,1))\n",
        "  X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "  X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "  #X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
        "\n",
        "  reshaped=  Reshape((32, 2048), name=\"reshape\") (X)\n",
        "\n",
        "  gru_1 =  Bidirectional(GRU(512, return_sequences=True, reset_after=True,dropout = 0.4,\n",
        "                  kernel_regularizer=regularizers.l2(REG)),\n",
        "                  name='bi_gru1')(reshaped)\n",
        "  x = Dropout(0.25)(gru_1)\n",
        "  #blstm_2 = Bidirectional(LSTM(512, return_sequences=True, dropout = 0.2,\n",
        "  #                kernel_regularizer=regularizers.l2(REG)))(blstm_1)\n",
        "  gru_2 =  Bidirectional(GRU(512, return_sequences=True, reset_after=True,dropout = 0.4,\n",
        "                  kernel_regularizer=regularizers.l2(REG)),\n",
        "                  name='bi_gru2')(gru_1)\n",
        "\n",
        "  x = Dropout(0.25)(gru_2)\n",
        "\n",
        "  outputs = Dense(len(char_list)+1, activation = 'softmax',\n",
        "                  kernel_regularizer=regularizers.l2(REG),\n",
        "                  name='dense1')(gru_2)\n",
        "\n",
        "  model = Model(X_input, outputs)\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "my_model = make_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gI8mXeaxfxsU"
      },
      "source": [
        "#DenseNet121 Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijTBQCJ6SfdW"
      },
      "source": [
        "from keras.engine import Layer, InputSpec\n",
        "try:\n",
        "    from keras import initializations\n",
        "except ImportError:\n",
        "    from keras import initializers as initializations\n",
        "import keras.backend as K\n",
        "\n",
        "class Scale(Layer):\n",
        "    '''Custom Layer for DenseNet used for BatchNormalization.\n",
        "\n",
        "    Learns a set of weights and biases used for scaling the input data.\n",
        "    the output consists simply in an element-wise multiplication of the input\n",
        "    and a sum of a set of constants:\n",
        "        out = in * gamma + beta,\n",
        "    where 'gamma' and 'beta' are the weights and biases larned.\n",
        "    # Arguments\n",
        "        axis: integer, axis along which to normalize in mode 0. For instance,\n",
        "            if your input tensor has shape (samples, channels, rows, cols),\n",
        "            set axis to 1 to normalize per feature map (channels axis).\n",
        "        momentum: momentum in the computation of the\n",
        "            exponential average of the mean and standard deviation\n",
        "            of the data, for feature-wise normalization.\n",
        "        weights: Initialization weights.\n",
        "            List of 2 Numpy arrays, with shapes:\n",
        "            `[(input_shape,), (input_shape,)]`\n",
        "        beta_init: name of initialization function for shift parameter\n",
        "            (see [initializations](../initializations.md)), or alternatively,\n",
        "            Theano/TensorFlow function to use for weights initialization.\n",
        "            This parameter is only relevant if you don't pass a `weights` argument.\n",
        "        gamma_init: name of initialization function for scale parameter (see\n",
        "            [initializations](../initializations.md)), or alternatively,\n",
        "            Theano/TensorFlow function to use for weights initialization.\n",
        "            This parameter is only relevant if you don't pass a `weights` argument.\n",
        "    '''\n",
        "    def __init__(self, weights=None, axis=-1, momentum = 0.9, beta_init='zero', gamma_init='one', **kwargs):\n",
        "        self.momentum = momentum\n",
        "        self.axis = axis\n",
        "        self.beta_init = initializations.get(beta_init)\n",
        "        self.gamma_init = initializations.get(gamma_init)\n",
        "        self.initial_weights = weights\n",
        "        super(Scale, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.input_spec = [InputSpec(shape=input_shape)]\n",
        "        shape = (int(input_shape[self.axis]),)\n",
        "\n",
        "        # Tensorflow >= 1.0.0 compatibility\n",
        "        self.gamma = K.variable(self.gamma_init(shape), name='{}_gamma'.format(self.name))\n",
        "        self.beta = K.variable(self.beta_init(shape), name='{}_beta'.format(self.name))\n",
        "        #self.gamma = self.gamma_init(shape, name='{}_gamma'.format(self.name))\n",
        "        #self.beta = self.beta_init(shape, name='{}_beta'.format(self.name))\n",
        "        self._trainable_weights = [self.gamma, self.beta]\n",
        "\n",
        "        if self.initial_weights is not None:\n",
        "            self.set_weights(self.initial_weights)\n",
        "            del self.initial_weights\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        input_shape = self.input_spec[0].shape\n",
        "        broadcast_shape = [1] * len(input_shape)\n",
        "        broadcast_shape[self.axis] = input_shape[self.axis]\n",
        "\n",
        "        out = K.reshape(self.gamma, broadcast_shape) * x + K.reshape(self.beta, broadcast_shape)\n",
        "        return out\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\"momentum\": self.momentum, \"axis\": self.axis}\n",
        "        base_config = super(Scale, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDH_bRLdSqku"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ART36hwfAQDw"
      },
      "source": [
        "def conv_blocktry(x, stage, branch, nb_filter, dropout_rate=None, weight_decay=1e-4):\n",
        "    '''Apply BatchNorm, Relu, bottleneck 1x1 Conv2D, 3x3 Conv2D, and option dropout\n",
        "        # Arguments\n",
        "            x: input tensor\n",
        "            stage: index for dense block\n",
        "            branch: layer index within each dense block\n",
        "            nb_filter: number of filters\n",
        "            dropout_rate: dropout rate\n",
        "            weight_decay: weight decay factor\n",
        "    '''\n",
        "    eps = 1.1e-5\n",
        "    conv_name_base = 'conv' + str(stage) + '_' + str(branch)\n",
        "    relu_name_base = 'relu' + str(stage) + '_' + str(branch)\n",
        "\n",
        "    # 1x1 Convolution (Bottleneck layer)\n",
        "    inter_channel = nb_filter * 4\n",
        "    x = BatchNormalization(epsilon=eps, axis=3, name=conv_name_base+'_x1_bn')(x)\n",
        "    x = Scale(axis=3, name=conv_name_base+'_x1_scale')(x)\n",
        "    x = Activation('relu', name=relu_name_base+'_x1')(x)\n",
        "    x = Conv2D(inter_channel, (1, 1), name=conv_name_base+'_x1', padding= 'same' ,use_bias=False)(x)\n",
        "    #print(\"ima from conv block\")\n",
        "    #print(x.shape)\n",
        "    #print(\"not a good idea\")\n",
        "    if dropout_rate:\n",
        "        x = Dropout(dropout_rate)(x)\n",
        "\n",
        "    # 3x3 Convolution\n",
        "    x = BatchNormalization(epsilon=eps, axis=3, name=conv_name_base+'_x2_bn')(x)\n",
        "    x = Scale(axis=3, name=conv_name_base+'_x2_scale')(x)\n",
        "    x = Activation('relu', name=relu_name_base+'_x2')(x)\n",
        "    #x = ZeroPadding2D((1, 1), name=conv_name_base+'_x2_zeropadding')(x)\n",
        "    x = Conv2D(nb_filter, (3, 3), name=conv_name_base+'_x2', padding = 'same', use_bias=False)(x)\n",
        "\n",
        "    if dropout_rate:\n",
        "        x = Dropout(dropout_rate)(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9ZibmAkS6SU"
      },
      "source": [
        "#transition block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scJPJSAeSvaW"
      },
      "source": [
        "def transition_blocktry(x, stage, nb_filter, compression=1.0, dropout_rate=None, weight_decay=1E-4):\n",
        "    ''' Apply BatchNorm, 1x1 Convolution, averagePooling, optional compression, dropout\n",
        "        # Arguments\n",
        "            x: input tensor\n",
        "            stage: index for dense block\n",
        "            nb_filter: number of filters\n",
        "            compression: calculated as 1 - reduction. Reduces the number of feature maps in the transition block.\n",
        "            dropout_rate: dropout rate\n",
        "            weight_decay: weight decay factor\n",
        "    '''\n",
        "\n",
        "    eps = 1.1e-5\n",
        "    conv_name_base = 'conv' + str(stage) + '_blk'\n",
        "    relu_name_base = 'relu' + str(stage) + '_blk'\n",
        "    pool_name_base = 'pool' + str(stage)\n",
        "\n",
        "    x = BatchNormalization(epsilon=eps, axis=3, name=conv_name_base+'_bn')(x)\n",
        "    x = Scale(axis=3, name=conv_name_base+'_scale')(x)\n",
        "    x = Activation('relu', name=relu_name_base)(x)\n",
        "    x = Conv2D(int(nb_filter * compression), (1, 1), name=conv_name_base, use_bias=False)(x)\n",
        "\n",
        "    if dropout_rate:\n",
        "        x = Dropout(dropout_rate)(x)\n",
        "\n",
        "    x = AveragePooling2D((2, 1), strides=(2, 1), name=pool_name_base)(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYAOstVHTFf8"
      },
      "source": [
        "def dense_blocktry(x, stage, nb_layers, nb_filter, growth_rate, dropout_rate=None, weight_decay=1e-4, grow_nb_filters=True):\n",
        "    ''' Build a dense_block where the output of each conv_block is fed to subsequent ones\n",
        "        # Arguments\n",
        "            x: input tensor\n",
        "            stage: index for dense block\n",
        "            nb_layers: the number of layers of conv_block to append to the model.\n",
        "            nb_filter: number of filters\n",
        "            growth_rate: growth rate\n",
        "            dropout_rate: dropout rate\n",
        "            weight_decay: weight decay factor\n",
        "            grow_nb_filters: flag to decide to allow number of filters to grow\n",
        "    '''\n",
        "\n",
        "    eps = 1.1e-5\n",
        "    concat_feat = x\n",
        "    #print(concat_feat.shape)\n",
        "\n",
        "    for i in range(nb_layers):\n",
        "        branch = i+1\n",
        "        x = conv_blocktry(concat_feat, stage, branch, growth_rate, dropout_rate, weight_decay)\n",
        "        #print(x.shape)\n",
        "        concat_feat = Concatenate (axis=-1)([concat_feat, x])\n",
        "\n",
        "        if grow_nb_filters:\n",
        "            nb_filter += growth_rate\n",
        "\n",
        "    return concat_feat, nb_filter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nP5ahKvJXEzX",
        "outputId": "5af86acd-6d66-490d-8a1f-91c3ff6e2b69"
      },
      "source": [
        "print( K.image_data_format())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "channels_last\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zW6qPUbXToql"
      },
      "source": [
        "def DenseNettry(nb_dense_block=4, growth_rate=32, nb_filter=64, reduction=0.0, dropout_rate=0.0, weight_decay=1e-4, classes=1000, weights_path=None):\n",
        "    '''Instantiate the DenseNet 121 architecture,\n",
        "        # Arguments\n",
        "            nb_dense_block: number of dense blocks to add to end\n",
        "            growth_rate: number of filters to add per dense block\n",
        "            nb_filter: initial number of filters\n",
        "            reduction: reduction factor of transition blocks.\n",
        "            dropout_rate: dropout rate\n",
        "            weight_decay: weight decay factor\n",
        "            classes: optional number of classes to classify images\n",
        "            weights_path: path to pre-trained weights\n",
        "        # Returns\n",
        "            A Keras model instance.\n",
        "    '''\n",
        "    eps = 1.1e-5\n",
        "\n",
        "    # compute compression factor\n",
        "    compression = 1.0 - reduction\n",
        "\n",
        "    img_input = Input(shape=(32, 128, 1), name='data')\n",
        "    concat_axis = 3\n",
        "    #Handle Dimension Ordering for different backends\n",
        "    # global concat_axis\n",
        "    # if K.image_data_format() == 'tf':\n",
        "    #   concat_axis = 3\n",
        "    #   img_input = Input(shape=(224, 224, 3), name='data')\n",
        "    # else:\n",
        "    #   concat_axis = 1\n",
        "    #   img_input = Input(shape=(3, 224, 224), name='data')\n",
        "\n",
        "    # From architecture for ImageNet (Table 1 in the paper)\n",
        "    nb_filter = 64\n",
        "    nb_layers = [6,12,24,16] # For DenseNet-121\n",
        "\n",
        "    # Initial convolution\n",
        "    x = ZeroPadding2D((3, 3), name='conv1_zeropadding')(img_input)\n",
        "    x = Conv2D(nb_filter, (7, 7), strides=(2, 2), name='conv1', use_bias=False)(x)\n",
        "    x = BatchNormalization(epsilon=eps, axis = 3, name='conv1_bn')(x)\n",
        "    x = Scale(axis=3, name='conv1_scale')(x)\n",
        "    x = Activation('relu', name='relu1')(x)\n",
        "    x = ZeroPadding2D((1, 1), name='pool1_zeropadding')(x)\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), name='pool1')(x)\n",
        "\n",
        "    # Add dense blocks\n",
        "    for block_idx in range(nb_dense_block - 1):\n",
        "        stage = block_idx+2\n",
        "        x, nb_filter = dense_blocktry(x, stage, nb_layers[block_idx], nb_filter, growth_rate, dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
        "\n",
        "        # Add transition_block\n",
        "        x = transition_blocktry(x, stage, nb_filter, compression=compression, dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
        "        nb_filter = int(nb_filter * compression)\n",
        "\n",
        "    final_stage = stage + 1\n",
        "    x, nb_filter = dense_blocktry(x, final_stage, nb_layers[-1], nb_filter, growth_rate, dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
        "\n",
        "    x = BatchNormalization(epsilon=eps, axis=3, name='conv'+str(final_stage)+'_blk_bn')(x)\n",
        "    x = Scale(axis=3, name='conv'+str(final_stage)+'_blk_scale')(x)\n",
        "    x = Activation('relu', name='relu'+str(final_stage)+'_blk')(x)\n",
        "    #x = GlobalAveragePooling2D(name='pool'+str(final_stage))(x)\n",
        "    #x = AveragePooling2D((2, 2), strides=(2, 2), name=\"pool_name_base\")(x)\n",
        "\n",
        "    reshaped=  Reshape((32, 1920), name=\"reshape\") (x)\n",
        "\n",
        "    gru_1 =  Bidirectional(GRU(512, return_sequences=True, reset_after=True,dropout = 0.4,\n",
        "                  kernel_regularizer=regularizers.l2(REG)),\n",
        "                  name='bi_gru1')(reshaped)\n",
        "    x = Dropout(0.25)(gru_1)\n",
        "    #blstm_2 = Bidirectional(LSTM(512, return_sequences=True, dropout = 0.2,\n",
        "    #                kernel_regularizer=regularizers.l2(REG)))(blstm_1)\n",
        "    gru_2 =  Bidirectional(GRU(512, return_sequences=True,reset_after=True, dropout = 0.4,\n",
        "                  kernel_regularizer=regularizers.l2(REG)),\n",
        "                  name='bi_gru2')(gru_1)\n",
        "\n",
        "    x = Dropout(0.25)(gru_2)\n",
        "\n",
        "    outputs = Dense(len(char_list)+1, activation = 'softmax',\n",
        "                  kernel_regularizer=regularizers.l2(REG),\n",
        "                  name='dense1')(gru_2)\n",
        "\n",
        "    #model = Model(base_model.inputs, outputs)\n",
        "    #model.summary()\n",
        "\n",
        "\n",
        "    model = Model(img_input, outputs)\n",
        "    model.summary()\n",
        "\n",
        "\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLCYYZ2SCjyq"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbCZ9uenVizL",
        "outputId": "7c5a717a-f529-421b-ae35-eb3b08c3b54a"
      },
      "source": [
        "#my_model = make_model()\n",
        "REG = 0.0001\n",
        "my_model=DenseNettry()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tracking <tf.Variable 'conv1_scale/conv1_scale_gamma:0' shape=(64,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv1_scale/conv1_scale_beta:0' shape=(64,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv2_1_x1_scale/conv2_1_x1_scale_gamma:0' shape=(64,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv2_1_x1_scale/conv2_1_x1_scale_beta:0' shape=(64,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv2_1_x2_scale/conv2_1_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv2_1_x2_scale/conv2_1_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv2_2_x1_scale/conv2_2_x1_scale_gamma:0' shape=(96,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv2_2_x1_scale/conv2_2_x1_scale_beta:0' shape=(96,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv2_2_x2_scale/conv2_2_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv2_2_x2_scale/conv2_2_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv2_3_x1_scale/conv2_3_x1_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv2_3_x1_scale/conv2_3_x1_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv2_3_x2_scale/conv2_3_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv2_3_x2_scale/conv2_3_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv2_4_x1_scale/conv2_4_x1_scale_gamma:0' shape=(160,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv2_4_x1_scale/conv2_4_x1_scale_beta:0' shape=(160,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv2_4_x2_scale/conv2_4_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv2_4_x2_scale/conv2_4_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv2_5_x1_scale/conv2_5_x1_scale_gamma:0' shape=(192,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv2_5_x1_scale/conv2_5_x1_scale_beta:0' shape=(192,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv2_5_x2_scale/conv2_5_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv2_5_x2_scale/conv2_5_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv2_6_x1_scale/conv2_6_x1_scale_gamma:0' shape=(224,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv2_6_x1_scale/conv2_6_x1_scale_beta:0' shape=(224,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv2_6_x2_scale/conv2_6_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv2_6_x2_scale/conv2_6_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv2_blk_scale/conv2_blk_scale_gamma:0' shape=(256,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv2_blk_scale/conv2_blk_scale_beta:0' shape=(256,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_1_x1_scale/conv3_1_x1_scale_gamma:0' shape=(256,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_1_x1_scale/conv3_1_x1_scale_beta:0' shape=(256,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_1_x2_scale/conv3_1_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_1_x2_scale/conv3_1_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_2_x1_scale/conv3_2_x1_scale_gamma:0' shape=(288,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_2_x1_scale/conv3_2_x1_scale_beta:0' shape=(288,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_2_x2_scale/conv3_2_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_2_x2_scale/conv3_2_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_3_x1_scale/conv3_3_x1_scale_gamma:0' shape=(320,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_3_x1_scale/conv3_3_x1_scale_beta:0' shape=(320,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_3_x2_scale/conv3_3_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_3_x2_scale/conv3_3_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_4_x1_scale/conv3_4_x1_scale_gamma:0' shape=(352,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_4_x1_scale/conv3_4_x1_scale_beta:0' shape=(352,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_4_x2_scale/conv3_4_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_4_x2_scale/conv3_4_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_5_x1_scale/conv3_5_x1_scale_gamma:0' shape=(384,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_5_x1_scale/conv3_5_x1_scale_beta:0' shape=(384,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_5_x2_scale/conv3_5_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_5_x2_scale/conv3_5_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_6_x1_scale/conv3_6_x1_scale_gamma:0' shape=(416,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_6_x1_scale/conv3_6_x1_scale_beta:0' shape=(416,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_6_x2_scale/conv3_6_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_6_x2_scale/conv3_6_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_7_x1_scale/conv3_7_x1_scale_gamma:0' shape=(448,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_7_x1_scale/conv3_7_x1_scale_beta:0' shape=(448,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_7_x2_scale/conv3_7_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_7_x2_scale/conv3_7_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_8_x1_scale/conv3_8_x1_scale_gamma:0' shape=(480,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_8_x1_scale/conv3_8_x1_scale_beta:0' shape=(480,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_8_x2_scale/conv3_8_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_8_x2_scale/conv3_8_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_9_x1_scale/conv3_9_x1_scale_gamma:0' shape=(512,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_9_x1_scale/conv3_9_x1_scale_beta:0' shape=(512,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_9_x2_scale/conv3_9_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_9_x2_scale/conv3_9_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_10_x1_scale/conv3_10_x1_scale_gamma:0' shape=(544,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_10_x1_scale/conv3_10_x1_scale_beta:0' shape=(544,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_10_x2_scale/conv3_10_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_10_x2_scale/conv3_10_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_11_x1_scale/conv3_11_x1_scale_gamma:0' shape=(576,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_11_x1_scale/conv3_11_x1_scale_beta:0' shape=(576,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_11_x2_scale/conv3_11_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_11_x2_scale/conv3_11_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_12_x1_scale/conv3_12_x1_scale_gamma:0' shape=(608,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_12_x1_scale/conv3_12_x1_scale_beta:0' shape=(608,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_12_x2_scale/conv3_12_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_12_x2_scale/conv3_12_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_blk_scale/conv3_blk_scale_gamma:0' shape=(640,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_blk_scale/conv3_blk_scale_beta:0' shape=(640,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_1_x1_scale/conv4_1_x1_scale_gamma:0' shape=(640,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_1_x1_scale/conv4_1_x1_scale_beta:0' shape=(640,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_1_x2_scale/conv4_1_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_1_x2_scale/conv4_1_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_2_x1_scale/conv4_2_x1_scale_gamma:0' shape=(672,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_2_x1_scale/conv4_2_x1_scale_beta:0' shape=(672,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_2_x2_scale/conv4_2_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_2_x2_scale/conv4_2_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_3_x1_scale/conv4_3_x1_scale_gamma:0' shape=(704,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_3_x1_scale/conv4_3_x1_scale_beta:0' shape=(704,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_3_x2_scale/conv4_3_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_3_x2_scale/conv4_3_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_4_x1_scale/conv4_4_x1_scale_gamma:0' shape=(736,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_4_x1_scale/conv4_4_x1_scale_beta:0' shape=(736,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_4_x2_scale/conv4_4_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_4_x2_scale/conv4_4_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_5_x1_scale/conv4_5_x1_scale_gamma:0' shape=(768,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_5_x1_scale/conv4_5_x1_scale_beta:0' shape=(768,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_5_x2_scale/conv4_5_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_5_x2_scale/conv4_5_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_6_x1_scale/conv4_6_x1_scale_gamma:0' shape=(800,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_6_x1_scale/conv4_6_x1_scale_beta:0' shape=(800,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_6_x2_scale/conv4_6_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_6_x2_scale/conv4_6_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_7_x1_scale/conv4_7_x1_scale_gamma:0' shape=(832,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_7_x1_scale/conv4_7_x1_scale_beta:0' shape=(832,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_7_x2_scale/conv4_7_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_7_x2_scale/conv4_7_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_8_x1_scale/conv4_8_x1_scale_gamma:0' shape=(864,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_8_x1_scale/conv4_8_x1_scale_beta:0' shape=(864,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_8_x2_scale/conv4_8_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_8_x2_scale/conv4_8_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_9_x1_scale/conv4_9_x1_scale_gamma:0' shape=(896,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_9_x1_scale/conv4_9_x1_scale_beta:0' shape=(896,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_9_x2_scale/conv4_9_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_9_x2_scale/conv4_9_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_10_x1_scale/conv4_10_x1_scale_gamma:0' shape=(928,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_10_x1_scale/conv4_10_x1_scale_beta:0' shape=(928,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_10_x2_scale/conv4_10_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_10_x2_scale/conv4_10_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_11_x1_scale/conv4_11_x1_scale_gamma:0' shape=(960,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_11_x1_scale/conv4_11_x1_scale_beta:0' shape=(960,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_11_x2_scale/conv4_11_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_11_x2_scale/conv4_11_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_12_x1_scale/conv4_12_x1_scale_gamma:0' shape=(992,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_12_x1_scale/conv4_12_x1_scale_beta:0' shape=(992,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_12_x2_scale/conv4_12_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_12_x2_scale/conv4_12_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_13_x1_scale/conv4_13_x1_scale_gamma:0' shape=(1024,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_13_x1_scale/conv4_13_x1_scale_beta:0' shape=(1024,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_13_x2_scale/conv4_13_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_13_x2_scale/conv4_13_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_14_x1_scale/conv4_14_x1_scale_gamma:0' shape=(1056,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_14_x1_scale/conv4_14_x1_scale_beta:0' shape=(1056,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_14_x2_scale/conv4_14_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_14_x2_scale/conv4_14_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_15_x1_scale/conv4_15_x1_scale_gamma:0' shape=(1088,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_15_x1_scale/conv4_15_x1_scale_beta:0' shape=(1088,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_15_x2_scale/conv4_15_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_15_x2_scale/conv4_15_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_16_x1_scale/conv4_16_x1_scale_gamma:0' shape=(1120,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_16_x1_scale/conv4_16_x1_scale_beta:0' shape=(1120,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_16_x2_scale/conv4_16_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_16_x2_scale/conv4_16_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_17_x1_scale/conv4_17_x1_scale_gamma:0' shape=(1152,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_17_x1_scale/conv4_17_x1_scale_beta:0' shape=(1152,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_17_x2_scale/conv4_17_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_17_x2_scale/conv4_17_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_18_x1_scale/conv4_18_x1_scale_gamma:0' shape=(1184,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_18_x1_scale/conv4_18_x1_scale_beta:0' shape=(1184,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_18_x2_scale/conv4_18_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_18_x2_scale/conv4_18_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_19_x1_scale/conv4_19_x1_scale_gamma:0' shape=(1216,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_19_x1_scale/conv4_19_x1_scale_beta:0' shape=(1216,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_19_x2_scale/conv4_19_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_19_x2_scale/conv4_19_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_20_x1_scale/conv4_20_x1_scale_gamma:0' shape=(1248,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_20_x1_scale/conv4_20_x1_scale_beta:0' shape=(1248,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_20_x2_scale/conv4_20_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_20_x2_scale/conv4_20_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_21_x1_scale/conv4_21_x1_scale_gamma:0' shape=(1280,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_21_x1_scale/conv4_21_x1_scale_beta:0' shape=(1280,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_21_x2_scale/conv4_21_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_21_x2_scale/conv4_21_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_22_x1_scale/conv4_22_x1_scale_gamma:0' shape=(1312,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_22_x1_scale/conv4_22_x1_scale_beta:0' shape=(1312,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_22_x2_scale/conv4_22_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_22_x2_scale/conv4_22_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_23_x1_scale/conv4_23_x1_scale_gamma:0' shape=(1344,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_23_x1_scale/conv4_23_x1_scale_beta:0' shape=(1344,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_23_x2_scale/conv4_23_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_23_x2_scale/conv4_23_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_24_x1_scale/conv4_24_x1_scale_gamma:0' shape=(1376,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_24_x1_scale/conv4_24_x1_scale_beta:0' shape=(1376,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_24_x2_scale/conv4_24_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_24_x2_scale/conv4_24_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_blk_scale/conv4_blk_scale_gamma:0' shape=(1408,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_blk_scale/conv4_blk_scale_beta:0' shape=(1408,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_1_x1_scale/conv5_1_x1_scale_gamma:0' shape=(1408,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_1_x1_scale/conv5_1_x1_scale_beta:0' shape=(1408,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_1_x2_scale/conv5_1_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_1_x2_scale/conv5_1_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_2_x1_scale/conv5_2_x1_scale_gamma:0' shape=(1440,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_2_x1_scale/conv5_2_x1_scale_beta:0' shape=(1440,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_2_x2_scale/conv5_2_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_2_x2_scale/conv5_2_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_3_x1_scale/conv5_3_x1_scale_gamma:0' shape=(1472,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_3_x1_scale/conv5_3_x1_scale_beta:0' shape=(1472,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_3_x2_scale/conv5_3_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_3_x2_scale/conv5_3_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_4_x1_scale/conv5_4_x1_scale_gamma:0' shape=(1504,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_4_x1_scale/conv5_4_x1_scale_beta:0' shape=(1504,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_4_x2_scale/conv5_4_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_4_x2_scale/conv5_4_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_5_x1_scale/conv5_5_x1_scale_gamma:0' shape=(1536,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_5_x1_scale/conv5_5_x1_scale_beta:0' shape=(1536,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_5_x2_scale/conv5_5_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_5_x2_scale/conv5_5_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_6_x1_scale/conv5_6_x1_scale_gamma:0' shape=(1568,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_6_x1_scale/conv5_6_x1_scale_beta:0' shape=(1568,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_6_x2_scale/conv5_6_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_6_x2_scale/conv5_6_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_7_x1_scale/conv5_7_x1_scale_gamma:0' shape=(1600,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_7_x1_scale/conv5_7_x1_scale_beta:0' shape=(1600,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_7_x2_scale/conv5_7_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_7_x2_scale/conv5_7_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_8_x1_scale/conv5_8_x1_scale_gamma:0' shape=(1632,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_8_x1_scale/conv5_8_x1_scale_beta:0' shape=(1632,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_8_x2_scale/conv5_8_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_8_x2_scale/conv5_8_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_9_x1_scale/conv5_9_x1_scale_gamma:0' shape=(1664,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_9_x1_scale/conv5_9_x1_scale_beta:0' shape=(1664,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_9_x2_scale/conv5_9_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_9_x2_scale/conv5_9_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_10_x1_scale/conv5_10_x1_scale_gamma:0' shape=(1696,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_10_x1_scale/conv5_10_x1_scale_beta:0' shape=(1696,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_10_x2_scale/conv5_10_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_10_x2_scale/conv5_10_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_11_x1_scale/conv5_11_x1_scale_gamma:0' shape=(1728,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_11_x1_scale/conv5_11_x1_scale_beta:0' shape=(1728,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_11_x2_scale/conv5_11_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_11_x2_scale/conv5_11_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_12_x1_scale/conv5_12_x1_scale_gamma:0' shape=(1760,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_12_x1_scale/conv5_12_x1_scale_beta:0' shape=(1760,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_12_x2_scale/conv5_12_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_12_x2_scale/conv5_12_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_13_x1_scale/conv5_13_x1_scale_gamma:0' shape=(1792,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_13_x1_scale/conv5_13_x1_scale_beta:0' shape=(1792,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_13_x2_scale/conv5_13_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_13_x2_scale/conv5_13_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_14_x1_scale/conv5_14_x1_scale_gamma:0' shape=(1824,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_14_x1_scale/conv5_14_x1_scale_beta:0' shape=(1824,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_14_x2_scale/conv5_14_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_14_x2_scale/conv5_14_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_15_x1_scale/conv5_15_x1_scale_gamma:0' shape=(1856,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_15_x1_scale/conv5_15_x1_scale_beta:0' shape=(1856,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_15_x2_scale/conv5_15_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_15_x2_scale/conv5_15_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_16_x1_scale/conv5_16_x1_scale_gamma:0' shape=(1888,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_16_x1_scale/conv5_16_x1_scale_beta:0' shape=(1888,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_16_x2_scale/conv5_16_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_16_x2_scale/conv5_16_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_blk_scale/conv5_blk_scale_gamma:0' shape=(1920,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_blk_scale/conv5_blk_scale_beta:0' shape=(1920,) dtype=float32> beta\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "data (InputLayer)               (None, 32, 128, 1)   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_zeropadding (ZeroPadding2 (None, 38, 134, 1)   0           data[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 16, 64, 64)   3136        conv1_zeropadding[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 16, 64, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv1_scale (Scale)             (None, 16, 64, 64)   128         conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "relu1 (Activation)              (None, 16, 64, 64)   0           conv1_scale[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "pool1_zeropadding (ZeroPadding2 (None, 18, 66, 64)   0           relu1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "pool1 (MaxPooling2D)            (None, 8, 32, 64)    0           pool1_zeropadding[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_x1_bn (BatchNormalizati (None, 8, 32, 64)    256         pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_x1_scale (Scale)        (None, 8, 32, 64)    128         conv2_1_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu2_1_x1 (Activation)         (None, 8, 32, 64)    0           conv2_1_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_x1 (Conv2D)             (None, 8, 32, 128)   8192        relu2_1_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_x2_bn (BatchNormalizati (None, 8, 32, 128)   512         conv2_1_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_x2_scale (Scale)        (None, 8, 32, 128)   256         conv2_1_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu2_1_x2 (Activation)         (None, 8, 32, 128)   0           conv2_1_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_x2 (Conv2D)             (None, 8, 32, 32)    36864       relu2_1_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 8, 32, 96)    0           pool1[0][0]                      \n",
            "                                                                 conv2_1_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_x1_bn (BatchNormalizati (None, 8, 32, 96)    384         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_x1_scale (Scale)        (None, 8, 32, 96)    192         conv2_2_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu2_2_x1 (Activation)         (None, 8, 32, 96)    0           conv2_2_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_x1 (Conv2D)             (None, 8, 32, 128)   12288       relu2_2_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_x2_bn (BatchNormalizati (None, 8, 32, 128)   512         conv2_2_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_x2_scale (Scale)        (None, 8, 32, 128)   256         conv2_2_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu2_2_x2 (Activation)         (None, 8, 32, 128)   0           conv2_2_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_x2 (Conv2D)             (None, 8, 32, 32)    36864       relu2_2_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 8, 32, 128)   0           concatenate_1[0][0]              \n",
            "                                                                 conv2_2_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_x1_bn (BatchNormalizati (None, 8, 32, 128)   512         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_x1_scale (Scale)        (None, 8, 32, 128)   256         conv2_3_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu2_3_x1 (Activation)         (None, 8, 32, 128)   0           conv2_3_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_x1 (Conv2D)             (None, 8, 32, 128)   16384       relu2_3_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_x2_bn (BatchNormalizati (None, 8, 32, 128)   512         conv2_3_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_x2_scale (Scale)        (None, 8, 32, 128)   256         conv2_3_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu2_3_x2 (Activation)         (None, 8, 32, 128)   0           conv2_3_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_x2 (Conv2D)             (None, 8, 32, 32)    36864       relu2_3_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 8, 32, 160)   0           concatenate_2[0][0]              \n",
            "                                                                 conv2_3_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_4_x1_bn (BatchNormalizati (None, 8, 32, 160)   640         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_4_x1_scale (Scale)        (None, 8, 32, 160)   320         conv2_4_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu2_4_x1 (Activation)         (None, 8, 32, 160)   0           conv2_4_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_4_x1 (Conv2D)             (None, 8, 32, 128)   20480       relu2_4_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_4_x2_bn (BatchNormalizati (None, 8, 32, 128)   512         conv2_4_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_4_x2_scale (Scale)        (None, 8, 32, 128)   256         conv2_4_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu2_4_x2 (Activation)         (None, 8, 32, 128)   0           conv2_4_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_4_x2 (Conv2D)             (None, 8, 32, 32)    36864       relu2_4_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 8, 32, 192)   0           concatenate_3[0][0]              \n",
            "                                                                 conv2_4_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_5_x1_bn (BatchNormalizati (None, 8, 32, 192)   768         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_5_x1_scale (Scale)        (None, 8, 32, 192)   384         conv2_5_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu2_5_x1 (Activation)         (None, 8, 32, 192)   0           conv2_5_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_5_x1 (Conv2D)             (None, 8, 32, 128)   24576       relu2_5_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_5_x2_bn (BatchNormalizati (None, 8, 32, 128)   512         conv2_5_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_5_x2_scale (Scale)        (None, 8, 32, 128)   256         conv2_5_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu2_5_x2 (Activation)         (None, 8, 32, 128)   0           conv2_5_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_5_x2 (Conv2D)             (None, 8, 32, 32)    36864       relu2_5_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 8, 32, 224)   0           concatenate_4[0][0]              \n",
            "                                                                 conv2_5_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_6_x1_bn (BatchNormalizati (None, 8, 32, 224)   896         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_6_x1_scale (Scale)        (None, 8, 32, 224)   448         conv2_6_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu2_6_x1 (Activation)         (None, 8, 32, 224)   0           conv2_6_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_6_x1 (Conv2D)             (None, 8, 32, 128)   28672       relu2_6_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_6_x2_bn (BatchNormalizati (None, 8, 32, 128)   512         conv2_6_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_6_x2_scale (Scale)        (None, 8, 32, 128)   256         conv2_6_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu2_6_x2 (Activation)         (None, 8, 32, 128)   0           conv2_6_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_6_x2 (Conv2D)             (None, 8, 32, 32)    36864       relu2_6_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 8, 32, 256)   0           concatenate_5[0][0]              \n",
            "                                                                 conv2_6_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_blk_bn (BatchNormalizatio (None, 8, 32, 256)   1024        concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_blk_scale (Scale)         (None, 8, 32, 256)   512         conv2_blk_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "relu2_blk (Activation)          (None, 8, 32, 256)   0           conv2_blk_scale[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2_blk (Conv2D)              (None, 8, 32, 256)   65536       relu2_blk[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "pool2 (AveragePooling2D)        (None, 4, 32, 256)   0           conv2_blk[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_x1_bn (BatchNormalizati (None, 4, 32, 256)   1024        pool2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_x1_scale (Scale)        (None, 4, 32, 256)   512         conv3_1_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_1_x1 (Activation)         (None, 4, 32, 256)   0           conv3_1_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_x1 (Conv2D)             (None, 4, 32, 128)   32768       relu3_1_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_x2_bn (BatchNormalizati (None, 4, 32, 128)   512         conv3_1_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_x2_scale (Scale)        (None, 4, 32, 128)   256         conv3_1_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_1_x2 (Activation)         (None, 4, 32, 128)   0           conv3_1_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_x2 (Conv2D)             (None, 4, 32, 32)    36864       relu3_1_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 4, 32, 288)   0           pool2[0][0]                      \n",
            "                                                                 conv3_1_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_x1_bn (BatchNormalizati (None, 4, 32, 288)   1152        concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_x1_scale (Scale)        (None, 4, 32, 288)   576         conv3_2_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_2_x1 (Activation)         (None, 4, 32, 288)   0           conv3_2_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_x1 (Conv2D)             (None, 4, 32, 128)   36864       relu3_2_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_x2_bn (BatchNormalizati (None, 4, 32, 128)   512         conv3_2_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_x2_scale (Scale)        (None, 4, 32, 128)   256         conv3_2_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_2_x2 (Activation)         (None, 4, 32, 128)   0           conv3_2_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_x2 (Conv2D)             (None, 4, 32, 32)    36864       relu3_2_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 4, 32, 320)   0           concatenate_7[0][0]              \n",
            "                                                                 conv3_2_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_x1_bn (BatchNormalizati (None, 4, 32, 320)   1280        concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_x1_scale (Scale)        (None, 4, 32, 320)   640         conv3_3_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_3_x1 (Activation)         (None, 4, 32, 320)   0           conv3_3_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_x1 (Conv2D)             (None, 4, 32, 128)   40960       relu3_3_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_x2_bn (BatchNormalizati (None, 4, 32, 128)   512         conv3_3_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_x2_scale (Scale)        (None, 4, 32, 128)   256         conv3_3_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_3_x2 (Activation)         (None, 4, 32, 128)   0           conv3_3_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_x2 (Conv2D)             (None, 4, 32, 32)    36864       relu3_3_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 4, 32, 352)   0           concatenate_8[0][0]              \n",
            "                                                                 conv3_3_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_x1_bn (BatchNormalizati (None, 4, 32, 352)   1408        concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_x1_scale (Scale)        (None, 4, 32, 352)   704         conv3_4_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_4_x1 (Activation)         (None, 4, 32, 352)   0           conv3_4_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_x1 (Conv2D)             (None, 4, 32, 128)   45056       relu3_4_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_x2_bn (BatchNormalizati (None, 4, 32, 128)   512         conv3_4_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_x2_scale (Scale)        (None, 4, 32, 128)   256         conv3_4_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_4_x2 (Activation)         (None, 4, 32, 128)   0           conv3_4_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_x2 (Conv2D)             (None, 4, 32, 32)    36864       relu3_4_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 4, 32, 384)   0           concatenate_9[0][0]              \n",
            "                                                                 conv3_4_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_5_x1_bn (BatchNormalizati (None, 4, 32, 384)   1536        concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_5_x1_scale (Scale)        (None, 4, 32, 384)   768         conv3_5_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_5_x1 (Activation)         (None, 4, 32, 384)   0           conv3_5_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_5_x1 (Conv2D)             (None, 4, 32, 128)   49152       relu3_5_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_5_x2_bn (BatchNormalizati (None, 4, 32, 128)   512         conv3_5_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_5_x2_scale (Scale)        (None, 4, 32, 128)   256         conv3_5_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_5_x2 (Activation)         (None, 4, 32, 128)   0           conv3_5_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_5_x2 (Conv2D)             (None, 4, 32, 32)    36864       relu3_5_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 4, 32, 416)   0           concatenate_10[0][0]             \n",
            "                                                                 conv3_5_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_6_x1_bn (BatchNormalizati (None, 4, 32, 416)   1664        concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_6_x1_scale (Scale)        (None, 4, 32, 416)   832         conv3_6_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_6_x1 (Activation)         (None, 4, 32, 416)   0           conv3_6_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_6_x1 (Conv2D)             (None, 4, 32, 128)   53248       relu3_6_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_6_x2_bn (BatchNormalizati (None, 4, 32, 128)   512         conv3_6_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_6_x2_scale (Scale)        (None, 4, 32, 128)   256         conv3_6_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_6_x2 (Activation)         (None, 4, 32, 128)   0           conv3_6_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_6_x2 (Conv2D)             (None, 4, 32, 32)    36864       relu3_6_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 4, 32, 448)   0           concatenate_11[0][0]             \n",
            "                                                                 conv3_6_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_7_x1_bn (BatchNormalizati (None, 4, 32, 448)   1792        concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_7_x1_scale (Scale)        (None, 4, 32, 448)   896         conv3_7_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_7_x1 (Activation)         (None, 4, 32, 448)   0           conv3_7_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_7_x1 (Conv2D)             (None, 4, 32, 128)   57344       relu3_7_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_7_x2_bn (BatchNormalizati (None, 4, 32, 128)   512         conv3_7_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_7_x2_scale (Scale)        (None, 4, 32, 128)   256         conv3_7_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_7_x2 (Activation)         (None, 4, 32, 128)   0           conv3_7_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_7_x2 (Conv2D)             (None, 4, 32, 32)    36864       relu3_7_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 4, 32, 480)   0           concatenate_12[0][0]             \n",
            "                                                                 conv3_7_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_8_x1_bn (BatchNormalizati (None, 4, 32, 480)   1920        concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_8_x1_scale (Scale)        (None, 4, 32, 480)   960         conv3_8_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_8_x1 (Activation)         (None, 4, 32, 480)   0           conv3_8_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_8_x1 (Conv2D)             (None, 4, 32, 128)   61440       relu3_8_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_8_x2_bn (BatchNormalizati (None, 4, 32, 128)   512         conv3_8_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_8_x2_scale (Scale)        (None, 4, 32, 128)   256         conv3_8_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_8_x2 (Activation)         (None, 4, 32, 128)   0           conv3_8_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_8_x2 (Conv2D)             (None, 4, 32, 32)    36864       relu3_8_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 4, 32, 512)   0           concatenate_13[0][0]             \n",
            "                                                                 conv3_8_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_9_x1_bn (BatchNormalizati (None, 4, 32, 512)   2048        concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_9_x1_scale (Scale)        (None, 4, 32, 512)   1024        conv3_9_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_9_x1 (Activation)         (None, 4, 32, 512)   0           conv3_9_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_9_x1 (Conv2D)             (None, 4, 32, 128)   65536       relu3_9_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_9_x2_bn (BatchNormalizati (None, 4, 32, 128)   512         conv3_9_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_9_x2_scale (Scale)        (None, 4, 32, 128)   256         conv3_9_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_9_x2 (Activation)         (None, 4, 32, 128)   0           conv3_9_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_9_x2 (Conv2D)             (None, 4, 32, 32)    36864       relu3_9_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 4, 32, 544)   0           concatenate_14[0][0]             \n",
            "                                                                 conv3_9_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_10_x1_bn (BatchNormalizat (None, 4, 32, 544)   2176        concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_10_x1_scale (Scale)       (None, 4, 32, 544)   1088        conv3_10_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu3_10_x1 (Activation)        (None, 4, 32, 544)   0           conv3_10_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_10_x1 (Conv2D)            (None, 4, 32, 128)   69632       relu3_10_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3_10_x2_bn (BatchNormalizat (None, 4, 32, 128)   512         conv3_10_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3_10_x2_scale (Scale)       (None, 4, 32, 128)   256         conv3_10_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu3_10_x2 (Activation)        (None, 4, 32, 128)   0           conv3_10_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_10_x2 (Conv2D)            (None, 4, 32, 32)    36864       relu3_10_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 4, 32, 576)   0           concatenate_15[0][0]             \n",
            "                                                                 conv3_10_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3_11_x1_bn (BatchNormalizat (None, 4, 32, 576)   2304        concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_11_x1_scale (Scale)       (None, 4, 32, 576)   1152        conv3_11_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu3_11_x1 (Activation)        (None, 4, 32, 576)   0           conv3_11_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_11_x1 (Conv2D)            (None, 4, 32, 128)   73728       relu3_11_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3_11_x2_bn (BatchNormalizat (None, 4, 32, 128)   512         conv3_11_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3_11_x2_scale (Scale)       (None, 4, 32, 128)   256         conv3_11_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu3_11_x2 (Activation)        (None, 4, 32, 128)   0           conv3_11_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_11_x2 (Conv2D)            (None, 4, 32, 32)    36864       relu3_11_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 4, 32, 608)   0           concatenate_16[0][0]             \n",
            "                                                                 conv3_11_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3_12_x1_bn (BatchNormalizat (None, 4, 32, 608)   2432        concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_12_x1_scale (Scale)       (None, 4, 32, 608)   1216        conv3_12_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu3_12_x1 (Activation)        (None, 4, 32, 608)   0           conv3_12_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_12_x1 (Conv2D)            (None, 4, 32, 128)   77824       relu3_12_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3_12_x2_bn (BatchNormalizat (None, 4, 32, 128)   512         conv3_12_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3_12_x2_scale (Scale)       (None, 4, 32, 128)   256         conv3_12_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu3_12_x2 (Activation)        (None, 4, 32, 128)   0           conv3_12_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_12_x2 (Conv2D)            (None, 4, 32, 32)    36864       relu3_12_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 4, 32, 640)   0           concatenate_17[0][0]             \n",
            "                                                                 conv3_12_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3_blk_bn (BatchNormalizatio (None, 4, 32, 640)   2560        concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_blk_scale (Scale)         (None, 4, 32, 640)   1280        conv3_blk_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "relu3_blk (Activation)          (None, 4, 32, 640)   0           conv3_blk_scale[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv3_blk (Conv2D)              (None, 4, 32, 640)   409600      relu3_blk[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "pool3 (AveragePooling2D)        (None, 2, 32, 640)   0           conv3_blk[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_x1_bn (BatchNormalizati (None, 2, 32, 640)   2560        pool3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_x1_scale (Scale)        (None, 2, 32, 640)   1280        conv4_1_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_1_x1 (Activation)         (None, 2, 32, 640)   0           conv4_1_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_x1 (Conv2D)             (None, 2, 32, 128)   81920       relu4_1_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_x2_bn (BatchNormalizati (None, 2, 32, 128)   512         conv4_1_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_x2_scale (Scale)        (None, 2, 32, 128)   256         conv4_1_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_1_x2 (Activation)         (None, 2, 32, 128)   0           conv4_1_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_x2 (Conv2D)             (None, 2, 32, 32)    36864       relu4_1_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 2, 32, 672)   0           pool3[0][0]                      \n",
            "                                                                 conv4_1_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_x1_bn (BatchNormalizati (None, 2, 32, 672)   2688        concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_x1_scale (Scale)        (None, 2, 32, 672)   1344        conv4_2_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_2_x1 (Activation)         (None, 2, 32, 672)   0           conv4_2_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_x1 (Conv2D)             (None, 2, 32, 128)   86016       relu4_2_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_x2_bn (BatchNormalizati (None, 2, 32, 128)   512         conv4_2_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_x2_scale (Scale)        (None, 2, 32, 128)   256         conv4_2_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_2_x2 (Activation)         (None, 2, 32, 128)   0           conv4_2_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_x2 (Conv2D)             (None, 2, 32, 32)    36864       relu4_2_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 2, 32, 704)   0           concatenate_19[0][0]             \n",
            "                                                                 conv4_2_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_x1_bn (BatchNormalizati (None, 2, 32, 704)   2816        concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_x1_scale (Scale)        (None, 2, 32, 704)   1408        conv4_3_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_3_x1 (Activation)         (None, 2, 32, 704)   0           conv4_3_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_x1 (Conv2D)             (None, 2, 32, 128)   90112       relu4_3_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_x2_bn (BatchNormalizati (None, 2, 32, 128)   512         conv4_3_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_x2_scale (Scale)        (None, 2, 32, 128)   256         conv4_3_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_3_x2 (Activation)         (None, 2, 32, 128)   0           conv4_3_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_x2 (Conv2D)             (None, 2, 32, 32)    36864       relu4_3_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 2, 32, 736)   0           concatenate_20[0][0]             \n",
            "                                                                 conv4_3_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_x1_bn (BatchNormalizati (None, 2, 32, 736)   2944        concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_x1_scale (Scale)        (None, 2, 32, 736)   1472        conv4_4_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_4_x1 (Activation)         (None, 2, 32, 736)   0           conv4_4_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_x1 (Conv2D)             (None, 2, 32, 128)   94208       relu4_4_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_x2_bn (BatchNormalizati (None, 2, 32, 128)   512         conv4_4_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_x2_scale (Scale)        (None, 2, 32, 128)   256         conv4_4_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_4_x2 (Activation)         (None, 2, 32, 128)   0           conv4_4_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_x2 (Conv2D)             (None, 2, 32, 32)    36864       relu4_4_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 2, 32, 768)   0           concatenate_21[0][0]             \n",
            "                                                                 conv4_4_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_x1_bn (BatchNormalizati (None, 2, 32, 768)   3072        concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_x1_scale (Scale)        (None, 2, 32, 768)   1536        conv4_5_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_5_x1 (Activation)         (None, 2, 32, 768)   0           conv4_5_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_x1 (Conv2D)             (None, 2, 32, 128)   98304       relu4_5_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_x2_bn (BatchNormalizati (None, 2, 32, 128)   512         conv4_5_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_x2_scale (Scale)        (None, 2, 32, 128)   256         conv4_5_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_5_x2 (Activation)         (None, 2, 32, 128)   0           conv4_5_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_x2 (Conv2D)             (None, 2, 32, 32)    36864       relu4_5_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 2, 32, 800)   0           concatenate_22[0][0]             \n",
            "                                                                 conv4_5_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_x1_bn (BatchNormalizati (None, 2, 32, 800)   3200        concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_x1_scale (Scale)        (None, 2, 32, 800)   1600        conv4_6_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_6_x1 (Activation)         (None, 2, 32, 800)   0           conv4_6_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_x1 (Conv2D)             (None, 2, 32, 128)   102400      relu4_6_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_x2_bn (BatchNormalizati (None, 2, 32, 128)   512         conv4_6_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_x2_scale (Scale)        (None, 2, 32, 128)   256         conv4_6_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_6_x2 (Activation)         (None, 2, 32, 128)   0           conv4_6_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_x2 (Conv2D)             (None, 2, 32, 32)    36864       relu4_6_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 2, 32, 832)   0           concatenate_23[0][0]             \n",
            "                                                                 conv4_6_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_7_x1_bn (BatchNormalizati (None, 2, 32, 832)   3328        concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_7_x1_scale (Scale)        (None, 2, 32, 832)   1664        conv4_7_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_7_x1 (Activation)         (None, 2, 32, 832)   0           conv4_7_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_7_x1 (Conv2D)             (None, 2, 32, 128)   106496      relu4_7_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_7_x2_bn (BatchNormalizati (None, 2, 32, 128)   512         conv4_7_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_7_x2_scale (Scale)        (None, 2, 32, 128)   256         conv4_7_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_7_x2 (Activation)         (None, 2, 32, 128)   0           conv4_7_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_7_x2 (Conv2D)             (None, 2, 32, 32)    36864       relu4_7_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 2, 32, 864)   0           concatenate_24[0][0]             \n",
            "                                                                 conv4_7_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_8_x1_bn (BatchNormalizati (None, 2, 32, 864)   3456        concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_8_x1_scale (Scale)        (None, 2, 32, 864)   1728        conv4_8_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_8_x1 (Activation)         (None, 2, 32, 864)   0           conv4_8_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_8_x1 (Conv2D)             (None, 2, 32, 128)   110592      relu4_8_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_8_x2_bn (BatchNormalizati (None, 2, 32, 128)   512         conv4_8_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_8_x2_scale (Scale)        (None, 2, 32, 128)   256         conv4_8_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_8_x2 (Activation)         (None, 2, 32, 128)   0           conv4_8_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_8_x2 (Conv2D)             (None, 2, 32, 32)    36864       relu4_8_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_26 (Concatenate)    (None, 2, 32, 896)   0           concatenate_25[0][0]             \n",
            "                                                                 conv4_8_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_9_x1_bn (BatchNormalizati (None, 2, 32, 896)   3584        concatenate_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_9_x1_scale (Scale)        (None, 2, 32, 896)   1792        conv4_9_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_9_x1 (Activation)         (None, 2, 32, 896)   0           conv4_9_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_9_x1 (Conv2D)             (None, 2, 32, 128)   114688      relu4_9_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_9_x2_bn (BatchNormalizati (None, 2, 32, 128)   512         conv4_9_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_9_x2_scale (Scale)        (None, 2, 32, 128)   256         conv4_9_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_9_x2 (Activation)         (None, 2, 32, 128)   0           conv4_9_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_9_x2 (Conv2D)             (None, 2, 32, 32)    36864       relu4_9_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_27 (Concatenate)    (None, 2, 32, 928)   0           concatenate_26[0][0]             \n",
            "                                                                 conv4_9_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_10_x1_bn (BatchNormalizat (None, 2, 32, 928)   3712        concatenate_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_10_x1_scale (Scale)       (None, 2, 32, 928)   1856        conv4_10_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_10_x1 (Activation)        (None, 2, 32, 928)   0           conv4_10_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_10_x1 (Conv2D)            (None, 2, 32, 128)   118784      relu4_10_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_10_x2_bn (BatchNormalizat (None, 2, 32, 128)   512         conv4_10_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_10_x2_scale (Scale)       (None, 2, 32, 128)   256         conv4_10_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_10_x2 (Activation)        (None, 2, 32, 128)   0           conv4_10_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_10_x2 (Conv2D)            (None, 2, 32, 32)    36864       relu4_10_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_28 (Concatenate)    (None, 2, 32, 960)   0           concatenate_27[0][0]             \n",
            "                                                                 conv4_10_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_11_x1_bn (BatchNormalizat (None, 2, 32, 960)   3840        concatenate_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_11_x1_scale (Scale)       (None, 2, 32, 960)   1920        conv4_11_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_11_x1 (Activation)        (None, 2, 32, 960)   0           conv4_11_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_11_x1 (Conv2D)            (None, 2, 32, 128)   122880      relu4_11_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_11_x2_bn (BatchNormalizat (None, 2, 32, 128)   512         conv4_11_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_11_x2_scale (Scale)       (None, 2, 32, 128)   256         conv4_11_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_11_x2 (Activation)        (None, 2, 32, 128)   0           conv4_11_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_11_x2 (Conv2D)            (None, 2, 32, 32)    36864       relu4_11_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_29 (Concatenate)    (None, 2, 32, 992)   0           concatenate_28[0][0]             \n",
            "                                                                 conv4_11_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_12_x1_bn (BatchNormalizat (None, 2, 32, 992)   3968        concatenate_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_12_x1_scale (Scale)       (None, 2, 32, 992)   1984        conv4_12_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_12_x1 (Activation)        (None, 2, 32, 992)   0           conv4_12_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_12_x1 (Conv2D)            (None, 2, 32, 128)   126976      relu4_12_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_12_x2_bn (BatchNormalizat (None, 2, 32, 128)   512         conv4_12_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_12_x2_scale (Scale)       (None, 2, 32, 128)   256         conv4_12_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_12_x2 (Activation)        (None, 2, 32, 128)   0           conv4_12_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_12_x2 (Conv2D)            (None, 2, 32, 32)    36864       relu4_12_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_30 (Concatenate)    (None, 2, 32, 1024)  0           concatenate_29[0][0]             \n",
            "                                                                 conv4_12_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_13_x1_bn (BatchNormalizat (None, 2, 32, 1024)  4096        concatenate_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_13_x1_scale (Scale)       (None, 2, 32, 1024)  2048        conv4_13_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_13_x1 (Activation)        (None, 2, 32, 1024)  0           conv4_13_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_13_x1 (Conv2D)            (None, 2, 32, 128)   131072      relu4_13_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_13_x2_bn (BatchNormalizat (None, 2, 32, 128)   512         conv4_13_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_13_x2_scale (Scale)       (None, 2, 32, 128)   256         conv4_13_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_13_x2 (Activation)        (None, 2, 32, 128)   0           conv4_13_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_13_x2 (Conv2D)            (None, 2, 32, 32)    36864       relu4_13_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_31 (Concatenate)    (None, 2, 32, 1056)  0           concatenate_30[0][0]             \n",
            "                                                                 conv4_13_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_14_x1_bn (BatchNormalizat (None, 2, 32, 1056)  4224        concatenate_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_14_x1_scale (Scale)       (None, 2, 32, 1056)  2112        conv4_14_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_14_x1 (Activation)        (None, 2, 32, 1056)  0           conv4_14_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_14_x1 (Conv2D)            (None, 2, 32, 128)   135168      relu4_14_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_14_x2_bn (BatchNormalizat (None, 2, 32, 128)   512         conv4_14_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_14_x2_scale (Scale)       (None, 2, 32, 128)   256         conv4_14_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_14_x2 (Activation)        (None, 2, 32, 128)   0           conv4_14_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_14_x2 (Conv2D)            (None, 2, 32, 32)    36864       relu4_14_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_32 (Concatenate)    (None, 2, 32, 1088)  0           concatenate_31[0][0]             \n",
            "                                                                 conv4_14_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_15_x1_bn (BatchNormalizat (None, 2, 32, 1088)  4352        concatenate_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_15_x1_scale (Scale)       (None, 2, 32, 1088)  2176        conv4_15_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_15_x1 (Activation)        (None, 2, 32, 1088)  0           conv4_15_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_15_x1 (Conv2D)            (None, 2, 32, 128)   139264      relu4_15_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_15_x2_bn (BatchNormalizat (None, 2, 32, 128)   512         conv4_15_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_15_x2_scale (Scale)       (None, 2, 32, 128)   256         conv4_15_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_15_x2 (Activation)        (None, 2, 32, 128)   0           conv4_15_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_15_x2 (Conv2D)            (None, 2, 32, 32)    36864       relu4_15_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_33 (Concatenate)    (None, 2, 32, 1120)  0           concatenate_32[0][0]             \n",
            "                                                                 conv4_15_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_16_x1_bn (BatchNormalizat (None, 2, 32, 1120)  4480        concatenate_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_16_x1_scale (Scale)       (None, 2, 32, 1120)  2240        conv4_16_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_16_x1 (Activation)        (None, 2, 32, 1120)  0           conv4_16_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_16_x1 (Conv2D)            (None, 2, 32, 128)   143360      relu4_16_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_16_x2_bn (BatchNormalizat (None, 2, 32, 128)   512         conv4_16_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_16_x2_scale (Scale)       (None, 2, 32, 128)   256         conv4_16_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_16_x2 (Activation)        (None, 2, 32, 128)   0           conv4_16_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_16_x2 (Conv2D)            (None, 2, 32, 32)    36864       relu4_16_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_34 (Concatenate)    (None, 2, 32, 1152)  0           concatenate_33[0][0]             \n",
            "                                                                 conv4_16_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_17_x1_bn (BatchNormalizat (None, 2, 32, 1152)  4608        concatenate_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_17_x1_scale (Scale)       (None, 2, 32, 1152)  2304        conv4_17_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_17_x1 (Activation)        (None, 2, 32, 1152)  0           conv4_17_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_17_x1 (Conv2D)            (None, 2, 32, 128)   147456      relu4_17_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_17_x2_bn (BatchNormalizat (None, 2, 32, 128)   512         conv4_17_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_17_x2_scale (Scale)       (None, 2, 32, 128)   256         conv4_17_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_17_x2 (Activation)        (None, 2, 32, 128)   0           conv4_17_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_17_x2 (Conv2D)            (None, 2, 32, 32)    36864       relu4_17_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, 2, 32, 1184)  0           concatenate_34[0][0]             \n",
            "                                                                 conv4_17_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_18_x1_bn (BatchNormalizat (None, 2, 32, 1184)  4736        concatenate_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_18_x1_scale (Scale)       (None, 2, 32, 1184)  2368        conv4_18_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_18_x1 (Activation)        (None, 2, 32, 1184)  0           conv4_18_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_18_x1 (Conv2D)            (None, 2, 32, 128)   151552      relu4_18_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_18_x2_bn (BatchNormalizat (None, 2, 32, 128)   512         conv4_18_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_18_x2_scale (Scale)       (None, 2, 32, 128)   256         conv4_18_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_18_x2 (Activation)        (None, 2, 32, 128)   0           conv4_18_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_18_x2 (Conv2D)            (None, 2, 32, 32)    36864       relu4_18_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_36 (Concatenate)    (None, 2, 32, 1216)  0           concatenate_35[0][0]             \n",
            "                                                                 conv4_18_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_19_x1_bn (BatchNormalizat (None, 2, 32, 1216)  4864        concatenate_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_19_x1_scale (Scale)       (None, 2, 32, 1216)  2432        conv4_19_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_19_x1 (Activation)        (None, 2, 32, 1216)  0           conv4_19_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_19_x1 (Conv2D)            (None, 2, 32, 128)   155648      relu4_19_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_19_x2_bn (BatchNormalizat (None, 2, 32, 128)   512         conv4_19_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_19_x2_scale (Scale)       (None, 2, 32, 128)   256         conv4_19_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_19_x2 (Activation)        (None, 2, 32, 128)   0           conv4_19_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_19_x2 (Conv2D)            (None, 2, 32, 32)    36864       relu4_19_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_37 (Concatenate)    (None, 2, 32, 1248)  0           concatenate_36[0][0]             \n",
            "                                                                 conv4_19_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_20_x1_bn (BatchNormalizat (None, 2, 32, 1248)  4992        concatenate_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_20_x1_scale (Scale)       (None, 2, 32, 1248)  2496        conv4_20_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_20_x1 (Activation)        (None, 2, 32, 1248)  0           conv4_20_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_20_x1 (Conv2D)            (None, 2, 32, 128)   159744      relu4_20_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_20_x2_bn (BatchNormalizat (None, 2, 32, 128)   512         conv4_20_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_20_x2_scale (Scale)       (None, 2, 32, 128)   256         conv4_20_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_20_x2 (Activation)        (None, 2, 32, 128)   0           conv4_20_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_20_x2 (Conv2D)            (None, 2, 32, 32)    36864       relu4_20_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_38 (Concatenate)    (None, 2, 32, 1280)  0           concatenate_37[0][0]             \n",
            "                                                                 conv4_20_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_21_x1_bn (BatchNormalizat (None, 2, 32, 1280)  5120        concatenate_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_21_x1_scale (Scale)       (None, 2, 32, 1280)  2560        conv4_21_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_21_x1 (Activation)        (None, 2, 32, 1280)  0           conv4_21_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_21_x1 (Conv2D)            (None, 2, 32, 128)   163840      relu4_21_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_21_x2_bn (BatchNormalizat (None, 2, 32, 128)   512         conv4_21_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_21_x2_scale (Scale)       (None, 2, 32, 128)   256         conv4_21_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_21_x2 (Activation)        (None, 2, 32, 128)   0           conv4_21_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_21_x2 (Conv2D)            (None, 2, 32, 32)    36864       relu4_21_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_39 (Concatenate)    (None, 2, 32, 1312)  0           concatenate_38[0][0]             \n",
            "                                                                 conv4_21_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_22_x1_bn (BatchNormalizat (None, 2, 32, 1312)  5248        concatenate_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_22_x1_scale (Scale)       (None, 2, 32, 1312)  2624        conv4_22_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_22_x1 (Activation)        (None, 2, 32, 1312)  0           conv4_22_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_22_x1 (Conv2D)            (None, 2, 32, 128)   167936      relu4_22_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_22_x2_bn (BatchNormalizat (None, 2, 32, 128)   512         conv4_22_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_22_x2_scale (Scale)       (None, 2, 32, 128)   256         conv4_22_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_22_x2 (Activation)        (None, 2, 32, 128)   0           conv4_22_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_22_x2 (Conv2D)            (None, 2, 32, 32)    36864       relu4_22_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_40 (Concatenate)    (None, 2, 32, 1344)  0           concatenate_39[0][0]             \n",
            "                                                                 conv4_22_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_23_x1_bn (BatchNormalizat (None, 2, 32, 1344)  5376        concatenate_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_23_x1_scale (Scale)       (None, 2, 32, 1344)  2688        conv4_23_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_23_x1 (Activation)        (None, 2, 32, 1344)  0           conv4_23_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_23_x1 (Conv2D)            (None, 2, 32, 128)   172032      relu4_23_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_23_x2_bn (BatchNormalizat (None, 2, 32, 128)   512         conv4_23_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_23_x2_scale (Scale)       (None, 2, 32, 128)   256         conv4_23_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_23_x2 (Activation)        (None, 2, 32, 128)   0           conv4_23_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_23_x2 (Conv2D)            (None, 2, 32, 32)    36864       relu4_23_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_41 (Concatenate)    (None, 2, 32, 1376)  0           concatenate_40[0][0]             \n",
            "                                                                 conv4_23_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_24_x1_bn (BatchNormalizat (None, 2, 32, 1376)  5504        concatenate_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_24_x1_scale (Scale)       (None, 2, 32, 1376)  2752        conv4_24_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_24_x1 (Activation)        (None, 2, 32, 1376)  0           conv4_24_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_24_x1 (Conv2D)            (None, 2, 32, 128)   176128      relu4_24_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_24_x2_bn (BatchNormalizat (None, 2, 32, 128)   512         conv4_24_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_24_x2_scale (Scale)       (None, 2, 32, 128)   256         conv4_24_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_24_x2 (Activation)        (None, 2, 32, 128)   0           conv4_24_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_24_x2 (Conv2D)            (None, 2, 32, 32)    36864       relu4_24_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_42 (Concatenate)    (None, 2, 32, 1408)  0           concatenate_41[0][0]             \n",
            "                                                                 conv4_24_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_blk_bn (BatchNormalizatio (None, 2, 32, 1408)  5632        concatenate_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_blk_scale (Scale)         (None, 2, 32, 1408)  2816        conv4_blk_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "relu4_blk (Activation)          (None, 2, 32, 1408)  0           conv4_blk_scale[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv4_blk (Conv2D)              (None, 2, 32, 1408)  1982464     relu4_blk[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "pool4 (AveragePooling2D)        (None, 1, 32, 1408)  0           conv4_blk[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_x1_bn (BatchNormalizati (None, 1, 32, 1408)  5632        pool4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_x1_scale (Scale)        (None, 1, 32, 1408)  2816        conv5_1_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_1_x1 (Activation)         (None, 1, 32, 1408)  0           conv5_1_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_x1 (Conv2D)             (None, 1, 32, 128)   180224      relu5_1_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_x2_bn (BatchNormalizati (None, 1, 32, 128)   512         conv5_1_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_x2_scale (Scale)        (None, 1, 32, 128)   256         conv5_1_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_1_x2 (Activation)         (None, 1, 32, 128)   0           conv5_1_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_x2 (Conv2D)             (None, 1, 32, 32)    36864       relu5_1_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_43 (Concatenate)    (None, 1, 32, 1440)  0           pool4[0][0]                      \n",
            "                                                                 conv5_1_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_x1_bn (BatchNormalizati (None, 1, 32, 1440)  5760        concatenate_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_x1_scale (Scale)        (None, 1, 32, 1440)  2880        conv5_2_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_2_x1 (Activation)         (None, 1, 32, 1440)  0           conv5_2_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_x1 (Conv2D)             (None, 1, 32, 128)   184320      relu5_2_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_x2_bn (BatchNormalizati (None, 1, 32, 128)   512         conv5_2_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_x2_scale (Scale)        (None, 1, 32, 128)   256         conv5_2_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_2_x2 (Activation)         (None, 1, 32, 128)   0           conv5_2_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_x2 (Conv2D)             (None, 1, 32, 32)    36864       relu5_2_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_44 (Concatenate)    (None, 1, 32, 1472)  0           concatenate_43[0][0]             \n",
            "                                                                 conv5_2_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_x1_bn (BatchNormalizati (None, 1, 32, 1472)  5888        concatenate_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_x1_scale (Scale)        (None, 1, 32, 1472)  2944        conv5_3_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_3_x1 (Activation)         (None, 1, 32, 1472)  0           conv5_3_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_x1 (Conv2D)             (None, 1, 32, 128)   188416      relu5_3_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_x2_bn (BatchNormalizati (None, 1, 32, 128)   512         conv5_3_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_x2_scale (Scale)        (None, 1, 32, 128)   256         conv5_3_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_3_x2 (Activation)         (None, 1, 32, 128)   0           conv5_3_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_x2 (Conv2D)             (None, 1, 32, 32)    36864       relu5_3_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_45 (Concatenate)    (None, 1, 32, 1504)  0           concatenate_44[0][0]             \n",
            "                                                                 conv5_3_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_4_x1_bn (BatchNormalizati (None, 1, 32, 1504)  6016        concatenate_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_4_x1_scale (Scale)        (None, 1, 32, 1504)  3008        conv5_4_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_4_x1 (Activation)         (None, 1, 32, 1504)  0           conv5_4_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_4_x1 (Conv2D)             (None, 1, 32, 128)   192512      relu5_4_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_4_x2_bn (BatchNormalizati (None, 1, 32, 128)   512         conv5_4_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_4_x2_scale (Scale)        (None, 1, 32, 128)   256         conv5_4_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_4_x2 (Activation)         (None, 1, 32, 128)   0           conv5_4_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_4_x2 (Conv2D)             (None, 1, 32, 32)    36864       relu5_4_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_46 (Concatenate)    (None, 1, 32, 1536)  0           concatenate_45[0][0]             \n",
            "                                                                 conv5_4_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_5_x1_bn (BatchNormalizati (None, 1, 32, 1536)  6144        concatenate_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_5_x1_scale (Scale)        (None, 1, 32, 1536)  3072        conv5_5_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_5_x1 (Activation)         (None, 1, 32, 1536)  0           conv5_5_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_5_x1 (Conv2D)             (None, 1, 32, 128)   196608      relu5_5_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_5_x2_bn (BatchNormalizati (None, 1, 32, 128)   512         conv5_5_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_5_x2_scale (Scale)        (None, 1, 32, 128)   256         conv5_5_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_5_x2 (Activation)         (None, 1, 32, 128)   0           conv5_5_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_5_x2 (Conv2D)             (None, 1, 32, 32)    36864       relu5_5_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_47 (Concatenate)    (None, 1, 32, 1568)  0           concatenate_46[0][0]             \n",
            "                                                                 conv5_5_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_6_x1_bn (BatchNormalizati (None, 1, 32, 1568)  6272        concatenate_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_6_x1_scale (Scale)        (None, 1, 32, 1568)  3136        conv5_6_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_6_x1 (Activation)         (None, 1, 32, 1568)  0           conv5_6_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_6_x1 (Conv2D)             (None, 1, 32, 128)   200704      relu5_6_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_6_x2_bn (BatchNormalizati (None, 1, 32, 128)   512         conv5_6_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_6_x2_scale (Scale)        (None, 1, 32, 128)   256         conv5_6_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_6_x2 (Activation)         (None, 1, 32, 128)   0           conv5_6_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_6_x2 (Conv2D)             (None, 1, 32, 32)    36864       relu5_6_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_48 (Concatenate)    (None, 1, 32, 1600)  0           concatenate_47[0][0]             \n",
            "                                                                 conv5_6_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_7_x1_bn (BatchNormalizati (None, 1, 32, 1600)  6400        concatenate_48[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_7_x1_scale (Scale)        (None, 1, 32, 1600)  3200        conv5_7_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_7_x1 (Activation)         (None, 1, 32, 1600)  0           conv5_7_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_7_x1 (Conv2D)             (None, 1, 32, 128)   204800      relu5_7_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_7_x2_bn (BatchNormalizati (None, 1, 32, 128)   512         conv5_7_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_7_x2_scale (Scale)        (None, 1, 32, 128)   256         conv5_7_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_7_x2 (Activation)         (None, 1, 32, 128)   0           conv5_7_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_7_x2 (Conv2D)             (None, 1, 32, 32)    36864       relu5_7_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_49 (Concatenate)    (None, 1, 32, 1632)  0           concatenate_48[0][0]             \n",
            "                                                                 conv5_7_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_8_x1_bn (BatchNormalizati (None, 1, 32, 1632)  6528        concatenate_49[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_8_x1_scale (Scale)        (None, 1, 32, 1632)  3264        conv5_8_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_8_x1 (Activation)         (None, 1, 32, 1632)  0           conv5_8_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_8_x1 (Conv2D)             (None, 1, 32, 128)   208896      relu5_8_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_8_x2_bn (BatchNormalizati (None, 1, 32, 128)   512         conv5_8_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_8_x2_scale (Scale)        (None, 1, 32, 128)   256         conv5_8_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_8_x2 (Activation)         (None, 1, 32, 128)   0           conv5_8_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_8_x2 (Conv2D)             (None, 1, 32, 32)    36864       relu5_8_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_50 (Concatenate)    (None, 1, 32, 1664)  0           concatenate_49[0][0]             \n",
            "                                                                 conv5_8_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_9_x1_bn (BatchNormalizati (None, 1, 32, 1664)  6656        concatenate_50[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_9_x1_scale (Scale)        (None, 1, 32, 1664)  3328        conv5_9_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_9_x1 (Activation)         (None, 1, 32, 1664)  0           conv5_9_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_9_x1 (Conv2D)             (None, 1, 32, 128)   212992      relu5_9_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_9_x2_bn (BatchNormalizati (None, 1, 32, 128)   512         conv5_9_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_9_x2_scale (Scale)        (None, 1, 32, 128)   256         conv5_9_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_9_x2 (Activation)         (None, 1, 32, 128)   0           conv5_9_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_9_x2 (Conv2D)             (None, 1, 32, 32)    36864       relu5_9_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_51 (Concatenate)    (None, 1, 32, 1696)  0           concatenate_50[0][0]             \n",
            "                                                                 conv5_9_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_10_x1_bn (BatchNormalizat (None, 1, 32, 1696)  6784        concatenate_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_10_x1_scale (Scale)       (None, 1, 32, 1696)  3392        conv5_10_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu5_10_x1 (Activation)        (None, 1, 32, 1696)  0           conv5_10_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_10_x1 (Conv2D)            (None, 1, 32, 128)   217088      relu5_10_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_10_x2_bn (BatchNormalizat (None, 1, 32, 128)   512         conv5_10_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_10_x2_scale (Scale)       (None, 1, 32, 128)   256         conv5_10_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu5_10_x2 (Activation)        (None, 1, 32, 128)   0           conv5_10_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_10_x2 (Conv2D)            (None, 1, 32, 32)    36864       relu5_10_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_52 (Concatenate)    (None, 1, 32, 1728)  0           concatenate_51[0][0]             \n",
            "                                                                 conv5_10_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_11_x1_bn (BatchNormalizat (None, 1, 32, 1728)  6912        concatenate_52[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_11_x1_scale (Scale)       (None, 1, 32, 1728)  3456        conv5_11_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu5_11_x1 (Activation)        (None, 1, 32, 1728)  0           conv5_11_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_11_x1 (Conv2D)            (None, 1, 32, 128)   221184      relu5_11_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_11_x2_bn (BatchNormalizat (None, 1, 32, 128)   512         conv5_11_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_11_x2_scale (Scale)       (None, 1, 32, 128)   256         conv5_11_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu5_11_x2 (Activation)        (None, 1, 32, 128)   0           conv5_11_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_11_x2 (Conv2D)            (None, 1, 32, 32)    36864       relu5_11_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_53 (Concatenate)    (None, 1, 32, 1760)  0           concatenate_52[0][0]             \n",
            "                                                                 conv5_11_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_12_x1_bn (BatchNormalizat (None, 1, 32, 1760)  7040        concatenate_53[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_12_x1_scale (Scale)       (None, 1, 32, 1760)  3520        conv5_12_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu5_12_x1 (Activation)        (None, 1, 32, 1760)  0           conv5_12_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_12_x1 (Conv2D)            (None, 1, 32, 128)   225280      relu5_12_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_12_x2_bn (BatchNormalizat (None, 1, 32, 128)   512         conv5_12_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_12_x2_scale (Scale)       (None, 1, 32, 128)   256         conv5_12_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu5_12_x2 (Activation)        (None, 1, 32, 128)   0           conv5_12_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_12_x2 (Conv2D)            (None, 1, 32, 32)    36864       relu5_12_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_54 (Concatenate)    (None, 1, 32, 1792)  0           concatenate_53[0][0]             \n",
            "                                                                 conv5_12_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_13_x1_bn (BatchNormalizat (None, 1, 32, 1792)  7168        concatenate_54[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_13_x1_scale (Scale)       (None, 1, 32, 1792)  3584        conv5_13_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu5_13_x1 (Activation)        (None, 1, 32, 1792)  0           conv5_13_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_13_x1 (Conv2D)            (None, 1, 32, 128)   229376      relu5_13_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_13_x2_bn (BatchNormalizat (None, 1, 32, 128)   512         conv5_13_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_13_x2_scale (Scale)       (None, 1, 32, 128)   256         conv5_13_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu5_13_x2 (Activation)        (None, 1, 32, 128)   0           conv5_13_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_13_x2 (Conv2D)            (None, 1, 32, 32)    36864       relu5_13_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_55 (Concatenate)    (None, 1, 32, 1824)  0           concatenate_54[0][0]             \n",
            "                                                                 conv5_13_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_14_x1_bn (BatchNormalizat (None, 1, 32, 1824)  7296        concatenate_55[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_14_x1_scale (Scale)       (None, 1, 32, 1824)  3648        conv5_14_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu5_14_x1 (Activation)        (None, 1, 32, 1824)  0           conv5_14_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_14_x1 (Conv2D)            (None, 1, 32, 128)   233472      relu5_14_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_14_x2_bn (BatchNormalizat (None, 1, 32, 128)   512         conv5_14_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_14_x2_scale (Scale)       (None, 1, 32, 128)   256         conv5_14_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu5_14_x2 (Activation)        (None, 1, 32, 128)   0           conv5_14_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_14_x2 (Conv2D)            (None, 1, 32, 32)    36864       relu5_14_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_56 (Concatenate)    (None, 1, 32, 1856)  0           concatenate_55[0][0]             \n",
            "                                                                 conv5_14_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_15_x1_bn (BatchNormalizat (None, 1, 32, 1856)  7424        concatenate_56[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_15_x1_scale (Scale)       (None, 1, 32, 1856)  3712        conv5_15_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu5_15_x1 (Activation)        (None, 1, 32, 1856)  0           conv5_15_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_15_x1 (Conv2D)            (None, 1, 32, 128)   237568      relu5_15_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_15_x2_bn (BatchNormalizat (None, 1, 32, 128)   512         conv5_15_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_15_x2_scale (Scale)       (None, 1, 32, 128)   256         conv5_15_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu5_15_x2 (Activation)        (None, 1, 32, 128)   0           conv5_15_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_15_x2 (Conv2D)            (None, 1, 32, 32)    36864       relu5_15_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_57 (Concatenate)    (None, 1, 32, 1888)  0           concatenate_56[0][0]             \n",
            "                                                                 conv5_15_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_16_x1_bn (BatchNormalizat (None, 1, 32, 1888)  7552        concatenate_57[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_16_x1_scale (Scale)       (None, 1, 32, 1888)  3776        conv5_16_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu5_16_x1 (Activation)        (None, 1, 32, 1888)  0           conv5_16_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_16_x1 (Conv2D)            (None, 1, 32, 128)   241664      relu5_16_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_16_x2_bn (BatchNormalizat (None, 1, 32, 128)   512         conv5_16_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_16_x2_scale (Scale)       (None, 1, 32, 128)   256         conv5_16_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu5_16_x2 (Activation)        (None, 1, 32, 128)   0           conv5_16_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_16_x2 (Conv2D)            (None, 1, 32, 32)    36864       relu5_16_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_58 (Concatenate)    (None, 1, 32, 1920)  0           concatenate_57[0][0]             \n",
            "                                                                 conv5_16_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_blk_bn (BatchNormalizatio (None, 1, 32, 1920)  7680        concatenate_58[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_blk_scale (Scale)         (None, 1, 32, 1920)  3840        conv5_blk_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "relu5_blk (Activation)          (None, 1, 32, 1920)  0           conv5_blk_scale[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 32, 1920)     0           relu5_blk[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bi_gru1 (Bidirectional)         (None, 32, 1024)     7477248     reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bi_gru2 (Bidirectional)         (None, 32, 1024)     4724736     bi_gru1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense1 (Dense)                  (None, 32, 301)      308525      bi_gru2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 24,765,101\n",
            "Trainable params: 24,628,461\n",
            "Non-trainable params: 136,640\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Km2GyDuBI1sv"
      },
      "source": [
        "#This code cell holds the DenseNet model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cUvLNBIARz2"
      },
      "source": [
        "INPUT_SHAPE = (32, 128, 1) # (img_rows, img_cols, img_channel)\n",
        "\n",
        "REG = 0.0001\n",
        "from keras.layers import LSTM, Reshape, Input, Conv2D, MaxPool2D, Bidirectional\n",
        "from keras.applications import VGG16, ResNet50, MobileNet, Xception, DenseNet121, ResNet152V2\n",
        "\n",
        "def make_model():\n",
        "  #base_model = ResNet50(include_top=False, weights=None, input_tensor=None, input_shape=INPUT_SHAPE)\n",
        "  #base_model = ResNet152V2(include_top=False, weights=None, input_tensor=None, input_shape=INPUT_SHAPE)\n",
        "  base_model = DenseNet121(include_top=False, weights=None, input_tensor=None, input_shape=INPUT_SHAPE)\n",
        "\n",
        "  #model = Model(base_model.inputs, base_model.outputs)\n",
        "  base_model.summary()\n",
        "  # x = base_model.layers[51].output\n",
        "  # model = Model(base_model.inputs, x)\n",
        "  # model.summary()\n",
        "\n",
        "make_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2HoHROs09pk"
      },
      "source": [
        "INPUT_SHAPE = (32, 128, 1) # (img_rows, img_cols, img_channel)\n",
        "\n",
        "REG = 0.0001\n",
        "from keras.layers import LSTM, Reshape, Input, Conv2D, MaxPool2D, Bidirectional\n",
        "from keras.applications import VGG16, ResNet50, MobileNet, Xception, DenseNet121, ResNet152V2\n",
        "\n",
        "def make_model():\n",
        "  #base_model = ResNet50(include_top=False, weights=None, input_tensor=None, input_shape=INPUT_SHAPE)\n",
        "  #base_model = ResNet152V2(include_top=False, weights=None, input_tensor=None, input_shape=INPUT_SHAPE)\n",
        "  base_model = DenseNet121(include_top=False, weights=None, input_tensor=None, input_shape=INPUT_SHAPE)\n",
        "\n",
        "  #model = Model(base_model.inputs, base_model.outputs)\n",
        "  #model.summary()\n",
        "  #x = base_model.layers[60].output\n",
        "  x = base_model.output\n",
        "  x =  Reshape((32, 240), name=\"reshape\") (x)\n",
        "\n",
        "  #squeezed = Lambda(lambda x: K.squeeze(x, 1), name='squeeze')(reshaped)\n",
        "\n",
        "  # bidirectional LSTM layers with units=128\n",
        "  #blstm_1 = Bidirectional(LSTM(512, return_sequences=True, dropout = 0.2,\n",
        "  #                kernel_regularizer=regularizers.l2(REG)))(squeezed)\n",
        "  gru_1 =  Bidirectional(GRU(512, return_sequences=True, dropout = 0.4,\n",
        "                  kernel_regularizer=regularizers.l2(REG)),\n",
        "                  name='bi_gru1')(x)\n",
        "  #x = Dropout(0.5)(gru_1)\n",
        "  #blstm_2 = Bidirectional(LSTM(512, return_sequences=True, dropout = 0.2,\n",
        "  #                kernel_regularizer=regularizers.l2(REG)))(blstm_1)\n",
        "  gru_2 =  Bidirectional(GRU(512, return_sequences=True, dropout = 0.4,\n",
        "                  kernel_regularizer=regularizers.l2(REG)),\n",
        "                  name='bi_gru2')(gru_1)\n",
        "\n",
        "  #x = Dropout(0.5)(gru_2)\n",
        "\n",
        "  outputs = Dense(len(char_list)+1, activation = 'softmax',\n",
        "                  kernel_regularizer=regularizers.l2(REG),\n",
        "                  name='dense1')(gru_2)\n",
        "  #x = Dropout(0.25)(gru_2)\n",
        "  # model to be used at test time\n",
        "  model = Model(base_model.inputs, outputs)\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "\n",
        "my_model = make_model()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snAwzMnqJhD1"
      },
      "source": [
        "#This code call holds the VGG_19 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TYg_ZFYmy1Q",
        "outputId": "efa41478-e69f-480e-c759-6eb5e90a25b4"
      },
      "source": [
        "INPUT_SHAPE = (64, 256, 1) # (img_rows, img_cols, img_channel)\n",
        "\n",
        "REG = 0.0001\n",
        "from keras.layers import LSTM, Reshape, Input, Conv2D, MaxPool2D, Bidirectional\n",
        "from keras.applications import VGG19, ResNet50, MobileNet, Xception, DenseNet201, ResNet152V2\n",
        "\n",
        "def make_model():\n",
        "  base_model = VGG19(include_top=False, weights=None, input_tensor=None, input_shape=INPUT_SHAPE)\n",
        "  x = base_model.layers[0].output\n",
        "  x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(x)\n",
        "  x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
        "  x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
        "\n",
        "  # Block 2\n",
        "  x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
        "  x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
        "  x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
        "\n",
        "  # Block 3\n",
        "  x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
        "  x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
        "  x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
        "  x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv4')(x)\n",
        "  x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
        "\n",
        "  # Block 4\n",
        "  x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
        "  x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
        "  x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
        "  x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv4')(x)\n",
        "  x = MaxPooling2D((2, 1), strides=(2, 1), name='block4_pool')(x)\n",
        "\n",
        "  # Block 5\n",
        "  x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
        "  x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
        "  x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
        "  x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv4')(x)\n",
        "  x = MaxPooling2D((2, 1), strides=(2, 1), name='block5_pool')(x)\n",
        "  reshaped =  Reshape((32, 1024), name=\"reshape\") (x)\n",
        "\n",
        "  gru_1 =  Bidirectional(GRU(512, return_sequences=True, reset_after=True,\n",
        "                  kernel_regularizer=regularizers.l2(REG)),\n",
        "                  name='bi_gru1')(reshaped)\n",
        "  x = Dropout(0.5)(gru_1)\n",
        "    #blstm_2 = Bidirectional(LSTM(512, return_sequences=True, dropout = 0.2,\n",
        "    #                kernel_regularizer=regularizers.l2(REG)))(blstm_1)\n",
        "  gru_2 =  Bidirectional(GRU(512, return_sequences=True, reset_after=True,\n",
        "                  kernel_regularizer=regularizers.l2(REG)),\n",
        "                  name='bi_gru2')(gru_1)\n",
        "\n",
        "  x = Dropout(0.5)(gru_2)\n",
        "\n",
        "  outputs = Dense(len(char_list)+1, activation = 'softmax',\n",
        "                  kernel_regularizer=regularizers.l2(REG),\n",
        "                  name='dense1')(gru_2)\n",
        "  model = Model(base_model.inputs, outputs)\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "\n",
        "  #x = base_model.layers[-6].output\n",
        "\n",
        "my_model = make_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 64, 256, 1)        0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 64, 256, 64)       640       \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 64, 256, 64)       36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 32, 128, 64)       0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 32, 128, 128)      73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 32, 128, 128)      147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 16, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 16, 64, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 16, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 16, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 16, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 8, 32, 256)        0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 8, 32, 512)        1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 8, 32, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 8, 32, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, 8, 32, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 4, 32, 512)        0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 4, 32, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 4, 32, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 4, 32, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv4 (Conv2D)        (None, 4, 32, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 2, 32, 512)        0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 32, 1024)          0         \n",
            "_________________________________________________________________\n",
            "bi_gru1 (Bidirectional)      (None, 32, 1024)          4724736   \n",
            "_________________________________________________________________\n",
            "bi_gru2 (Bidirectional)      (None, 32, 1024)          4724736   \n",
            "_________________________________________________________________\n",
            "dense1 (Dense)               (None, 32, 301)           308525    \n",
            "=================================================================\n",
            "Total params: 29,781,229\n",
            "Trainable params: 29,781,229\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxToofGVJBzS"
      },
      "source": [
        "INPUT_SHAPE = (32, 128, 1) # (img_rows, img_cols, img_channel)\n",
        "\n",
        "REG = 0.0001\n",
        "from keras.layers import LSTM, Reshape, Input, Conv2D, MaxPool2D, Bidirectional\n",
        "from keras.applications import VGG19, ResNet50, MobileNet, Xception, DenseNet201, ResNet152V2\n",
        "\n",
        "def make_model():\n",
        "  #base_model = ResNet50(include_top=False, weights=None, input_tensor=None, input_shape=INPUT_SHAPE)\n",
        "  #base_model = ResNet152V2(include_top=False, weights=None, input_tensor=None, input_shape=INPUT_SHAPE)\n",
        "  base_model = VGG16(include_top=False, weights=None, input_tensor=None, input_shape=INPUT_SHAPE)\n",
        "\n",
        "  #model = Model(base_model.inputs, base_model.outputs)\n",
        "  #model.summary()\n",
        "  #x = base_model.layers[60].output\n",
        "  x = base_model.layers[-6].output\n",
        "  x =  Reshape((64, 512), name=\"reshape\") (x)\n",
        "\n",
        "  #squeezed = Lambda(lambda x: K.squeeze(x, 1), name='squeeze')(reshaped)\n",
        "\n",
        "  # bidirectional LSTM layers with units=128\n",
        "  #blstm_1 = Bidirectional(LSTM(512, return_sequences=True, dropout = 0.2,\n",
        "  #                kernel_regularizer=regularizers.l2(REG)))(squeezed)\n",
        "  gru_1 =  Bidirectional(GRU(512, return_sequences=True, dropout = 0.4,\n",
        "                  kernel_regularizer=regularizers.l2(REG)),\n",
        "                  name='bi_gru1')(x)\n",
        "  #x = Dropout(0.5)(gru_1)\n",
        "  #blstm_2 = Bidirectional(LSTM(512, return_sequences=True, dropout = 0.2,\n",
        "  #                kernel_regularizer=regularizers.l2(REG)))(blstm_1)\n",
        "  gru_2 =  Bidirectional(GRU(512, return_sequences=True, dropout = 0.4,\n",
        "                  kernel_regularizer=regularizers.l2(REG)),\n",
        "                  name='bi_gru2')(gru_1)\n",
        "\n",
        "  #x = Dropout(0.5)(gru_2)\n",
        "\n",
        "  outputs = Dense(len(char_list)+1, activation = 'softmax',\n",
        "                  kernel_regularizer=regularizers.l2(REG),\n",
        "                  name='dense1')(gru_2)\n",
        "  #x = Dropout(0.25)(gru_2)\n",
        "  # model to be used at test time\n",
        "  model = Model(base_model.inputs, outputs)\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "\n",
        "my_model = make_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aIAc2rAsxna"
      },
      "source": [
        "keras.utils.vis_utils.plot_model(model, show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DioCv0ZB1Agg"
      },
      "source": [
        "###THIS PART IS USED TO DEVELOP THE ARCHITECTURE OF THE PRE-TRAINED MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHZFjHXH07iW"
      },
      "source": [
        "from keras.models import load_model\n",
        "loaded_model= load_model('/content/drive/Shared drives/PolypDB/models/<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7efe461f6940>o-15000r-200e-100000t-20000v.hdf5'\n",
        ",  custom_objects={'<lambda>': lambda y_true, y_pred: y_pred} )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "go15uiwT4IaI"
      },
      "source": [
        "loaded_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CpFn_SM8Rjo"
      },
      "source": [
        "#remove the head of the pre-trained network before the 23rd layer and add new head\n",
        "REG = 0.0001\n",
        "l1=loaded_model.layers[61].output\n",
        "l1=Dense(len(char_list)+1, kernel_regularizer=regularizers.l2(REG), name='outputs')(l1)\n",
        "l1=Activation('softmax', name='softmax')(l1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "0-ppfcEgvEay",
        "outputId": "ab96ef46-d8a9-4c62-d837-71c4baac37ea"
      },
      "source": [
        "loaded_model.layers[60]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.wrappers.Bidirectional at 0x7f63301bf0f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T8IYWCn5m-7"
      },
      "source": [
        "for layer in loaded_model.layers[:-38]:\n",
        "    #print(layer)\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0ymdIUi9bjN"
      },
      "source": [
        "new_model= Model(inputs=loaded_model.input[0], outputs=l1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka2bVCsf9qms"
      },
      "source": [
        "LR_START = 0.0001\n",
        "LR_MAX = 0.0005\n",
        "LR_MIN = 0.0001\n",
        "LR_RAMPUP_EPOCHS = 5\n",
        "LR_SUSTAIN_EPOCHS = 0\n",
        "LR_EXP_DECAY = .9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTC_6r0bNJkn"
      },
      "source": [
        "import tensorflow as tf\n",
        "def lrfn(epoch):\n",
        "    if epoch < LR_RAMPUP_EPOCHS:\n",
        "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
        "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
        "        lr = LR_MAX\n",
        "    else:\n",
        "        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n",
        "    return lr\n",
        "\n",
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGI_043qfGAa"
      },
      "source": [
        "batch_size = 8\n",
        "epochs = 40\n",
        "e = str(epochs)\n",
        "#optimizer_name = 'adadelta'\n",
        "#opt =RMSprop(learning_rate=0.0001)\n",
        "opt = Adam(learning_rate=0.0001)\n",
        "#uncomment this two lines for the pre-trained model\n",
        "inputs = my_model.input\n",
        "outputs = my_model.output\n",
        "#inputs = new_model.input\n",
        "#outputs = new_model.output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fB8I5how47Jh"
      },
      "source": [
        "the_labels = Input(name='the_labels', shape=[max_label_len], dtype='float32')\n",
        "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
        "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
        "\n",
        "def ctc_lambda_func(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        "\n",
        "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
        "\n",
        "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([outputs, the_labels, input_length, label_length])\n",
        "\n",
        "#model to be used at training time\n",
        "model = Model(inputs=[inputs, the_labels, input_length, label_length], outputs=loss_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxx7F384gyHN"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDvELng282Fe"
      },
      "source": [
        "#grid search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6wCgjkC_85K"
      },
      "source": [
        "# Use scikit-learn to grid search the batch size and epochs\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(optimizer='adam'):\n",
        "\t# create model\n",
        "\tmodel = Model(inputs=[inputs, the_labels, input_length, label_length], outputs=loss_out)\n",
        "\t#model = Model(inputs=[inputs, the_labels, input_length, label_length], outputs=loss_out)\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=optimizer, metrics=['accuracy'])\n",
        "\treturn model\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "np.random.seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "3sKuxY82xoL-",
        "outputId": "05b9eeeb-d2d3-4417-a953-baebd4bc02aa"
      },
      "source": [
        "# split into input (X) and output (Y) variables\n",
        "train_data = ([X_train, y_train, train_input_length, train_label_length], [np.zeros(len(X_train))])\n",
        "X = [X_train, y_train, train_input_length, train_label_length]\n",
        "Y = np.zeros(len(X_train))\n",
        "len(X_train), len(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7496, 7496)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy0ZLHg4yFi8"
      },
      "source": [
        "# create model\n",
        "clf = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
        "# define the grid search parameters\n",
        "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
        "param_grid = dict(optimizer=optimizer)\n",
        "grid = GridSearchCV(estimator=clf, param_grid=param_grid, n_jobs=1, cv=3)\n",
        "grid_result = grid.fit(X, Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9LJ6KucfOqJ"
      },
      "source": [
        "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=opt, metrics=['accuracy'])\n",
        "#drive/My Drive/Colab Notebooks/Handwritten-Text-Recognition/\n",
        "filepath=\"/content/drive/Shared drives/PolypDB/AWR_Test 7/models/{}o-{}r-{}e-{}t-{}v.hdf5\".format(opt,\n",
        "                                                                        str(RECORDS_COUNT),\n",
        "                                                                        str(epochs),\n",
        "                                                                        str(X_train.shape[0]),\n",
        "                                                                        str(X_val.shape[0]))\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "callbacks_list = [checkpoint]\n",
        "#callbacks_list=[lr_callback]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDFikYPxmj7k",
        "outputId": "291ffcc0-689c-40eb-8bfc-1ed2758a882c"
      },
      "source": [
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta = 0.1,\n",
        "    patience = 2)\n",
        "\n",
        "history = model.fit(x=[X_train, y_train, train_input_length, train_label_length],\n",
        "                    y=np.zeros(len(X_train)),\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=([X_val, y_val, valid_input_length, valid_label_length], [np.zeros(len(X_val))]),\n",
        "                    verbose=2,\n",
        "                    callbacks=callbacks_list\n",
        "                    )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 29224 samples, validate on 3248 samples\n",
            "Epoch 1/40\n",
            " - 718s - loss: 17.1494 - accuracy: 3.4218e-05 - val_loss: 16.1575 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 16.15752, saving model to /content/drive/Shared drives/PolypDB/AWR_Test 7/models/<keras.optimizers.Adam object at 0x7f3c716e6850>o-8486r-40e-29224t-3248v.hdf5\n",
            "Epoch 2/40\n",
            " - 705s - loss: 16.0588 - accuracy: 0.0037 - val_loss: 15.6170 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00002: val_loss improved from 16.15752 to 15.61697, saving model to /content/drive/Shared drives/PolypDB/AWR_Test 7/models/<keras.optimizers.Adam object at 0x7f3c716e6850>o-8486r-40e-29224t-3248v.hdf5\n",
            "Epoch 3/40\n",
            " - 705s - loss: 15.2891 - accuracy: 0.0256 - val_loss: 14.6148 - val_accuracy: 0.0403\n",
            "\n",
            "Epoch 00003: val_loss improved from 15.61697 to 14.61477, saving model to /content/drive/Shared drives/PolypDB/AWR_Test 7/models/<keras.optimizers.Adam object at 0x7f3c716e6850>o-8486r-40e-29224t-3248v.hdf5\n",
            "Epoch 4/40\n",
            " - 702s - loss: 14.1685 - accuracy: 0.0543 - val_loss: 13.5345 - val_accuracy: 0.0690\n",
            "\n",
            "Epoch 00004: val_loss improved from 14.61477 to 13.53453, saving model to /content/drive/Shared drives/PolypDB/AWR_Test 7/models/<keras.optimizers.Adam object at 0x7f3c716e6850>o-8486r-40e-29224t-3248v.hdf5\n",
            "Epoch 5/40\n",
            " - 707s - loss: 13.0761 - accuracy: 0.0727 - val_loss: 12.3478 - val_accuracy: 0.0877\n",
            "\n",
            "Epoch 00005: val_loss improved from 13.53453 to 12.34778, saving model to /content/drive/Shared drives/PolypDB/AWR_Test 7/models/<keras.optimizers.Adam object at 0x7f3c716e6850>o-8486r-40e-29224t-3248v.hdf5\n",
            "Epoch 6/40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mr21XvBukBYL",
        "outputId": "ec627829-5eb3-47d6-aa0e-3b65c64e9b77"
      },
      "source": [
        "print(valid_input_length[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_Epc3XBfRHQ"
      },
      "source": [
        "# Train and validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DsiGXJbfZXY"
      },
      "source": [
        "# predict outputs on validation images\n",
        "prediction = my_model.predict(X_val[2:20])\n",
        "\n",
        "# use CTC decoder\n",
        "decoded = K.ctc_decode(prediction,\n",
        "                       input_length=np.ones(prediction.shape[0]) * prediction.shape[1],\n",
        "                       greedy=True)[0][0]\n",
        "\n",
        "out = K.get_value(decoded)\n",
        "\n",
        "# see the results\n",
        "for i, x in enumerate(out):\n",
        "    print(\"original_text =  \", valid_original_text[2+i])\n",
        "    print(\"predicted text = \", end = '')\n",
        "    for p in x:\n",
        "        if int(p) != -1:\n",
        "            print(char_list[int(p)], end = '')\n",
        "    plt.imshow(X_val[2+i].reshape(32,128), cmap=plt.cm.gray)\n",
        "    plt.show()\n",
        "    print('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaYmgiHRfvfu"
      },
      "source": [
        "# plot accuracy and loss\n",
        "def plotgraph(epochs, acc, val_acc):\n",
        "    # Plot training & validation accuracy values\n",
        "    plt.plot(epochs, acc, 'b')\n",
        "    plt.plot(epochs, val_acc, 'r')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Val'], loc='upper left')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gO9QRkT4ga6Z"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1,len(loss)+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qy0kAaHggdv6"
      },
      "source": [
        "plt.title('Model loss')\n",
        "plotgraph(epochs, loss, val_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHjAY0CrggpN"
      },
      "source": [
        "plt.title('Model accuracy')\n",
        "plotgraph(epochs, acc, val_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhN0HHdPgjmk"
      },
      "source": [
        "# get best model index\n",
        "minimum_val_loss = np.min(history.history['val_loss'])\n",
        "best_model_index = np.where(history.history['val_loss'] == minimum_val_loss)[0][0]\n",
        "\n",
        "best_loss = str(history.history['loss'][best_model_index])\n",
        "best_acc = str(history.history['accuracy'][best_model_index])\n",
        "best_val_loss = str(history.history['val_loss'][best_model_index])\n",
        "best_val_acc = str(history.history['val_accuracy'][best_model_index])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPAGVF91gB6U"
      },
      "source": [
        "# Test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIPJ3W3w4BZ3"
      },
      "source": [
        "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl2NMjXM4ls1"
      },
      "source": [
        "!pip install keras==2.3.1\n",
        "!pip install tensorflow==2.1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsCoPuEbmSdh"
      },
      "source": [
        "from keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_jyhC_PgfvH",
        "outputId": "eae031a4-3400-430c-f2e1-fc8a9c17de63"
      },
      "source": [
        "#model.load_weights(\"/content/drive/Shared drives/PolypDB/AWR_Test 7/models/Best custom with 32x128 aug latest.hdf5\")\n",
        "model.load_weights(\"/content/drive/Shared drives/PolypDB/AWR_Test 7/models/Best VGG19 with 64x256 aug latest one one.hdf5\")\n",
        "# train_data = ([X_train, y_train, train_input_length, train_label_length], [np.zeros(len(X_train))])\n",
        "# valid_data = ([X_val, y_val, valid_input_length, valid_label_length], [np.zeros(len(X_val))])\n",
        "test_data = ([X_test, y_test, test_input_length, test_label_length], [np.zeros(len(X_test))])\n",
        "# scores1 = model.evaluate(x=train_data[0], y=train_data[1], verbose=1)\n",
        "# scores2 = model.evaluate(x=valid_data[0], y=valid_data[1], verbose=1)\n",
        "# scores3 = model.evaluate(x=test_data[0], y=test_data[1], verbose=1)\n",
        "\n",
        "# scores1 = model.evaluate([X_train, y_train, train_input_length, train_label_length], [np.zeros(len(X_train))], verbose=1)\n",
        "# scores2 = model.evaluate([X_val, y_val, valid_input_length, valid_label_length],[np.zeros(len(X_val))], verbose=1)\n",
        "scores3 = model.evaluate([X_test, y_test, test_input_length, test_label_length], [np.zeros(len(X_test))], verbose=1)\n",
        "\n",
        "# print(\"Train Accuracy = {:.2%}\". format(scores1[1]))\n",
        "# print(\"Train Loss = \", scores1[0])\n",
        "\n",
        "# print(\"Validation Accuracy = {:.2%}\". format(scores2[1]))\n",
        "# print(\"Validation Loss = \", scores2[0])\n",
        "\n",
        "print(\"Test Accuracy = {:.2%}\". format(scores3[1]))\n",
        "print(\"Test Loss = \", scores3[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1200/1200 [==============================] - 4s 3ms/step\n",
            "Test Accuracy = 77.25%\n",
            "Test Loss =  1.298891305923462\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGRDSTbgn_Oe"
      },
      "source": [
        "#this part is used for re-training from saved model file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNI7nAB2y6HE"
      },
      "source": [
        "from keras.models import load_model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVGOPjPBzANA"
      },
      "source": [
        "\n",
        "loaded_model = load_model(\"/content/drive/Shared drives/PolypDB/AWR_Test 7/models/Best VGG19 with 64x256 aug latest one one.hdf5\",  custom_objects={'<lambda>': lambda y_true, y_pred: y_pred} )\n",
        "#loaded_model = load_model(\"/content/drive/Shared drives/PolypDB/AWR_Test 7/models/Best densenet with 32x128 aug latest.hdf5\",  custom_objects={'<lambda>': lambda y_true, y_pred: y_pred, 'Scale' : Scale} )\n",
        "#model.load_weights(\"/content/drive/Shared drives/PolypDB/AWR_Test 7/models/<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fef08e74780>o-8486r-50e-9622t-1202v.hdf5\")\n",
        "#train_data = ([X_train, y_train, train_input_length, train_label_length], [np.zeros(len(X_train))])\n",
        "#valid_data = ([X_val, y_val, valid_input_length, valid_label_length], [np.zeros(len(X_val))])\n",
        "#test_data = ([X_test, y_test, test_input_length, test_label_length], [np.zeros(len(X_test))])\n",
        "# scores1 = model.evaluate(x=train_data[0], y=train_data[1], verbose=1)\n",
        "# scores2 = model.evaluate(x=valid_data[0], y=valid_data[1], verbose=1)\n",
        "# scores3 = model.evaluate(x=test_data[0], y=test_data[1], verbose=1)\n",
        "\n",
        "#scores1 = model.evaluate([X_train, y_train, train_input_length, train_label_length], [np.zeros(len(X_train))], verbose=1)\n",
        "#scores2 = model.evaluate([X_val, y_val, valid_input_length, valid_label_length],[np.zeros(len(X_val))], verbose=1)\n",
        "#scores3 = loaded_model.evaluate([X_test, y_test, test_input_length, test_label_length], [np.zeros(len(X_test))], verbose=1)\n",
        "\n",
        "# print(\"Train Accuracy = {:.2%}\". format(scores1[1]))\n",
        "# print(\"Train Loss = \", scores1[0])\n",
        "\n",
        "# print(\"Validation Accuracy = {:.2%}\". format(scores2[1]))\n",
        "# print(\"Validation Loss = \", scores2[0])\n",
        "\n",
        "#print(\"Test Accuracy = {:.2%}\". format(scores3[1]))\n",
        "#print(\"Test Loss = \", scores3[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJZM1EG5L1z7"
      },
      "source": [
        "filepath=\"/content/drive/Shared drives/PolypDB/AWR_Test 7/models/{}o-{}r-{}e-{}t-{}v.hdf5\".format(opt,\n",
        "                                                                        str(RECORDS_COUNT),\n",
        "                                                                        str(epochs),\n",
        "                                                                        str(X_train.shape[0]),\n",
        "                                                                       str(X_val.shape[0]))\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "callbacks_list = [checkpoint]\n",
        "#callbacks_list=[lr_callback]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EnWtW_77L7iZ",
        "outputId": "cb43556c-4f4b-40aa-d2c7-cbc3bb947490"
      },
      "source": [
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta = 0.1,\n",
        "    patience = 2)\n",
        "\n",
        "\n",
        "history = loaded_model.fit(x=[X_train, y_train, train_input_length, train_label_length],\n",
        "                    y=np.zeros(len(X_train)),\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=([X_val, y_val, valid_input_length, valid_label_length], [np.zeros(len(X_val))]),\n",
        "                    verbose=2,\n",
        "                    callbacks=callbacks_list\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 29224 samples, validate on 3248 samples\n",
            "Epoch 1/40\n",
            " - 686s - loss: 0.1624 - accuracy: 0.9927 - val_loss: 0.2623 - val_accuracy: 0.9698\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.26234, saving model to /content/drive/Shared drives/PolypDB/AWR_Test 7/models/<keras.optimizers.Adam object at 0x7f043cca7b50>o-8486r-40e-29224t-3248v.hdf5\n",
            "Epoch 2/40\n",
            " - 679s - loss: 0.1681 - accuracy: 0.9914 - val_loss: 0.2283 - val_accuracy: 0.9806\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.26234 to 0.22831, saving model to /content/drive/Shared drives/PolypDB/AWR_Test 7/models/<keras.optimizers.Adam object at 0x7f043cca7b50>o-8486r-40e-29224t-3248v.hdf5\n",
            "Epoch 3/40\n",
            " - 676s - loss: 0.1604 - accuracy: 0.9932 - val_loss: 0.2448 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.22831\n",
            "Epoch 4/40\n",
            " - 674s - loss: 0.1585 - accuracy: 0.9939 - val_loss: 0.2606 - val_accuracy: 0.9723\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.22831\n",
            "Epoch 5/40\n",
            " - 673s - loss: 0.1575 - accuracy: 0.9923 - val_loss: 0.2930 - val_accuracy: 0.9587\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.22831\n",
            "Epoch 6/40\n",
            " - 671s - loss: 0.1677 - accuracy: 0.9904 - val_loss: 0.2626 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.22831\n",
            "Epoch 7/40\n",
            " - 671s - loss: 0.1589 - accuracy: 0.9924 - val_loss: 0.2789 - val_accuracy: 0.9658\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.22831\n",
            "Epoch 8/40\n",
            " - 672s - loss: 0.1669 - accuracy: 0.9909 - val_loss: 0.3068 - val_accuracy: 0.9689\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.22831\n",
            "Epoch 9/40\n",
            " - 672s - loss: 0.1726 - accuracy: 0.9893 - val_loss: 0.2637 - val_accuracy: 0.9735\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.22831\n",
            "Epoch 10/40\n",
            " - 671s - loss: 0.1631 - accuracy: 0.9924 - val_loss: 0.2477 - val_accuracy: 0.9763\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.22831\n",
            "Epoch 11/40\n",
            " - 671s - loss: 0.1562 - accuracy: 0.9943 - val_loss: 0.2380 - val_accuracy: 0.9803\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.22831\n",
            "Epoch 12/40\n",
            " - 670s - loss: 0.1556 - accuracy: 0.9926 - val_loss: 0.2569 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.22831\n",
            "Epoch 13/40\n",
            " - 675s - loss: 0.1564 - accuracy: 0.9926 - val_loss: 0.2529 - val_accuracy: 0.9729\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.22831\n",
            "Epoch 14/40\n",
            " - 672s - loss: 0.1542 - accuracy: 0.9927 - val_loss: 0.2253 - val_accuracy: 0.9797\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.22831 to 0.22526, saving model to /content/drive/Shared drives/PolypDB/AWR_Test 7/models/<keras.optimizers.Adam object at 0x7f043cca7b50>o-8486r-40e-29224t-3248v.hdf5\n",
            "Epoch 15/40\n",
            " - 672s - loss: 0.1561 - accuracy: 0.9927 - val_loss: 0.2622 - val_accuracy: 0.9732\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.22526\n",
            "Epoch 16/40\n",
            " - 669s - loss: 0.1657 - accuracy: 0.9899 - val_loss: 0.2765 - val_accuracy: 0.9667\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.22526\n",
            "Epoch 17/40\n",
            " - 677s - loss: 0.1614 - accuracy: 0.9911 - val_loss: 0.2817 - val_accuracy: 0.9652\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.22526\n",
            "Epoch 18/40\n",
            " - 669s - loss: 0.1610 - accuracy: 0.9923 - val_loss: 0.2328 - val_accuracy: 0.9806\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.22526\n",
            "Epoch 19/40\n",
            " - 668s - loss: 0.1647 - accuracy: 0.9914 - val_loss: 0.2391 - val_accuracy: 0.9794\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.22526\n",
            "Epoch 20/40\n",
            " - 670s - loss: 0.1557 - accuracy: 0.9926 - val_loss: 0.2638 - val_accuracy: 0.9735\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.22526\n",
            "Epoch 21/40\n",
            " - 671s - loss: 0.1616 - accuracy: 0.9908 - val_loss: 0.2704 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.22526\n",
            "Epoch 22/40\n",
            " - 672s - loss: 0.1547 - accuracy: 0.9950 - val_loss: 0.3114 - val_accuracy: 0.9597\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.22526\n",
            "Epoch 23/40\n",
            " - 672s - loss: 0.1560 - accuracy: 0.9933 - val_loss: 0.2393 - val_accuracy: 0.9778\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.22526\n",
            "Epoch 24/40\n",
            " - 671s - loss: 0.1553 - accuracy: 0.9932 - val_loss: 0.2533 - val_accuracy: 0.9748\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.22526\n",
            "Epoch 25/40\n",
            " - 673s - loss: 0.1629 - accuracy: 0.9907 - val_loss: 0.2350 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.22526\n",
            "Epoch 26/40\n",
            " - 667s - loss: 0.1505 - accuracy: 0.9943 - val_loss: 0.2483 - val_accuracy: 0.9754\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.22526\n",
            "Epoch 27/40\n",
            " - 666s - loss: 0.1548 - accuracy: 0.9929 - val_loss: 0.2501 - val_accuracy: 0.9754\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.22526\n",
            "Epoch 28/40\n",
            " - 663s - loss: 0.1555 - accuracy: 0.9920 - val_loss: 0.2764 - val_accuracy: 0.9643\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.22526\n",
            "Epoch 29/40\n",
            " - 664s - loss: 0.1496 - accuracy: 0.9950 - val_loss: 0.2592 - val_accuracy: 0.9754\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.22526\n",
            "Epoch 30/40\n",
            " - 662s - loss: 0.1519 - accuracy: 0.9931 - val_loss: 0.2483 - val_accuracy: 0.9744\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.22526\n",
            "Epoch 31/40\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-865916bb39f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_input_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_label_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3733\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3735\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3736\u001b[0m         expand_composites=True)\n\u001b[1;32m   3737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3733\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3735\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3736\u001b[0m         expand_composites=True)\n\u001b[1;32m   3737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7fJePlXCvK9"
      },
      "source": [
        "# predict outputs on test images\n",
        "predictions = my_model.predict(X_test[1:100])\n",
        "# use CTC decoder\n",
        "decoded = K.ctc_decode(predictions,\n",
        "                       input_length=np.ones(predictions.shape[0]) * predictions.shape[1],\n",
        "                       greedy=True)[0][0]\n",
        "\n",
        "out = K.get_value(decoded)\n",
        "\n",
        "# see the results\n",
        "for i, x in enumerate(out):\n",
        "    print(\"original_text =  \", test_original_text[1+i])\n",
        "    print(\"predicted text = \", end = '')\n",
        "    for p in x:\n",
        "        if int(p) != -1:\n",
        "            print(char_list[int(p)], end = '')\n",
        "    plt.imshow(X_test[1+i].reshape(32,128), cmap=plt.cm.gray)\n",
        "    plt.show()\n",
        "    print('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF1MSgbxgp3i"
      },
      "source": [
        "Using Jaro Distance & Ratio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PjFQPPAgLg0"
      },
      "source": [
        "pip install python-Levenshtein"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW458wBif59E"
      },
      "source": [
        "# load the saved best model weights\n",
        "my_model.load_weights(filepath)\n",
        "\n",
        "# predict outputs on validation images\n",
        "# use CTC decoder\n",
        "decoded = K.ctc_decode(prediction,\n",
        "                       input_length=np.ones(prediction.shape[0]) * prediction.shape[1],\n",
        "                       greedy=True)[0][0]\n",
        "out = K.get_value(decoded)\n",
        "\n",
        "import Levenshtein as lv\n",
        "\n",
        "total_jaro = 0\n",
        "total_rati = 0\n",
        "# see the results\n",
        "for i, x in enumerate(out):\n",
        "    letters=''\n",
        "    for p in x:\n",
        "        if int(p) != -1:\n",
        "            letters+=char_list[int(p)]\n",
        "    total_jaro+=lv.jaro(letters, valid_original_text[i])\n",
        "    total_rati+=lv.ratio(letters, valid_original_text[i])\n",
        "\n",
        "print('jaro :', total_jaro/len(out))\n",
        "print('ratio:', total_rati/len(out))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFBPdIuBgu1E"
      },
      "source": [
        "# Save History"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxitf32mgnTt"
      },
      "source": [
        "#drive/My Drive/Colab Notebooks/Handwritten-Text-Recognition/\n",
        "with open('drive/My Drive/AWR_Test 7/history.txt', 'a') as f:\n",
        "    new_data = '{},{},{},{},{},{},{},{},{},{}\\n'.format(filepath,\n",
        "                                                      opt,\n",
        "                                                      str(RECORDS_COUNT),\n",
        "                                                      e,\n",
        "                                                      str(X_train.shape[0]),\n",
        "                                                      str(X_val.shape[0]),\n",
        "                                                      best_loss,\n",
        "                                                      best_acc,\n",
        "                                                      best_val_loss,\n",
        "                                                      best_val_acc)\n",
        "    f.write(new_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gI8AnHa-hPoi"
      },
      "source": [
        "# More Reports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2480wwrg_zv"
      },
      "source": [
        "def recognized(x):\n",
        "  s=''\n",
        "  for p in x:\n",
        "    if int(p) != 300:\n",
        "      if int(p) != -1:\n",
        "        s += char_list[int(p)] + ''\n",
        "  return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D9PCq4Zjo2x"
      },
      "source": [
        "def wer(r, h):\n",
        "    \"\"\"\n",
        "    Calculation of WER with Levenshtein distance.\n",
        "    Works only for iterables up to 254 elements (uint8).\n",
        "    O(nm) time ans space complexity.\n",
        "    Parameters\n",
        "    ----------\n",
        "    r : list\n",
        "    h : list\n",
        "    Returns\n",
        "    -------\n",
        "    int\n",
        "    Examples\n",
        "    --------\n",
        "    >>> wer(\"who is there\".split(), \"is there\".split())\n",
        "    1\n",
        "    >>> wer(\"who is there\".split(), \"\".split())\n",
        "    3\n",
        "    >>> wer(\"\".split(), \"who is there\".split())\n",
        "    3\n",
        "    \"\"\"\n",
        "    # initialisation\n",
        "    d = np.zeros((len(r)+1)*(len(h)+1), dtype=np.uint8)\n",
        "    d = d.reshape((len(r)+1, len(h)+1))\n",
        "    for i in range(len(r)+1):\n",
        "        for j in range(len(h)+1):\n",
        "            if i == 0:\n",
        "                d[0][j] = j\n",
        "            elif j == 0:\n",
        "                d[i][0] = i\n",
        "\n",
        "    # computation++++++\n",
        "    for i in range(1, len(r)+1):\n",
        "        for j in range(1, len(h)+1):\n",
        "            if r[i-1] == h[j-1]:\n",
        "                d[i][j] = d[i-1][j-1]\n",
        "            else:\n",
        "                substitution = d[i-1][j-1] + 1\n",
        "                insertion = d[i][j-1] + 1\n",
        "                deletion = d[i-1][j] + 1\n",
        "                d[i][j] = min(substitution, insertion, deletion)\n",
        "    return d[len(r)][len(h)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXZQaC-ziYO7"
      },
      "source": [
        "def jaro_and_ratio(letters, original_text):\n",
        "  \"\"\"In computer science and statistics,\n",
        "  the Jaro–Winkler distance is a string metric measuring an edit distance\n",
        "  between two sequences. It is a variant proposed in 1990 by William E. Winkler\n",
        "  of the Jaro distance metric (1989, Matthew A. Jaro).\"\"\"\n",
        "  total_jar = 0\n",
        "  total_rati = 0\n",
        "\n",
        "  for i in range(len(letters)):\n",
        "    total_jar+=lv.jaro(letters[i], original_text[i])\n",
        "    total_rati+=lv.ratio(letters[i], original_text[i])\n",
        "\n",
        "  jaro = total_jar/len(letters)\n",
        "  ratio = total_rati/len(letters)\n",
        "  print(len(letters))\n",
        "  return jaro, ratio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5nfd0JcxLBn"
      },
      "source": [
        "import time\n",
        "def validate(x, y):\n",
        "  \"\"\" Validate neural network \"\"\"\n",
        "  numCharErr = 0\n",
        "  numCharTotal = 0\n",
        "  numWordOK = 0\n",
        "  numWordTotal = 0\n",
        "\n",
        "  totalCER = []\n",
        "  totalWER = []\n",
        "\n",
        "  start_time_total = time.time()\n",
        "\n",
        "  x_pred = my_model.predict(x)\n",
        "  #x_pred = model.predict(x)\n",
        "  x_deco = K.ctc_decode(x_pred , input_length=np.ones(x_pred.shape[0])*x_pred.shape[1], greedy=True)[0][0]\n",
        "\n",
        "  elapsed_time_total = (time.time()-start_time_total)/60\n",
        "  print('\\n\\ntotal elapsed time =',elapsed_time_total,' minutes')\n",
        "\n",
        "  x_reco = K.get_value(x_deco)\n",
        "  x_reco_txt = []\n",
        "  y_orig_txt = []\n",
        "  for i, j in enumerate(x_reco):\n",
        "    try:\n",
        "      x_reco_txt.append(recognized(j))\n",
        "      y_orig_txt.append(recognized(y[i]))\n",
        "    except:\n",
        "      continue\n",
        "\n",
        "  print('Ground truth ~> Recognized')\n",
        "  for i in range(len(x_reco_txt)):\n",
        "      numWordOK += 1 if y_orig_txt[i] == x_reco_txt[i] else 0\n",
        "      numWordTotal += 1\n",
        "      dist = editdistance.eval(x_reco_txt[i], y_orig_txt[i])\n",
        "      ## editdistance\n",
        "      currCER = dist/max(len(x_reco_txt[i]), len(y_orig_txt[i]))\n",
        "      totalCER.append(currCER)\n",
        "\n",
        "      currWER = wer(x_reco_txt[i].split(), y_orig_txt[i].split())\n",
        "      totalWER.append(currWER)\n",
        "\n",
        "      numCharErr += dist\n",
        "      numCharTotal += len(y_orig_txt[i])\n",
        "      with open(\"/content/drive/Shared drives/PolypDB/AWR_Test 7/out.txt\", 'a') as f:\n",
        "        print('[OK]' if dist == 0 else '[ERR:%d]' % dist, '\"' +\n",
        "              y_orig_txt[i] + '\"', '~>', '\"' + x_reco_txt[i] + '\"',file=f)\n",
        "\n",
        "      #if dist != 0:\n",
        "          #print('[ERR:%d]' % dist, '\"' + y_orig_txt[i] + '\"', '~>', '\"' + x_reco_txt[i] + '\"')\n",
        "      with tf.device('/gpu:0'):\n",
        "            #plt.imshow(x[i].reshape(64,256), cmap=plt.cm.gray)\n",
        "            #plt.show()\n",
        "            plt.imsave(\"/content/drive/Shared drives/PolypDB/AWR_Test 7/Best VGG19 with 64x256 aug/\" + 'AHWR'+str(i)+\".jpg\",x[i].reshape(64,256) )\n",
        "            print('\\n')\n",
        "      #print('' if dist == 0 else '[ERR:%d]' % dist, '\"' + y_orig_txt[i] + '\"', '~>', '\"' + x_reco_txt[i] + '\"')\n",
        "      #print( if dist != 0 '[ERR:%d]' % dist )\n",
        "      #with tf.device('/gpu:0'):\n",
        "        #plt.imshow(x[i].reshape(32,128), cmap=plt.cm.gray)\n",
        "        #plt.show()\n",
        "        #print('\\n')\n",
        "\n",
        "  # Print validation result\n",
        "  charErrorRate = sum(totalCER)/len(totalCER)\n",
        "  addressAccuracy = numWordOK / numWordTotal\n",
        "  wordErrorRate = sum(totalWER)/len(totalWER)\n",
        "  jaro, ratio = jaro_and_ratio(x_reco_txt, y_orig_txt)\n",
        "  print('Character error rate: %f%%. Address accuracy: %f%%. Word error rate: %f%%' %\n",
        "        (charErrorRate*100.0, addressAccuracy*100.0, wordErrorRate*100.0))\n",
        "  print('jaro: %f%% and ratio: %f%%' % (jaro*100.0, ratio*100.0))\n",
        "\n",
        "  return charErrorRate, addressAccuracy, wordErrorRate, jaro, ratio\n",
        "\n",
        "import editdistance\n",
        "#import Levenshtein as lv\n",
        "\n",
        "# Validate\n",
        "#print('Validate neural network')\n",
        "#charErrorRate, addressAccuracy, wordErrorRate, jaro, ratio = validate(X_val, y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43EvvHcGPPfu"
      },
      "source": [
        "import Levenshtein as lv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbzyuuk4SySW"
      },
      "source": [
        "pip install python-Levenshtein"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MV01tWXXbuVz",
        "outputId": "36377214-b4a9-4695-ebf9-fce7c06d76cd"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print('Test neural network')\n",
        "charErrorRate, addressAccuracy, wordErrorRate, jaro, ratio  = validate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test neural network\n",
            "\n",
            "\n",
            "total elapsed time = 0.047035741806030276  minutes\n",
            "Ground truth ~> Recognized\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1200\n",
            "Character error rate: 5.421164%. Address accuracy: 81.750000%. Word error rate: 18.250000%\n",
            "jaro: 96.866446% and ratio: 95.311905%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WG4-8qElyOgL"
      },
      "source": [
        "  model.add(Convolution2D(filters=512, kernel_size = KERNEL_SIZE,\n",
        "                 #strides=1,\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv5'))\n",
        "  model.add(Activation('relu', name='activation5'))\n",
        "  model.add(Dropout(0.5))\n",
        "  # Batch normalization layer\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Convolution2D(filters=512, kernel_size = KERNEL_SIZE,\n",
        "                 #strides=1,\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv6'))\n",
        "  model.add(Activation('relu', name='activation6'))\n",
        "\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 1), name='pool4'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odow3AOBRlLE"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPQw3IyBRl6K"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd01sPIGRmbC"
      },
      "source": [
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block as defined in Figure 3\n",
        "\n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "\n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "\n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    # Save the input value. You'll need this later to add back to the main path.\n",
        "    X_shortcut = X\n",
        "\n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "\n",
        "    # Second component of main path (≈3 lines)\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path (≈2 lines)\n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZhciui5Rn0h"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = (2,1)):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block as defined in Figure 4\n",
        "\n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "\n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "\n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path\n",
        "    X = Conv2D(F1, (1, 1), strides = s, name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Second component of main path (≈3 lines)\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "\n",
        "    # Third component of main path (≈2 lines)\n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "\n",
        "    ##### SHORTCUT PATH #### (≈2 lines)\n",
        "    X_shortcut = Conv2D(filters = F3, kernel_size = (1, 1), strides = s, padding = 'valid', name = conv_name_base + '1',\n",
        "                        kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ek6uBUHFS01B"
      },
      "source": [
        "def ResNet50s(input_shape=(64, 64, 3), classes=6):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = (2,1))\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    # output layer\n",
        "\n",
        "\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDy3mH8MTljp"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dropout,Bidirectional, RNN,Reshape,Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D,MaxPooling2D, GlobalMaxPooling2D,Concatenate,GlobalAveragePooling2D,Lambda, GRU\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop, Adamax, Adadelta, Adagrad\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "\n",
        "#from resnets_utils import *\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow.keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBR6NUSVdeMw"
      },
      "source": [
        "from keras.initializers import glorot_uniform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxh6I14tS6yo"
      },
      "source": [
        "model = ResNet50s(input_shape = (32, 128, 1), classes = 6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dws7TJJzFtc"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wuCMlIDzF88"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHT-ZuYmzGKJ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-78F_NhYzIFX"
      },
      "source": [
        "#### DenseNet121 implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R59Z5Kc7zGUK"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "KZm3JxBQ1cb0",
        "outputId": "85155071-998d-4e9c-80bb-f789b0f5e442"
      },
      "source": [
        "densemodel=DenseNettry()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-7511e7b304cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdensemodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDenseNettry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-28-34c3a341c580>\u001b[0m in \u001b[0;36mDenseNettry\u001b[0;34m(nb_dense_block, growth_rate, nb_filter, reduction, dropout_rate, weight_decay, classes, weights_path)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mblock_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_dense_block\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mstage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_filter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdense_blocktry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblock_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_filter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrowth_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# Add transition_block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-34c3a341c580>\u001b[0m in \u001b[0;36mdense_blocktry\u001b[0;34m(x, stage, nb_layers, nb_filter, growth_rate, dropout_rate, weight_decay, grow_nb_filters)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mbranch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_blocktry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbranch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrowth_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mconcat_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConcatenate\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconcat_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'concat_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbranch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgrow_nb_filters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 952\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1091\u001b[0;31m             inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    860\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2708\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2709\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2710\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2711\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2712\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    517\u001b[0m             shape[axis] for shape in shape_set if shape[axis] is not None)\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_dims\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_merge_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 56, 56, 64), (None, 19, 19, 32)]"
          ]
        }
      ]
    }
  ]
}