{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "q30eA8raIbJp",
        "dbRW1lBdIQjF",
        "CH0hXTEf1U3n",
        "TlMJhfakPkEm",
        "IKx14fU3FBNw",
        "gI8mXeaxfxsU",
        "A9ZibmAkS6SU",
        "Km2GyDuBI1sv"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq860rXEZVNd"
      },
      "source": [
        "# Setup Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ox1PwByfQzfS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3bbd35b-fda4-48e7-8c4a-c6d9c31c7e06"
      },
      "source": [
        "pip install keras_tqdm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_tqdm\n",
            "  Downloading keras_tqdm-2.0.1-py2.py3-none-any.whl (7.1 kB)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.10/dist-packages (from keras_tqdm) (2.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from keras_tqdm) (4.66.4)\n",
            "Installing collected packages: keras_tqdm\n",
            "Successfully installed keras_tqdm-2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqzL1C7lUgKf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c9952a6-8a13-48fc-faf3-771bbe263fe5"
      },
      "source": [
        "pip install watermark"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting watermark\n",
            "  Downloading watermark-2.4.3-py2.py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: ipython>=6.0 in /usr/local/lib/python3.10/dist-packages (from watermark) (7.34.0)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.10/dist-packages (from watermark) (7.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from watermark) (67.7.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->watermark) (3.18.1)\n",
            "Collecting jedi>=0.16 (from ipython>=6.0->watermark)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.0->watermark) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.0->watermark) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.0->watermark) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.0->watermark) (0.2.13)\n",
            "Installing collected packages: jedi, watermark\n",
            "Successfully installed jedi-0.19.1 watermark-2.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEK_GCnJITTj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ea48152-012c-443d-c59f-ca3020f244d5"
      },
      "source": [
        "!pip install keras==2.3.1"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras==2.3.1\n",
            "  Downloading Keras-2.3.1-py2.py3-none-any.whl (377 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.8/377.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras==2.3.1) (1.25.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.10/dist-packages (from keras==2.3.1) (1.11.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from keras==2.3.1) (1.16.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from keras==2.3.1) (6.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras==2.3.1) (3.9.0)\n",
            "Collecting keras-applications>=1.0.6 (from keras==2.3.1)\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-preprocessing>=1.0.5 (from keras==2.3.1)\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras-preprocessing, keras-applications, keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-2.3.1 keras-applications-1.0.8 keras-preprocessing-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HMBR2CH-esG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "9fc1f7e5-3eea-422a-fcc7-e80aff855b8a"
      },
      "source": [
        "!pip install tensorflow==2.8.0"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.8.0\n",
            "  Downloading tensorflow-2.8.0-cp310-cp310-manylinux2010_x86_64.whl (497.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.6/497.6 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (24.3.25)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.1.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (18.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (4.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.14.1)\n",
            "Collecting tensorboard<2.9,>=2.8 (from tensorflow==2.8.0)\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tf-estimator-nightly==2.8.0.dev2021122109 (from tensorflow==2.8.0)\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.9,>=2.8.0rc0 (from tensorflow==2.8.0)\n",
            "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.63.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.8.0) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.27.0)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.31.0)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0)\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.2.2)\n",
            "Installing collected packages: tf-estimator-nightly, tensorboard-plugin-wit, keras, tensorboard-data-server, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: Keras 2.3.1\n",
            "    Uninstalling Keras-2.3.1:\n",
            "      Successfully uninstalled Keras-2.3.1\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.0\n",
            "    Uninstalling google-auth-oauthlib-1.2.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-gbq 0.19.2 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-auth-oauthlib-0.4.6 keras-2.8.0 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf-hT1v9W1fa"
      },
      "source": [
        "from tensorflow.python.keras import regularizers"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwxCnx4VT62S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b40c6c3d-a72b-483f-a41c-1ba074851d7d"
      },
      "source": [
        "# code for loading the format for the notebook\n",
        "import os\n",
        "\n",
        "\n",
        "# 1. magic to print version\n",
        "# 2. magic so that the notebook will reload external python modules\n",
        "%load_ext watermark\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from tensorflow.python.keras import regularizers\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers.advanced_activations import PReLU\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import pandas as pd\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Dropout,Bidirectional, RNN,Reshape,Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D,MaxPooling2D, GlobalMaxPooling2D,Concatenate,GlobalAveragePooling2D,Lambda, GRU\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.applications import VGG19,VGG16, ResNet50, MobileNet, Xception\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop, Adamax, Adadelta, Adagrad\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Lambda, GRU, BatchNormalization\n",
        "from keras.layers.convolutional import Convolution2D, Cropping2D, ZeroPadding2D, MaxPooling2D\n",
        "#from keras.layers.normalization import BatchNormalization\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.layers import LSTM, Reshape, Input, Conv2D, MaxPool2D, Bidirectional, RNN, Concatenate\n",
        "from keras.models import Model\n",
        "from keras.activations import relu, sigmoid, softmax\n",
        "import keras.backend as K\n",
        "#from keras.utils import to_categorical\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras_tqdm import TQDMNotebookCallback\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "%watermark -a 'Ethen' -d -t -v -p numpy,pandas,keras,sklearn,tensorflow,cv2"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The watermark extension is already loaded. To reload it, use:\n",
            "  %reload_ext watermark\n",
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n",
            "Author: Ethen\n",
            "\n",
            "Python implementation: CPython\n",
            "Python version       : 3.10.12\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "numpy     : 1.25.2\n",
            "pandas    : 2.0.3\n",
            "keras     : 2.8.0\n",
            "sklearn   : 1.2.2\n",
            "tensorflow: 2.8.0\n",
            "cv2       : 4.8.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXVIMJ4AZkWb"
      },
      "source": [
        "# Connect My Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Skgf2fAZ8oZo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8454bb8f-cc14-4ce1-cac1-f938f95d57be"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "print(tf.__version__)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhtHh6RNZsyb",
        "outputId": "8a1cef32-bbba-4c8d-c2d9-4c5065fff3d6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ODyFyYVaxOH",
        "outputId": "aee240d9-6982-4f07-ead3-c4b12692d41d"
      },
      "source": [
        "cd /content/drive/Shared drives/PolypDB/AWR_Test 7"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/Shared drives/PolypDB/AWR_Test 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SL8cpRpka0Cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77f9bf99-56e2-4bbd-bfb2-472742d0c623"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'10-fold cross validation for AHWR.ipynb'  'Orig of save to npy.ipynb'\n",
            "'Best VGG19 with 64x256 aug'\t\t    out.txt\n",
            " data\t\t\t\t\t   '[ResNet50] GRU Test for AHWR.ipynb'\n",
            " history.txt\t\t\t\t   'Test for AHWR.ipynb'\n",
            " models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFBHLDXcaBDa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "71735642-6e2f-41b8-cef8-d2f574083ac1"
      },
      "source": [
        "#with open('parser/words.txt') as f:\n",
        "with open('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/words.txt') as f:\n",
        "    contents = f.readlines()\n",
        "\n",
        "lines = [line.strip() for line in contents]\n",
        "print (lines.size)\n",
        "lines[7]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ar01-ab01-001-008 ok 196 1129 31 155 37 NN ከክርስቶስ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (len(lines))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vubnXx6csmlp",
        "outputId": "5f04fe22-1af6-4791-b877-6421d46e6c22"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36190\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj1DVPlIXWlt"
      },
      "source": [
        "# tf-GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPptsb4yRI_J"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#ignore warnings in the output\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqRVqsAIXmcv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60d37b7d-b024-4b70-d3b0-d48c0f734734"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "# Check all available devices if GPU is available\n",
        "print(device_lib.list_local_devices())\n",
        "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 8117562483591214995\n",
            "xla_global_id: -1\n",
            "]\n",
            "Device mapping: no known devices.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "GIZM03yWXm2v",
        "outputId": "a0f84a63-cccc-42b2-cfc6-3a2045447d7e"
      },
      "source": [
        "tf.compat.v1.config.experimental.list_physical_devices('GPU')\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "print(\"Num GPUs:\", len(physical_devices))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUs: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uTvwa83bSrl"
      },
      "source": [
        "# Initializing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPAtd2LJameC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6350a546-9abd-4b7b-fc78-52cbe140edd6"
      },
      "source": [
        "max_label_len = 0\n",
        "#max_label_len = 11\n",
        "RECORDS_COUNT = 8486\n",
        "\n",
        "\n",
        "char_list = \"ሀሁሂሃሄህሆለሉሊላሌልሎሏሐሑሒሓሔሕሖመሙሚማሜምሞሟሠሡሢሣሤሥሦሧረሩሪራሬርሮሯሰሱሲሳሴስሶሷሸሹሺሻሼሽሾሿቀቁቂቃቄቅቆቋበቡቢባቤብቦቧቨቩቪቫቬቭቮቯተቱቲታቴትቶቷቸቹቺቻቼችቾቿኀኁኂኃኄኅኋነኑኒናኔንኖኗኘኙኚኛኜኝኞኟአኡኢኣኤእኦኧከኩኪካኬክኮኳኸኹኺኻኼኽኾዀዂወዉዊዋዌውዎዏዐዑዒዓዔዕዖዘዙዚዛዜዝዞዟዠዡዢዣዤዥዦዧየዩዪያዬይዮደዱዲዳዴድዶዷጀጁጂጃጄጅጆጇገጉጊጋጌግጎጐጓጠጡጢጣጤጥጦጧጨጩጪጫጬጭጮጯጰጱጲጳጴጵጶጷጸጹጺጻጼጽጾጿፀፁፂፃፄፅፆፈፉፊፋፌፍፎፏፐፑፒፓፔፕፖፗ!፦‹(«፥%»)›.+፣-።/0123456789፡፤…*#?\"\n",
        "print(char_list)\n",
        "print( len(char_list))\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ሀሁሂሃሄህሆለሉሊላሌልሎሏሐሑሒሓሔሕሖመሙሚማሜምሞሟሠሡሢሣሤሥሦሧረሩሪራሬርሮሯሰሱሲሳሴስሶሷሸሹሺሻሼሽሾሿቀቁቂቃቄቅቆቋበቡቢባቤብቦቧቨቩቪቫቬቭቮቯተቱቲታቴትቶቷቸቹቺቻቼችቾቿኀኁኂኃኄኅኋነኑኒናኔንኖኗኘኙኚኛኜኝኞኟአኡኢኣኤእኦኧከኩኪካኬክኮኳኸኹኺኻኼኽኾዀዂወዉዊዋዌውዎዏዐዑዒዓዔዕዖዘዙዚዛዜዝዞዟዠዡዢዣዤዥዦዧየዩዪያዬይዮደዱዲዳዴድዶዷጀጁጂጃጄጅጆጇገጉጊጋጌግጎጐጓጠጡጢጣጤጥጦጧጨጩጪጫጬጭጮጯጰጱጲጳጴጵጶጷጸጹጺጻጼጽጾጿፀፁፂፃፄፅፆፈፉፊፋፌፍፎፏፐፑፒፓፔፕፖፗ!፦‹(«፥%»)›.+፣-።/0123456789፡፤…*#?\n",
            "300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NMrs4I3_6rm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Z-PSOvQ2ckC"
      },
      "source": [
        "#images = []\n",
        "#labels = []\n",
        "\n",
        "RECORDS_COUNT = 8486\n",
        "X_train = []\n",
        "train_labels = []\n",
        "train_input_length = []\n",
        "train_label_length = []\n",
        "train_original_text = []\n",
        "\n",
        "X_val = []\n",
        "valid_labels = []\n",
        "valid_input_length = []\n",
        "valid_label_length = []\n",
        "valid_original_text = []\n",
        "\n",
        "X_test = []\n",
        "test_labels = []\n",
        "test_input_length = []\n",
        "test_label_length = []\n",
        "test_original_text = []\n",
        "\n",
        "inputs_length = []\n",
        "labels_length = []\n",
        "max_label_len = 11"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5TOpn1q3C0m"
      },
      "source": [
        "for index, line in enumerate(lines):\n",
        "    splits = line.split(' ')\n",
        "    status = splits[1]\n",
        "\n",
        "    if status == 'ok':\n",
        "        word_id = splits[0]\n",
        "        word = \"\".join(splits[8:])\n",
        "\n",
        "        splits_id = word_id.split('-')\n",
        "\n",
        "\n",
        "        if index % 5 == 0:\n",
        "          valid_original_text.append(word)\n",
        "\n",
        "        if index % 6 == 0:\n",
        "          test_original_text.append(word)\n",
        "\n",
        "        else:\n",
        "            train_original_text.append(word)\n",
        "\n",
        "\n",
        "        if len(word) > max_label_len:\n",
        "            max_label_len = len(word)\n",
        "\n",
        "    if index >= RECORDS_COUNT:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "sauvax_BbwMk",
        "outputId": "7001712d-e841-4f2d-b37b-ecb5f436d0b2"
      },
      "source": [
        "print(max_label_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6lPopkmdgG5"
      },
      "source": [
        "# Generate train & validation set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmjsHKkeHv9q"
      },
      "source": [
        "#This notebook cell is used to load the numpy data for original data of 32 x 128 size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAkKQdRCE8Ri",
        "outputId": "7b9a657e-53d3-4385-ce55-d7ee0e69e851"
      },
      "source": [
        "#the training, validation and test set\n",
        "X_train = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npy/X_train.npy')\n",
        "train_input_length = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npy/train_input_length.npy')\n",
        "train_label_length = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npy/train_label_length.npy')\n",
        "X_val = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npy/X_val.npy')\n",
        "valid_input_length = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npy/valid_input_length.npy')\n",
        "valid_label_length = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npy/valid_label_length.npy')\n",
        "X_test = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npy/X_test.npy')\n",
        "test_input_length = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npy/test_input_length.npy')\n",
        "test_label_length = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npy/test_label_length.npy')\n",
        "\n",
        "y_train = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npy/y_train.npy')\n",
        "y_val = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npy/y_val.npy')\n",
        "y_test = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npy/y_test.npy')\n",
        "\n",
        "print(train_label_length[0])\n",
        "print('number of training images: ', X_train.shape[0])\n",
        "print('number of validation images: ', X_val.shape[0])\n",
        "print('number of testing images: ', X_test.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of testing images:  1200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6yunEXeFUNJ",
        "outputId": "dcfb9177-8e4f-438c-dbb1-8b93ac9a2644"
      },
      "source": [
        "X_test.shape\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1200, 64, 256, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWeUUUoCoCmY",
        "outputId": "17db77e3-c016-4b93-9324-30ec3f3e95c4"
      },
      "source": [
        "print(y_test[0])\n",
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[153 112 300 300 300 300 300 300 300 300 300]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1200, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFWkKXR8BtMu"
      },
      "source": [
        "#augmented data for size 32x128"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ehgc-e5leie3",
        "outputId": "961f706d-0314-4343-e918-d11cb0e81bcf"
      },
      "source": [
        "# the training, validation and test set\n",
        "X_train = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npys/X_train.npy')\n",
        "train_input_length = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npys/train_input_length.npy')\n",
        "train_label_length = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npys/train_label_length.npy')\n",
        "X_val = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npys/X_val.npy')\n",
        "valid_input_length = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npys/valid_input_length.npy')\n",
        "valid_label_length = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npys/valid_label_length.npy')\n",
        "X_test = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npy/X_test.npy')\n",
        "test_input_length = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npy/test_input_length.npy')\n",
        "test_label_length = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npy/test_label_length.npy')\n",
        "\n",
        "y_train = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npys/y_train.npy')\n",
        "y_val = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npys/y_val.npy')\n",
        "y_test = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npy/y_test.npy')\n",
        "\n",
        "print(train_label_length[0])\n",
        "print('number of training images: ', X_train.shape[0])\n",
        "print('number of validation images: ', X_val.shape[0])\n",
        "print('number of testing images: ', X_test.shape[0])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "number of training images:  29224\n",
            "number of validation images:  3248\n",
            "number of testing images:  1200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeRmg2ynBzIi"
      },
      "source": [
        "#augmented data for size 64x256"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StGv2WOvBsC5",
        "outputId": "47e7d511-3530-48f9-d2a6-eba2f8126880"
      },
      "source": [
        "# the training, validation and test set\n",
        "X_train = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npys2/X_train.npy')\n",
        "train_input_length = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npys2/train_input_length.npy')\n",
        "train_label_length = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npys2/train_label_length.npy')\n",
        "X_val = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npys2/X_val.npy')\n",
        "valid_input_length = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npys2/valid_input_length.npy')\n",
        "valid_label_length = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npys2/valid_label_length.npy')\n",
        "\n",
        "\n",
        "y_train = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npys2/y_train.npy')\n",
        "y_val = np.load('/content/drive/Shared drives/PolypDB/AWR_Test 7/data/npys2/y_val.npy')\n",
        "\n",
        "\n",
        "print(train_label_length[0])\n",
        "print('number of training images: ', X_train.shape[0])\n",
        "print('number of validation images: ', X_val.shape[0])\n",
        "# print('number of testing images: ', X_test.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n",
            "number of training images:  29224\n",
            "number of validation images:  3248\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ApgHfVJTrA3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "557f944b-8923-49c5-8ac5-e9cb1dcb1a84"
      },
      "source": [
        "print(len(train_input_length))\n",
        "print(train_input_length[9])\n",
        "print(len(X_train))\n",
        "print(len(y_train))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29224\n",
            "31\n",
            "29224\n",
            "29224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24MfB6kzixbe",
        "outputId": "201653bd-1aa3-466d-aa62-5987a48b9caf"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29224, 32, 128, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap9tLXxQQStm"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5X-pzfVRHtW"
      },
      "source": [
        "for x in range (0,len(y_train)):\n",
        "  #print(x)\n",
        "  train_input_length[x]= 32"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDteyh3bUIGe"
      },
      "source": [
        "for x in range (0,len(y_val)):\n",
        "  valid_input_length[x]= 32"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E5HGZ4dUJS_"
      },
      "source": [
        "for x in range (0,len(y_test)):\n",
        "  test_input_length[x]= 32"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyhIj1lZ6Hs6",
        "outputId": "97cc447f-71cb-463c-a582-eb703d16d3c1"
      },
      "source": [
        "print(y_train[0])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[181  22  66 194 114 184 300 300 300 300 300]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxwydtw3TkpP",
        "outputId": "35c6dd1b-8582-434b-c484-b3dee1eeb1dc"
      },
      "source": [
        "train_original_text=[]\n",
        "\n",
        "for label in y_train:\n",
        "    str1= \"\"\n",
        "    for i in label:\n",
        "        if i != 300:\n",
        "            str1+=char_list[i]\n",
        "    #print(str)\n",
        "    train_original_text.append(str1)\n",
        "print(train_original_text[0])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "የመቄዶንያ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIsgTd4l6bgU",
        "outputId": "08704769-f874-4237-962e-d56d81707bec"
      },
      "source": [
        "\n",
        "print(len(train_original_text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9622\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-DvVpD_4wWt",
        "outputId": "3a8092c8-22ab-4be6-f8e3-34bcf6173802"
      },
      "source": [
        "valid_original_text=[]\n",
        "\n",
        "for label in y_val:\n",
        "    str1= \"\"\n",
        "    for i in label:\n",
        "        if i != 300:\n",
        "            str1+=char_list[i]\n",
        "    #print(str)\n",
        "    valid_original_text.append(str1)\n",
        "print(valid_original_text[0])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "አሪስቶትል\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6fCDXfC6YX0",
        "outputId": "fcb56360-7bd8-4469-c0dd-6382dbd1c1b0"
      },
      "source": [
        "print(valid_original_text[5])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ከዚያም\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1osWKeFv42Um",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ee6bedd-463b-43c9-b16b-2bf6503aee02"
      },
      "source": [
        "test_original_text = []\n",
        "\n",
        "for label in y_test:\n",
        "    str1= \"\"\n",
        "    for i in label:\n",
        "        if i != 300:\n",
        "            str1+=char_list[i]\n",
        "    #print(str)\n",
        "    test_original_text.append(str1)\n",
        "print(test_original_text[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ዋና\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "csg= np.squeeze(X_test[10])"
      ],
      "metadata": {
        "id": "rnEotZvo_EH7"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(csg.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGy5PYMV_F6l",
        "outputId": "5ba4210e-da2e-456c-97ad-020e8f46c46a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(csg, cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "id": "To-wPvvm_Kep",
        "outputId": "0e74c7f1-7426-43d2-9bc8-7b698301f2e6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcUEUuip6-Jq"
      },
      "source": [
        "INPUT_SHAPE = (64, 256, 1)\n",
        "POOL_SIZE = (2, 2)\n",
        "KERNEL_SIZE = (3, 3)\n",
        "\n",
        "KERNEL_SIZE1 = (5, 5)\n",
        "KERNEL_SIZE_BN = (2, 2)\n",
        "REG = 0.01\n",
        "\n",
        "base_model = ResNet50(include_top=False, weights=None, input_tensor=None, input_shape=INPUT_SHAPE)\n",
        "\n",
        "x = base_model.layers[38].output\n",
        "model = Model(base_model.inputs, x)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biov5jcapxYA"
      },
      "source": [
        "INPUT_SHAPE = (32, 128, 1)\n",
        "POOL_SIZE = (2, 2)\n",
        "KERNEL_SIZE = (3, 3)\n",
        "\n",
        "KERNEL_SIZE1 = (5, 5)\n",
        "KERNEL_SIZE_BN = (2, 2)\n",
        "REG = 0.01\n",
        "\n",
        "base_model = ResNet50(include_top=False, weights=None, input_tensor=None, input_shape=INPUT_SHAPE)\n",
        "base_model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AGh9icveWuh"
      },
      "source": [
        "# Build Models\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q30eA8raIbJp"
      },
      "source": [
        "#This cell holds an old version of custom model with 7 convolution layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bim-kFyHylCC"
      },
      "source": [
        "INPUT_SHAPE = (32, 128, 1)\n",
        "POOL_SIZE = (2, 2)\n",
        "KERNEL_SIZE = (3, 3)\n",
        "KERNEL_SIZE1 = (5, 5)\n",
        "KERNEL_SIZE_BN = (2, 2)\n",
        "REG = 0.01\n",
        "\n",
        "def create_model():\n",
        "  # Initialise a model\n",
        "  model = Sequential()\n",
        "\n",
        "  # First conv layer - input layer\n",
        "  model.add(Convolution2D(filters=64, kernel_size = KERNEL_SIZE, input_shape=INPUT_SHAPE,\n",
        "                 use_bias=True,\n",
        "                 #strides=1,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv1'))\n",
        "  model.add(Activation('relu', name='activation1'))\n",
        "  #model.add(Dropout(0.25))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), name='pool1'))\n",
        "\n",
        "  model.add(Convolution2D(filters=128, kernel_size = KERNEL_SIZE,\n",
        "                 #strides=1,\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv2'))\n",
        "  model.add(Activation('relu', name='activation2'))\n",
        "  #model.add(Dropout(0.25))\n",
        "  model.add(MaxPooling2D(pool_size=POOL_SIZE, strides=(2,2), name='pool2'))\n",
        "\n",
        "  model.add(Convolution2D(filters=256, kernel_size = KERNEL_SIZE,\n",
        "                 #strides=1,\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv3'))\n",
        "  model.add(Activation('relu', name='activation3'))\n",
        "  #model.add(Dropout(0.25))\n",
        "  #model.add(MaxPooling2D(pool_size=(2, 2), name='pool3'))\n",
        "\n",
        "  model.add(Convolution2D(filters=256, kernel_size = KERNEL_SIZE,\n",
        "                 #strides=1,\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv4'))\n",
        "  model.add(Activation('relu', name='activation4'))\n",
        "  #model.add(Dropout(0.2))\n",
        "  # pooling layer with kernel size (2,1)\n",
        "  model.add(MaxPooling2D(pool_size=(2, 1), name='pool4'))\n",
        "\n",
        "  model.add(Convolution2D(filters=512, kernel_size = KERNEL_SIZE,\n",
        "                 #strides=1,\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv5'))\n",
        "  model.add(Activation('relu', name='activation5'))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "  model.add(Convolution2D(filters=512, kernel_size = KERNEL_SIZE,\n",
        "                 #strides=1,\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv6'))\n",
        "  model.add(Activation('relu', name='activation6'))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(BatchNormalization())\n",
        "  # pooling layer with kernel size (2,1)\n",
        "  model.add(MaxPooling2D(pool_size=(2, 1), name='pool5'))\n",
        "\n",
        "\n",
        "  model.add(  Reshape((32, 1024), name=\"reshape\") )\n",
        "  model.summary()\n",
        "  #model.add(Convolution2D(filters=512, kernel_size = KERNEL_SIZE_BN, kernel_regularizer=regularizers.l2(REG), name='conv7'))\n",
        "  #model.add(Activation('relu', name='activation7'))\n",
        "  #model.add(Dense(64, activation='relu', name='dense1'))\n",
        "\n",
        "  #model.add(Lambda(lambda x: K.squeeze(x, 1)))\n",
        "  #model.add(Dropout(0.2))\n",
        "\n",
        "  # bidirectional LSTM layers with units=128\n",
        "  #model.add(Bidirectional(LSTM(256, return_sequences=True,\n",
        "  #                             kernel_regularizer=regularizers.l2(REG), name='blstm1')))\n",
        "  #model.add(Dropout(0.2))\n",
        "  model.add(Bidirectional(GRU(512, return_sequences=True,\n",
        "                kernel_regularizer=regularizers.l2(REG), name='gru1')))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  #model.add(Bidirectional(LSTM(256, return_sequences=True,\n",
        "  #                             kernel_regularizer=regularizers.l2(REG), name='blstm2')))\n",
        "  #model.add(Dropout(0.2))\n",
        "  model.add(Bidirectional(GRU(256, return_sequences=True,\n",
        "                kernel_regularizer=regularizers.l2(REG), name='gru2')))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  # transforms RNN output to character activations\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  model.add(Dense(len(char_list)+1,\n",
        "                  kernel_regularizer=regularizers.l2(REG), name='outputs'))\n",
        "  model.add(Activation('softmax', name='softmax'))\n",
        "\n",
        "  return model\n",
        "\n",
        "my_model = create_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbRW1lBdIQjF"
      },
      "source": [
        "#This code cell holds best performing custom model\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqXjaQSjIODh",
        "outputId": "e355764e-6e0d-4704-df94-1e22235f9b21"
      },
      "source": [
        "INPUT_SHAPE = (64, 256, 1)\n",
        "POOL_SIZE = (2, 2)\n",
        "KERNEL_SIZE = (3, 3)\n",
        "KERNEL_SIZE_BN = (2, 2)\n",
        "REG = 0.00001\n",
        "\n",
        "def create_model():\n",
        "  # Initialise a model\n",
        "  model = Sequential()\n",
        "\n",
        "  # First conv layer - input layer\n",
        "  model.add(Convolution2D(filters=64, kernel_size = KERNEL_SIZE, input_shape=INPUT_SHAPE,\n",
        "                 use_bias=True,\n",
        "                 strides=(1, 1),\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv1'))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(BatchNormalization(name='bn1'))\n",
        "\n",
        "  model.add(Convolution2D(filters=64, kernel_size = KERNEL_SIZE,\n",
        "                 strides=(1, 1),\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv2'))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), name='pool1'))\n",
        "\n",
        "  model.add(Convolution2D(filters=128, kernel_size = KERNEL_SIZE,\n",
        "                 strides=(1, 1),\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv3'))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(BatchNormalization(name='bn2'))\n",
        "\n",
        "  model.add(Convolution2D(filters=128, kernel_size = KERNEL_SIZE,\n",
        "                 strides=(1, 1),\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv4'))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), name='pool2'))\n",
        "\n",
        "  model.add(Convolution2D(filters=256, kernel_size = KERNEL_SIZE,\n",
        "                 strides=(1, 1),\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv5'))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(BatchNormalization(name='bn3'))\n",
        "\n",
        "  model.add(Convolution2D(filters=256, kernel_size = KERNEL_SIZE,\n",
        "                 strides=(1, 1),\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv6'))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2), name='pool3'))\n",
        "\n",
        "  model.add(Convolution2D(filters=256, kernel_size = KERNEL_SIZE,\n",
        "                 strides=(1, 1),\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv7'))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(BatchNormalization(name='bn4'))\n",
        "\n",
        "  model.add(Convolution2D(filters=256, kernel_size = KERNEL_SIZE,\n",
        "                 strides=(1, 1),\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv8'))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(MaxPooling2D(pool_size=(2, 1), name='pool4'))\n",
        "\n",
        "  model.add(Convolution2D(filters=512, kernel_size = KERNEL_SIZE,\n",
        "                 strides=(1, 1),\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv9'))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(BatchNormalization(name='bn5'))\n",
        "\n",
        "  model.add(Convolution2D(filters=512, kernel_size = KERNEL_SIZE,\n",
        "                 strides=(1, 1),\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv10'))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(BatchNormalization(name='bn6'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 1), name='pool5'))\n",
        "\n",
        "  model.add(Convolution2D(filters=512, kernel_size = KERNEL_SIZE,\n",
        "                 strides=(1, 1),\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv11'))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  model.add(BatchNormalization(name='bn7'))\n",
        "\n",
        "  model.add(Convolution2D(filters=512, kernel_size = KERNEL_SIZE_BN,  padding='same',\n",
        "                          kernel_regularizer=regularizers.l2(REG), name='conv12'))\n",
        "  model.add(Activation('relu'))\n",
        "\n",
        "  #model.add(Dense(64, activation='relu', name='dense1'))\n",
        "  model.summary()\n",
        "\n",
        "  #model.add(Lambda(lambda x: K.squeeze(x, 1)))\n",
        "  model.add(  Reshape((32, 1024), name=\"reshape\") )\n",
        "\n",
        "  # bidirectional LSTM layers with units=128\n",
        "  #model.add(Bidirectional(LSTM(256, return_sequences=True,\n",
        "  #                             kernel_regularizer=regularizers.l2(REG), name='blstm1')))\n",
        "  #model.add(Dropout(0.2))\n",
        "  #with tf.device('/gpu:0'):\n",
        "  model.add(Bidirectional(GRU(512, return_sequences=True,\n",
        "                kernel_regularizer=regularizers.l2(REG), reset_after=True, name='gru1')))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  #model.add(Bidirectional(LSTM(256, return_sequences=True,\n",
        "  #                             kernel_regularizer=regularizers.l2(REG), name='blstm2')))\n",
        "  #model.add(Dropout(0.2))\n",
        "  #with tf.device('/gpu:1'):\n",
        "  model.add(Bidirectional(GRU(512, return_sequences=True,\n",
        "                kernel_regularizer=regularizers.l2(REG), reset_after=True, name='gru2')))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "  # transforms RNN output to character activations\n",
        "  model.add(Dense(len(char_list)+1,\n",
        "                  kernel_regularizer=regularizers.l2(REG), name='outputs'))\n",
        "  model.add(Activation('softmax', name='softmax'))\n",
        "\n",
        "  return model\n",
        "\n",
        "my_model = create_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1 (Conv2D)               (None, 64, 256, 64)       640       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 64, 256, 64)       0         \n",
            "_________________________________________________________________\n",
            "bn1 (BatchNormalization)     (None, 64, 256, 64)       256       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 64, 256, 64)       36928     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 64, 256, 64)       0         \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 32, 128, 64)       0         \n",
            "_________________________________________________________________\n",
            "conv3 (Conv2D)               (None, 32, 128, 128)      73856     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 32, 128, 128)      0         \n",
            "_________________________________________________________________\n",
            "bn2 (BatchNormalization)     (None, 32, 128, 128)      512       \n",
            "_________________________________________________________________\n",
            "conv4 (Conv2D)               (None, 32, 128, 128)      147584    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 32, 128, 128)      0         \n",
            "_________________________________________________________________\n",
            "pool2 (MaxPooling2D)         (None, 16, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv5 (Conv2D)               (None, 16, 64, 256)       295168    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 16, 64, 256)       0         \n",
            "_________________________________________________________________\n",
            "bn3 (BatchNormalization)     (None, 16, 64, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv6 (Conv2D)               (None, 16, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 16, 64, 256)       0         \n",
            "_________________________________________________________________\n",
            "pool3 (MaxPooling2D)         (None, 8, 32, 256)        0         \n",
            "_________________________________________________________________\n",
            "conv7 (Conv2D)               (None, 8, 32, 256)        590080    \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 8, 32, 256)        0         \n",
            "_________________________________________________________________\n",
            "bn4 (BatchNormalization)     (None, 8, 32, 256)        1024      \n",
            "_________________________________________________________________\n",
            "conv8 (Conv2D)               (None, 8, 32, 256)        590080    \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 8, 32, 256)        0         \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 4, 32, 256)        0         \n",
            "_________________________________________________________________\n",
            "conv9 (Conv2D)               (None, 4, 32, 512)        1180160   \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 4, 32, 512)        0         \n",
            "_________________________________________________________________\n",
            "bn5 (BatchNormalization)     (None, 4, 32, 512)        2048      \n",
            "_________________________________________________________________\n",
            "conv10 (Conv2D)              (None, 4, 32, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 4, 32, 512)        0         \n",
            "_________________________________________________________________\n",
            "bn6 (BatchNormalization)     (None, 4, 32, 512)        2048      \n",
            "_________________________________________________________________\n",
            "pool5 (MaxPooling2D)         (None, 2, 32, 512)        0         \n",
            "_________________________________________________________________\n",
            "conv11 (Conv2D)              (None, 2, 32, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 2, 32, 512)        0         \n",
            "_________________________________________________________________\n",
            "bn7 (BatchNormalization)     (None, 2, 32, 512)        2048      \n",
            "_________________________________________________________________\n",
            "conv12 (Conv2D)              (None, 2, 32, 512)        1049088   \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 2, 32, 512)        0         \n",
            "=================================================================\n",
            "Total params: 9,282,240\n",
            "Trainable params: 9,277,760\n",
            "Non-trainable params: 4,480\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yOl8niXpIYc",
        "outputId": "d6423732-06f4-4161-8999-02ee71372151"
      },
      "source": [
        "my_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1 (Conv2D)               (None, 64, 256, 64)       640       \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 64, 256, 64)       0         \n",
            "_________________________________________________________________\n",
            "bn1 (BatchNormalization)     (None, 64, 256, 64)       256       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 64, 256, 64)       36928     \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 64, 256, 64)       0         \n",
            "_________________________________________________________________\n",
            "pool1 (MaxPooling2D)         (None, 32, 128, 64)       0         \n",
            "_________________________________________________________________\n",
            "conv3 (Conv2D)               (None, 32, 128, 128)      73856     \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 32, 128, 128)      0         \n",
            "_________________________________________________________________\n",
            "bn2 (BatchNormalization)     (None, 32, 128, 128)      512       \n",
            "_________________________________________________________________\n",
            "conv4 (Conv2D)               (None, 32, 128, 128)      147584    \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 32, 128, 128)      0         \n",
            "_________________________________________________________________\n",
            "pool2 (MaxPooling2D)         (None, 16, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv5 (Conv2D)               (None, 16, 64, 256)       295168    \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 16, 64, 256)       0         \n",
            "_________________________________________________________________\n",
            "bn3 (BatchNormalization)     (None, 16, 64, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv6 (Conv2D)               (None, 16, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 16, 64, 256)       0         \n",
            "_________________________________________________________________\n",
            "pool3 (MaxPooling2D)         (None, 8, 32, 256)        0         \n",
            "_________________________________________________________________\n",
            "conv7 (Conv2D)               (None, 8, 32, 256)        590080    \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 8, 32, 256)        0         \n",
            "_________________________________________________________________\n",
            "bn4 (BatchNormalization)     (None, 8, 32, 256)        1024      \n",
            "_________________________________________________________________\n",
            "conv8 (Conv2D)               (None, 8, 32, 256)        590080    \n",
            "_________________________________________________________________\n",
            "activation_20 (Activation)   (None, 8, 32, 256)        0         \n",
            "_________________________________________________________________\n",
            "pool4 (MaxPooling2D)         (None, 4, 32, 256)        0         \n",
            "_________________________________________________________________\n",
            "conv9 (Conv2D)               (None, 4, 32, 512)        1180160   \n",
            "_________________________________________________________________\n",
            "activation_21 (Activation)   (None, 4, 32, 512)        0         \n",
            "_________________________________________________________________\n",
            "bn5 (BatchNormalization)     (None, 4, 32, 512)        2048      \n",
            "_________________________________________________________________\n",
            "conv10 (Conv2D)              (None, 4, 32, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "activation_22 (Activation)   (None, 4, 32, 512)        0         \n",
            "_________________________________________________________________\n",
            "bn6 (BatchNormalization)     (None, 4, 32, 512)        2048      \n",
            "_________________________________________________________________\n",
            "pool5 (MaxPooling2D)         (None, 2, 32, 512)        0         \n",
            "_________________________________________________________________\n",
            "conv11 (Conv2D)              (None, 2, 32, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "activation_23 (Activation)   (None, 2, 32, 512)        0         \n",
            "_________________________________________________________________\n",
            "bn7 (BatchNormalization)     (None, 2, 32, 512)        2048      \n",
            "_________________________________________________________________\n",
            "conv12 (Conv2D)              (None, 2, 32, 512)        1049088   \n",
            "_________________________________________________________________\n",
            "activation_24 (Activation)   (None, 2, 32, 512)        0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 32, 1024)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 32, 1024)          4724736   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 32, 1024)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 32, 1024)          4724736   \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32, 1024)          0         \n",
            "_________________________________________________________________\n",
            "outputs (Dense)              (None, 32, 301)           308525    \n",
            "_________________________________________________________________\n",
            "softmax (Activation)         (None, 32, 301)           0         \n",
            "=================================================================\n",
            "Total params: 19,040,237\n",
            "Trainable params: 19,035,757\n",
            "Non-trainable params: 4,480\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUAXzClnb_fi"
      },
      "source": [
        "###ResNet Model with some layers added"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEsSxUv_b89U"
      },
      "source": [
        "INPUT_SHAPE = (32, 128, 1) # (img_rows, img_cols, img_channel)\n",
        "POOL_SIZE = (2, 2)\n",
        "POOL_SIZE2 = (2, 1)\n",
        "POOL_SIZE3 = (1, 2)\n",
        "KERNEL_SIZE = (3, 3)\n",
        "KERNEL_SIZE_F = (2, 2)\n",
        "REG = 0.0001\n",
        "from keras.layers import LSTM, Reshape, Input, Conv2D, MaxPool2D, Bidirectional\n",
        "\n",
        "def make_model():\n",
        "  base_model = ResNet50(include_top=False, weights=None, input_tensor=None, input_shape=INPUT_SHAPE)\n",
        "\n",
        "  x = MaxPooling2D((2, 1),\n",
        "                  #strides=(2, 2),\n",
        "                  name='block3_pool')(base_model.layers[38].output)\n",
        "\n",
        "\n",
        "  # Block 4\n",
        "  x = Conv2D(\n",
        "      512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
        "  x = Dropout(0.25)(x)\n",
        "  x = BatchNormalization(name='block4_BN')(x)\n",
        "  x = Conv2D(\n",
        "      512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
        "  x = Dropout(0.25)(x)\n",
        "  x = BatchNormalization(name='block5_BN')(x)\n",
        "  x = Conv2D(\n",
        "      512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
        "  #x = MaxPooling2D((2, 1),\n",
        "  #                 #strides=(2, 2),\n",
        "  #                 name='block4_pool')(x)\n",
        "  x = Dropout(0.25)(x)\n",
        "\n",
        "  x = BatchNormalization(name='block6_BN')(x)\n",
        "\n",
        "  # Block 5\n",
        "  x = Conv2D(\n",
        "      512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
        "  x = Dropout(0.25)(x)\n",
        "\n",
        "  x = BatchNormalization(name='block7_BN')(x)\n",
        "  x = Conv2D(\n",
        "      512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
        "  x = Conv2D(\n",
        "      512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
        "  x = BatchNormalization(name='block8_BN')(x)\n",
        "  x = MaxPooling2D((2, 1),\n",
        "                   #strides=(2, 2),\n",
        "                   name='block5_pool')(x)\n",
        "\n",
        "  # Block 6\n",
        "  conv_7 = Conv2D(512, (1, 1), activation = 'relu', name='block6_conv')(x)\n",
        "  #x = BatchNormalization(name='block6_BN')(x)\n",
        "\n",
        "  reshaped=  Reshape((32, 1024), name=\"reshape\") (conv_7)\n",
        "  #model.summary()\n",
        "    #squeezed = Lambda(lambda x: K.squeeze(x, 1), name='squeeze')(conv_7)\n",
        "\n",
        "  # bidirectional LSTM layers with units=128\n",
        "  #blstm_1 = Bidirectional(LSTM(512, return_sequences=True, dropout = 0.2,\n",
        "  #                kernel_regularizer=regularizers.l2(REG)))(squeezed)\n",
        "  gru_1 =  Bidirectional(GRU(512, return_sequences=True, dropout = 0.4,\n",
        "                  kernel_regularizer=regularizers.l2(REG)),\n",
        "                  name='bi_gru1')(reshaped)\n",
        "  x = Dropout(0.5)(gru_1)\n",
        "  #blstm_2 = Bidirectional(LSTM(512, return_sequences=True, dropout = 0.2,\n",
        "  #                kernel_regularizer=regularizers.l2(REG)))(blstm_1)\n",
        "  gru_2 =  Bidirectional(GRU(256, return_sequences=True, dropout = 0.2,\n",
        "                  kernel_regularizer=regularizers.l2(REG)),\n",
        "                  name='bi_gru2')(x)\n",
        "\n",
        "  x = Dropout(0.5)(gru_2)\n",
        "\n",
        "  outputs = Dense(len(char_list)+1, activation = 'softmax',\n",
        "                  kernel_regularizer=regularizers.l2(REG),\n",
        "                  name='dense1')(x)\n",
        "  #x = Dropout(0.25)(gru_2)\n",
        "  # model to be used at test time\n",
        "  model = Model(base_model.inputs, outputs)\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "\n",
        "my_model = make_model()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-60Eq0SDLlw"
      },
      "source": [
        "INPUT_SHAPE = (32, 128, 1)\n",
        "POOL_SIZE = (2, 2)\n",
        "KERNEL_SIZE = (3, 3)\n",
        "KERNEL_SIZE1 = (5, 5)\n",
        "KERNEL_SIZE_BN = (2, 2)\n",
        "REG = 0.01\n",
        "def create_model():\n",
        "  # Initialise a model\n",
        "  model = Sequential()\n",
        "  model.add(Convolution2D(filters=64, kernel_size = KERNEL_SIZE, input_shape=INPUT_SHAPE,\n",
        "                 use_bias=True,\n",
        "                 #strides=1,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv1'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 1), name='pool1'))\n",
        "\n",
        "  model.add(Convolution2D(filters=512, kernel_size = KERNEL_SIZE,\n",
        "                 #strides=1,\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv1'))\n",
        "  model.add(Activation('relu', name='activation1'))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "\n",
        "  model.add(Convolution2D(filters=512, kernel_size = KERNEL_SIZE,\n",
        "                 #strides=1,\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv2'))\n",
        "\n",
        "  model.add(Activation('relu', name='activation2'))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Convolution2D(filters=512, kernel_size = KERNEL_SIZE,\n",
        "                 #strides=1,\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv3'))\n",
        "\n",
        "  model.add(Activation('relu', name='activation3'))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Convolution2D(filters=512, kernel_size = KERNEL_SIZE,\n",
        "                 #strides=1,\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv4'))\n",
        "\n",
        "  model.add(Activation('relu', name='activation4'))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Convolution2D(filters=512, kernel_size = KERNEL_SIZE,\n",
        "                 #strides=1,\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv5'))\n",
        "  model.add(Activation('relu', name='activation5'))\n",
        "  model.add(Convolution2D(filters=512, kernel_size = KERNEL_SIZE,\n",
        "                 #strides=1,\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv6'))\n",
        "\n",
        "  model.add(Activation('relu', name='activation6'))\n",
        "  #model.add(Dropout(0.25))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 1), name='pool2'))\n",
        "\n",
        "  model.add(Convolution2D(filters=512, kernel_size = (1, 1),\n",
        "                 #strides=1,\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv7'))\n",
        "\n",
        "  model.add(Activation('relu', name='activation7'))\n",
        "  model.summary()\n",
        "\n",
        "  model.add(  Reshape((32, 1024), name=\"reshape\") )\n",
        "  #reshaped=  Reshape((32, 1024), name=\"reshape\") (conv_7)\n",
        "  #model.summary()\n",
        "    #squeezed = Lambda(lambda x: K.squeeze(x, 1), name='squeeze')(conv_7)\n",
        "\n",
        "  model.add(Bidirectional(GRU(512, return_sequences=True,\n",
        "                kernel_regularizer=regularizers.l2(REG), name='gru1')))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "\n",
        "  model.add(Bidirectional(GRU(512, return_sequences=True,\n",
        "                kernel_regularizer=regularizers.l2(REG), name='gru2')))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "  model.add(Dense(len(char_list)+1,\n",
        "                  kernel_regularizer=regularizers.l2(REG), name='outputs'))\n",
        "  model.add(Activation('softmax', name='softmax'))\n",
        "\n",
        "\n",
        "  #x = Dropout(0.25)(gru_2)\n",
        "  # model to be used at test time\n",
        "\n",
        " # model.summary()\n",
        "  return model\n",
        "\n",
        "\n",
        "my_model = make_model()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CH0hXTEf1U3n"
      },
      "source": [
        "# This is the model with the input length 16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtL6H_yEbtjj"
      },
      "source": [
        "INPUT_SHAPE = (32, 128, 1) # (img_rows, img_cols, img_channel)\n",
        "POOL_SIZE = (2, 2)\n",
        "POOL_SIZE2 = (2, 1)\n",
        "POOL_SIZE3 = (1, 2)\n",
        "KERNEL_SIZE = (3, 3)\n",
        "KERNEL_SIZE_F = (2, 2)\n",
        "REG = 0.0001\n",
        "from keras.layers import LSTM, Reshape, Input, Conv2D, MaxPool2D, Bidirectional\n",
        "\n",
        "def make_model():\n",
        "  base_model = ResNet50(include_top=False, weights=None, input_tensor=None, input_shape=INPUT_SHAPE)\n",
        "\n",
        "  x = base_model.layers[60].output\n",
        "\n",
        "\n",
        "  X = convolutional_block(x, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = (2,1))\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "\n",
        "      # Stage 5 (≈3 lines)\n",
        "  X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = (2,1))\n",
        "  X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "  X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "  reshaped=  Reshape((16, 2048), name=\"reshape\") (X)\n",
        "  #model.summary()\n",
        "    #squeezed = Lambda(lambda x: K.squeeze(x, 1), name='squeeze')(conv_7)\n",
        "\n",
        "  # bidirectional LSTM layers with units=128\n",
        "  #blstm_1 = Bidirectional(LSTM(512, return_sequences=True, dropout = 0.2,\n",
        "  #                kernel_regularizer=regularizers.l2(REG)))(squeezed)\n",
        "  gru_1 =  Bidirectional(GRU(512, return_sequences=True, dropout = 0.4,\n",
        "                  kernel_regularizer=regularizers.l2(REG)),\n",
        "                  name='bi_gru1')(reshaped)\n",
        "  #x = Dropout(0.5)(gru_1)\n",
        "  #blstm_2 = Bidirectional(LSTM(512, return_sequences=True, dropout = 0.2,\n",
        "  #                kernel_regularizer=regularizers.l2(REG)))(blstm_1)\n",
        "  gru_2 =  Bidirectional(GRU(256, return_sequences=True, dropout = 0.4,\n",
        "                  kernel_regularizer=regularizers.l2(REG)),\n",
        "                  name='bi_gru2')(gru_1)\n",
        "\n",
        "  #x = Dropout(0.5)(gru_2)\n",
        "\n",
        "  outputs = Dense(len(char_list)+1, activation = 'softmax',\n",
        "                  kernel_regularizer=regularizers.l2(REG),\n",
        "                  name='dense1')(gru_2)\n",
        "  #x = Dropout(0.25)(gru_2)\n",
        "  # model to be used at test time\n",
        "  model = Model(base_model.inputs, outputs)\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "\n",
        "my_model = make_model()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlMJhfakPkEm"
      },
      "source": [
        "#Pure ResNet Model including all layers except the TOP layer and the one achieved best performjance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpcVhjGymjlr"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhcaRm-Yb7p7"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dropout,Bidirectional, RNN,Reshape,Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D,MaxPooling2D, GlobalMaxPooling2D,Concatenate,GlobalAveragePooling2D,Lambda, GRU\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop, Adamax, Adadelta, Adagrad\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "\n",
        "#from resnets_utils import *\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow.keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_geOiF8zyB08"
      },
      "source": [
        "from tensorflow.keras.applications import VGG19,VGG16, ResNet50, MobileNet, Xception\n",
        "from tensorflow.python.keras import regularizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6sQHQkUWwEx"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ej48ceWXHAY"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIS0t0mbSaPW"
      },
      "source": [
        "!pip install keras==2.2.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx9tieObyOfR"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = (2,1)):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block as defined in Figure 4\n",
        "\n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "\n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "\n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path\n",
        "    X = Conv2D(F1, (1, 1), strides = s, name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Second component of main path (≈3 lines)\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "\n",
        "    # Third component of main path (≈2 lines)\n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "\n",
        "    ##### SHORTCUT PATH #### (≈2 lines)\n",
        "    X_shortcut = Conv2D(filters = F3, kernel_size = (1, 1), strides = s, padding = 'valid', name = conv_name_base + '1',\n",
        "                        kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROnlrzpLyVu0"
      },
      "source": [
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block as defined in Figure 3\n",
        "\n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "\n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "\n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    # Save the input value. You'll need this later to add back to the main path.\n",
        "    X_shortcut = X\n",
        "\n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "\n",
        "    # Second component of main path (≈3 lines)\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path (≈2 lines)\n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEPqnzONPijm",
        "outputId": "2150aa86-2667-47ad-c9a4-c419d38b771c"
      },
      "source": [
        "INPUT_SHAPE = (32, 128, 1) # (img_rows, img_cols, img_channel)\n",
        "POOL_SIZE = (2, 2)\n",
        "POOL_SIZE2 = (2, 1)\n",
        "POOL_SIZE3 = (1, 2)\n",
        "KERNEL_SIZE = (3, 3)\n",
        "KERNEL_SIZE_F = (2, 2)\n",
        "REG = 0.0001\n",
        "#from keras.layers import LSTM, Reshape, Input, Conv2D, MaxPool2D, Bidirectional\n",
        "\n",
        "def make_model():\n",
        "  base_model = ResNet50(include_top=False, weights=None, input_tensor=None, input_shape=INPUT_SHAPE)\n",
        "\n",
        "  X = base_model.layers[38].output\n",
        "\n",
        "\n",
        "  X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = (2,1))\n",
        "  X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "  X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "  X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "\n",
        "      # Stage 4 (≈6 lines)\n",
        "  X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = (2,1))\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "\n",
        "      # Stage 5 (≈3 lines)\n",
        "  X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = (2,1))\n",
        "  X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "  X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "  #X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
        "\n",
        "  reshaped=  Reshape((32, 2048), name=\"reshape\") (X)\n",
        "\n",
        "  gru_1 =  Bidirectional(GRU(512, return_sequences=True, dropout = 0.4,\n",
        "                  kernel_regularizer=regularizers.l2(REG)),\n",
        "                  name='bi_gru1')(reshaped)\n",
        "  x = Dropout(0.25)(gru_1)\n",
        "  #blstm_2 = Bidirectional(LSTM(512, return_sequences=True, dropout = 0.2,\n",
        "  #                kernel_regularizer=regularizers.l2(REG)))(blstm_1)\n",
        "  gru_2 =  Bidirectional(GRU(512, return_sequences=True, dropout = 0.4,\n",
        "                  kernel_regularizer=regularizers.l2(REG)),\n",
        "                  name='bi_gru2')(gru_1)\n",
        "\n",
        "  x = Dropout(0.25)(gru_2)\n",
        "\n",
        "  outputs = Dense(len(char_list)+1, activation = 'softmax',\n",
        "                  kernel_regularizer=regularizers.l2(REG),\n",
        "                  name='dense1')(gru_2)\n",
        "\n",
        "  model = Model(base_model.inputs, outputs)\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "my_model = make_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 128, 1)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 38, 134, 1)   0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 16, 64, 64)   3200        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 16, 64, 64)   256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 16, 64, 64)   0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 18, 66, 64)   0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 8, 32, 64)    0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 8, 32, 64)    4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 8, 32, 64)    256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 8, 32, 64)    0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 8, 32, 64)    36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 8, 32, 64)    256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 8, 32, 64)    0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 8, 32, 256)   16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 8, 32, 256)   16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 8, 32, 256)   1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 8, 32, 256)   1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 8, 32, 256)   0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 8, 32, 256)   0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 8, 32, 64)    16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 8, 32, 64)    256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 8, 32, 64)    0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 8, 32, 64)    36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 8, 32, 64)    256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 8, 32, 64)    0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 8, 32, 256)   16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 8, 32, 256)   1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 8, 32, 256)   0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 8, 32, 256)   0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 8, 32, 64)    16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 8, 32, 64)    256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 8, 32, 64)    0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 8, 32, 64)    36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 8, 32, 64)    256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 8, 32, 64)    0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 8, 32, 256)   16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 8, 32, 256)   1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 8, 32, 256)   0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 8, 32, 256)   0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 4, 32, 128)   32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 4, 32, 128)   512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 4, 32, 128)   0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 4, 32, 128)   147584      activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 4, 32, 128)   512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 4, 32, 128)   0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 4, 32, 512)   66048       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 4, 32, 512)   131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 4, 32, 512)   2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 4, 32, 512)   2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 4, 32, 512)   0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 4, 32, 512)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 4, 32, 128)   65664       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 4, 32, 128)   512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 4, 32, 128)   0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 4, 32, 128)   147584      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 4, 32, 128)   512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 4, 32, 128)   0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 4, 32, 512)   66048       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 4, 32, 512)   2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 4, 32, 512)   0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 4, 32, 512)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 4, 32, 128)   65664       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 4, 32, 128)   512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 4, 32, 128)   0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 4, 32, 128)   147584      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 4, 32, 128)   512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 4, 32, 128)   0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 4, 32, 512)   66048       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 4, 32, 512)   2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 4, 32, 512)   0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 4, 32, 512)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 4, 32, 128)   65664       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 4, 32, 128)   512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 4, 32, 128)   0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 4, 32, 128)   147584      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 4, 32, 128)   512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 4, 32, 128)   0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 4, 32, 512)   66048       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 4, 32, 512)   2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 4, 32, 512)   0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 4, 32, 512)   0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 2, 32, 256)   131328      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 2, 32, 256)   1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 2, 32, 256)   0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 2, 32, 256)   590080      activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 2, 32, 256)   1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 2, 32, 256)   0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 2, 32, 1024)  263168      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 2, 32, 1024)  525312      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 2, 32, 1024)  4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 2, 32, 1024)  4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 2, 32, 1024)  0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 2, 32, 1024)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 2, 32, 256)   262400      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 2, 32, 256)   1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 2, 32, 256)   0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 2, 32, 256)   590080      activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 2, 32, 256)   1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 2, 32, 256)   0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 2, 32, 1024)  263168      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 2, 32, 1024)  4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 2, 32, 1024)  0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 2, 32, 1024)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 2, 32, 256)   262400      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 2, 32, 256)   1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 2, 32, 256)   0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 2, 32, 256)   590080      activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 2, 32, 256)   1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 2, 32, 256)   0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 2, 32, 1024)  263168      activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 2, 32, 1024)  4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 2, 32, 1024)  0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 2, 32, 1024)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 2, 32, 256)   262400      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 2, 32, 256)   1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 2, 32, 256)   0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 2, 32, 256)   590080      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 2, 32, 256)   1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 2, 32, 256)   0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 2, 32, 1024)  263168      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 2, 32, 1024)  4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 2, 32, 1024)  0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 2, 32, 1024)  0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 2, 32, 256)   262400      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 2, 32, 256)   1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 2, 32, 256)   0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 2, 32, 256)   590080      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 2, 32, 256)   1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 2, 32, 256)   0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 2, 32, 1024)  263168      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 2, 32, 1024)  4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 2, 32, 1024)  0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 2, 32, 1024)  0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 2, 32, 256)   262400      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 2, 32, 256)   1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 2, 32, 256)   0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 2, 32, 256)   590080      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 2, 32, 256)   1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 2, 32, 256)   0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 2, 32, 1024)  263168      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 2, 32, 1024)  4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 2, 32, 1024)  0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 2, 32, 1024)  0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 1, 32, 512)   524800      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 1, 32, 512)   2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 1, 32, 512)   0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 1, 32, 512)   2359808     activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 1, 32, 512)   2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 1, 32, 512)   0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 1, 32, 2048)  1050624     activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 1, 32, 2048)  2099200     activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 1, 32, 2048)  8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 1, 32, 2048)  8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 1, 32, 2048)  0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 1, 32, 2048)  0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 1, 32, 512)   1049088     activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 1, 32, 512)   2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 1, 32, 512)   0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 1, 32, 512)   2359808     activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 1, 32, 512)   2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 1, 32, 512)   0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 1, 32, 2048)  1050624     activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 1, 32, 2048)  8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 1, 32, 2048)  0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 1, 32, 2048)  0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 1, 32, 512)   1049088     activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 1, 32, 512)   2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 1, 32, 512)   0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 1, 32, 512)   2359808     activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 1, 32, 512)   2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 1, 32, 512)   0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 1, 32, 2048)  1050624     activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 1, 32, 2048)  8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 1, 32, 2048)  0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 1, 32, 2048)  0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 32, 2048)     0           activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bi_gru1 (Bidirectional)         (None, 32, 1024)     7870464     reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bi_gru2 (Bidirectional)         (None, 32, 1024)     4724736     bi_gru1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense1 (Dense)                  (None, 32, 301)      308525      bi_gru2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 36,485,165\n",
            "Trainable params: 36,432,045\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbzUUJrASaVm"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKx14fU3FBNw"
      },
      "source": [
        "#This Resnet50 is the one developed from scratch since due to compatibility issue I cannot use the imported version from keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSbbqF-aE_8a"
      },
      "source": [
        "INPUT_SHAPE = (32, 128, 1) # (img_rows, img_cols, img_channel)\n",
        "POOL_SIZE = (2, 2)\n",
        "POOL_SIZE2 = (2, 1)\n",
        "POOL_SIZE3 = (1, 2)\n",
        "KERNEL_SIZE = (3, 3)\n",
        "KERNEL_SIZE_F = (2, 2)\n",
        "REG = 0.0001\n",
        "#from keras.layers import LSTM, Reshape, Input, Conv2D, MaxPool2D, Bidirectional\n",
        "\n",
        "def make_model():\n",
        "  #base_model = ResNet50(include_top=False, weights=None, input_tensor=None, input_shape=INPUT_SHAPE)\n",
        "\n",
        "  #X = base_model.layers[38].output\n",
        "  X_input = Input(INPUT_SHAPE)\n",
        "\n",
        "  X = ZeroPadding2D((3, 3))(X_input)\n",
        "  X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(X)\n",
        "  X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
        "  X = Activation('relu')(X)\n",
        "  X = ZeroPadding2D((1, 1), name='pool1_pad')(X)\n",
        "  X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "\n",
        "  X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=(1, 1))\n",
        "  X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "  X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "  X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = (2,1))\n",
        "  X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "  X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "  X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "\n",
        "      # Stage 4 (≈6 lines)\n",
        "  X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = (2,1))\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "  X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "\n",
        "      # Stage 5 (≈3 lines)\n",
        "  X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = (2,1))\n",
        "  X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "  X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "  #X = AveragePooling2D((2,2), name=\"avg_pool\")(X)\n",
        "\n",
        "  reshaped=  Reshape((32, 2048), name=\"reshape\") (X)\n",
        "\n",
        "  gru_1 =  Bidirectional(GRU(512, return_sequences=True, reset_after=True,dropout = 0.4,\n",
        "                  kernel_regularizer=regularizers.l2(REG)),\n",
        "                  name='bi_gru1')(reshaped)\n",
        "  x = Dropout(0.25)(gru_1)\n",
        "  #blstm_2 = Bidirectional(LSTM(512, return_sequences=True, dropout = 0.2,\n",
        "  #                kernel_regularizer=regularizers.l2(REG)))(blstm_1)\n",
        "  gru_2 =  Bidirectional(GRU(512, return_sequences=True, reset_after=True,dropout = 0.4,\n",
        "                  kernel_regularizer=regularizers.l2(REG)),\n",
        "                  name='bi_gru2')(gru_1)\n",
        "\n",
        "  x = Dropout(0.25)(gru_2)\n",
        "\n",
        "  outputs = Dense(len(char_list)+1, activation = 'softmax',\n",
        "                  kernel_regularizer=regularizers.l2(REG),\n",
        "                  name='dense1')(gru_2)\n",
        "\n",
        "  model = Model(X_input, outputs)\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "my_model = make_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gI8mXeaxfxsU"
      },
      "source": [
        "#DenseNet121 Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijTBQCJ6SfdW"
      },
      "source": [
        "from keras.engine import Layer, InputSpec\n",
        "try:\n",
        "    from keras import initializations\n",
        "except ImportError:\n",
        "    from keras import initializers as initializations\n",
        "import keras.backend as K\n",
        "\n",
        "class Scale(Layer):\n",
        "    '''Custom Layer for DenseNet used for BatchNormalization.\n",
        "\n",
        "    Learns a set of weights and biases used for scaling the input data.\n",
        "    the output consists simply in an element-wise multiplication of the input\n",
        "    and a sum of a set of constants:\n",
        "        out = in * gamma + beta,\n",
        "    where 'gamma' and 'beta' are the weights and biases larned.\n",
        "    # Arguments\n",
        "        axis: integer, axis along which to normalize in mode 0. For instance,\n",
        "            if your input tensor has shape (samples, channels, rows, cols),\n",
        "            set axis to 1 to normalize per feature map (channels axis).\n",
        "        momentum: momentum in the computation of the\n",
        "            exponential average of the mean and standard deviation\n",
        "            of the data, for feature-wise normalization.\n",
        "        weights: Initialization weights.\n",
        "            List of 2 Numpy arrays, with shapes:\n",
        "            `[(input_shape,), (input_shape,)]`\n",
        "        beta_init: name of initialization function for shift parameter\n",
        "            (see [initializations](../initializations.md)), or alternatively,\n",
        "            Theano/TensorFlow function to use for weights initialization.\n",
        "            This parameter is only relevant if you don't pass a `weights` argument.\n",
        "        gamma_init: name of initialization function for scale parameter (see\n",
        "            [initializations](../initializations.md)), or alternatively,\n",
        "            Theano/TensorFlow function to use for weights initialization.\n",
        "            This parameter is only relevant if you don't pass a `weights` argument.\n",
        "    '''\n",
        "    def __init__(self, weights=None, axis=-1, momentum = 0.9, beta_init='zero', gamma_init='one', **kwargs):\n",
        "        self.momentum = momentum\n",
        "        self.axis = axis\n",
        "        self.beta_init = initializations.get(beta_init)\n",
        "        self.gamma_init = initializations.get(gamma_init)\n",
        "        self.initial_weights = weights\n",
        "        super(Scale, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.input_spec = [InputSpec(shape=input_shape)]\n",
        "        shape = (int(input_shape[self.axis]),)\n",
        "\n",
        "        # Tensorflow >= 1.0.0 compatibility\n",
        "        self.gamma = K.variable(self.gamma_init(shape), name='{}_gamma'.format(self.name))\n",
        "        self.beta = K.variable(self.beta_init(shape), name='{}_beta'.format(self.name))\n",
        "        #self.gamma = self.gamma_init(shape, name='{}_gamma'.format(self.name))\n",
        "        #self.beta = self.beta_init(shape, name='{}_beta'.format(self.name))\n",
        "        self._trainable_weights = [self.gamma, self.beta]\n",
        "\n",
        "        if self.initial_weights is not None:\n",
        "            self.set_weights(self.initial_weights)\n",
        "            del self.initial_weights\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        input_shape = self.input_spec[0].shape\n",
        "        broadcast_shape = [1] * len(input_shape)\n",
        "        broadcast_shape[self.axis] = input_shape[self.axis]\n",
        "\n",
        "        out = K.reshape(self.gamma, broadcast_shape) * x + K.reshape(self.beta, broadcast_shape)\n",
        "        return out\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\"momentum\": self.momentum, \"axis\": self.axis}\n",
        "        base_config = super(Scale, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDH_bRLdSqku"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ART36hwfAQDw"
      },
      "source": [
        "def conv_blocktry(x, stage, branch, nb_filter, dropout_rate=None, weight_decay=1e-4):\n",
        "    '''Apply BatchNorm, Relu, bottleneck 1x1 Conv2D, 3x3 Conv2D, and option dropout\n",
        "        # Arguments\n",
        "            x: input tensor\n",
        "            stage: index for dense block\n",
        "            branch: layer index within each dense block\n",
        "            nb_filter: number of filters\n",
        "            dropout_rate: dropout rate\n",
        "            weight_decay: weight decay factor\n",
        "    '''\n",
        "    eps = 1.1e-5\n",
        "    conv_name_base = 'conv' + str(stage) + '_' + str(branch)\n",
        "    relu_name_base = 'relu' + str(stage) + '_' + str(branch)\n",
        "\n",
        "    # 1x1 Convolution (Bottleneck layer)\n",
        "    inter_channel = nb_filter * 4\n",
        "    x = BatchNormalization(epsilon=eps, axis=3, name=conv_name_base+'_x1_bn')(x)\n",
        "    x = Scale(axis=3, name=conv_name_base+'_x1_scale')(x)\n",
        "    x = Activation('relu', name=relu_name_base+'_x1')(x)\n",
        "    x = Conv2D(inter_channel, (1, 1), name=conv_name_base+'_x1', padding= 'same' ,use_bias=False)(x)\n",
        "    #print(\"ima from conv block\")\n",
        "    #print(x.shape)\n",
        "    #print(\"not a good idea\")\n",
        "    if dropout_rate:\n",
        "        x = Dropout(dropout_rate)(x)\n",
        "\n",
        "    # 3x3 Convolution\n",
        "    x = BatchNormalization(epsilon=eps, axis=3, name=conv_name_base+'_x2_bn')(x)\n",
        "    x = Scale(axis=3, name=conv_name_base+'_x2_scale')(x)\n",
        "    x = Activation('relu', name=relu_name_base+'_x2')(x)\n",
        "    #x = ZeroPadding2D((1, 1), name=conv_name_base+'_x2_zeropadding')(x)\n",
        "    x = Conv2D(nb_filter, (3, 3), name=conv_name_base+'_x2', padding = 'same', use_bias=False)(x)\n",
        "\n",
        "    if dropout_rate:\n",
        "        x = Dropout(dropout_rate)(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9ZibmAkS6SU"
      },
      "source": [
        "#transition block"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scJPJSAeSvaW"
      },
      "source": [
        "def transition_blocktry(x, stage, nb_filter, compression=1.0, dropout_rate=None, weight_decay=1E-4):\n",
        "    ''' Apply BatchNorm, 1x1 Convolution, averagePooling, optional compression, dropout\n",
        "        # Arguments\n",
        "            x: input tensor\n",
        "            stage: index for dense block\n",
        "            nb_filter: number of filters\n",
        "            compression: calculated as 1 - reduction. Reduces the number of feature maps in the transition block.\n",
        "            dropout_rate: dropout rate\n",
        "            weight_decay: weight decay factor\n",
        "    '''\n",
        "\n",
        "    eps = 1.1e-5\n",
        "    conv_name_base = 'conv' + str(stage) + '_blk'\n",
        "    relu_name_base = 'relu' + str(stage) + '_blk'\n",
        "    pool_name_base = 'pool' + str(stage)\n",
        "\n",
        "    x = BatchNormalization(epsilon=eps, axis=3, name=conv_name_base+'_bn')(x)\n",
        "    x = Scale(axis=3, name=conv_name_base+'_scale')(x)\n",
        "    x = Activation('relu', name=relu_name_base)(x)\n",
        "    x = Conv2D(int(nb_filter * compression), (1, 1), name=conv_name_base, use_bias=False)(x)\n",
        "\n",
        "    if dropout_rate:\n",
        "        x = Dropout(dropout_rate)(x)\n",
        "\n",
        "    x = AveragePooling2D((2, 1), strides=(2, 1), name=pool_name_base)(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYAOstVHTFf8"
      },
      "source": [
        "def dense_blocktry(x, stage, nb_layers, nb_filter, growth_rate, dropout_rate=None, weight_decay=1e-4, grow_nb_filters=True):\n",
        "    ''' Build a dense_block where the output of each conv_block is fed to subsequent ones\n",
        "        # Arguments\n",
        "            x: input tensor\n",
        "            stage: index for dense block\n",
        "            nb_layers: the number of layers of conv_block to append to the model.\n",
        "            nb_filter: number of filters\n",
        "            growth_rate: growth rate\n",
        "            dropout_rate: dropout rate\n",
        "            weight_decay: weight decay factor\n",
        "            grow_nb_filters: flag to decide to allow number of filters to grow\n",
        "    '''\n",
        "\n",
        "    eps = 1.1e-5\n",
        "    concat_feat = x\n",
        "    #print(concat_feat.shape)\n",
        "\n",
        "    for i in range(nb_layers):\n",
        "        branch = i+1\n",
        "        x = conv_blocktry(concat_feat, stage, branch, growth_rate, dropout_rate, weight_decay)\n",
        "        #print(x.shape)\n",
        "        concat_feat = Concatenate (axis=-1)([concat_feat, x])\n",
        "\n",
        "        if grow_nb_filters:\n",
        "            nb_filter += growth_rate\n",
        "\n",
        "    return concat_feat, nb_filter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nP5ahKvJXEzX",
        "outputId": "5af86acd-6d66-490d-8a1f-91c3ff6e2b69"
      },
      "source": [
        "print( K.image_data_format())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "channels_last\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zW6qPUbXToql"
      },
      "source": [
        "def DenseNettry(nb_dense_block=4, growth_rate=32, nb_filter=64, reduction=0.0, dropout_rate=0.0, weight_decay=1e-4, classes=1000, weights_path=None):\n",
        "    '''Instantiate the DenseNet 121 architecture,\n",
        "        # Arguments\n",
        "            nb_dense_block: number of dense blocks to add to end\n",
        "            growth_rate: number of filters to add per dense block\n",
        "            nb_filter: initial number of filters\n",
        "            reduction: reduction factor of transition blocks.\n",
        "            dropout_rate: dropout rate\n",
        "            weight_decay: weight decay factor\n",
        "            classes: optional number of classes to classify images\n",
        "            weights_path: path to pre-trained weights\n",
        "        # Returns\n",
        "            A Keras model instance.\n",
        "    '''\n",
        "    eps = 1.1e-5\n",
        "\n",
        "    # compute compression factor\n",
        "    compression = 1.0 - reduction\n",
        "\n",
        "    img_input = Input(shape=(32, 128, 1), name='data')\n",
        "    concat_axis = 3\n",
        "    #Handle Dimension Ordering for different backends\n",
        "    # global concat_axis\n",
        "    # if K.image_data_format() == 'tf':\n",
        "    #   concat_axis = 3\n",
        "    #   img_input = Input(shape=(224, 224, 3), name='data')\n",
        "    # else:\n",
        "    #   concat_axis = 1\n",
        "    #   img_input = Input(shape=(3, 224, 224), name='data')\n",
        "\n",
        "    # From architecture for ImageNet (Table 1 in the paper)\n",
        "    nb_filter = 64\n",
        "    nb_layers = [6,12,24,16] # For DenseNet-121\n",
        "\n",
        "    # Initial convolution\n",
        "    x = ZeroPadding2D((3, 3), name='conv1_zeropadding')(img_input)\n",
        "    x = Conv2D(nb_filter, (7, 7), strides=(2, 2), name='conv1', use_bias=False)(x)\n",
        "    x = BatchNormalization(epsilon=eps, axis = 3, name='conv1_bn')(x)\n",
        "    x = Scale(axis=3, name='conv1_scale')(x)\n",
        "    x = Activation('relu', name='relu1')(x)\n",
        "    x = ZeroPadding2D((1, 1), name='pool1_zeropadding')(x)\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2), name='pool1')(x)\n",
        "\n",
        "    # Add dense blocks\n",
        "    for block_idx in range(nb_dense_block - 1):\n",
        "        stage = block_idx+2\n",
        "        x, nb_filter = dense_blocktry(x, stage, nb_layers[block_idx], nb_filter, growth_rate, dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
        "\n",
        "        # Add transition_block\n",
        "        x = transition_blocktry(x, stage, nb_filter, compression=compression, dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
        "        nb_filter = int(nb_filter * compression)\n",
        "\n",
        "    final_stage = stage + 1\n",
        "    x, nb_filter = dense_blocktry(x, final_stage, nb_layers[-1], nb_filter, growth_rate, dropout_rate=dropout_rate, weight_decay=weight_decay)\n",
        "\n",
        "    x = BatchNormalization(epsilon=eps, axis=3, name='conv'+str(final_stage)+'_blk_bn')(x)\n",
        "    x = Scale(axis=3, name='conv'+str(final_stage)+'_blk_scale')(x)\n",
        "    x = Activation('relu', name='relu'+str(final_stage)+'_blk')(x)\n",
        "    #x = GlobalAveragePooling2D(name='pool'+str(final_stage))(x)\n",
        "    #x = AveragePooling2D((2, 2), strides=(2, 2), name=\"pool_name_base\")(x)\n",
        "\n",
        "    reshaped=  Reshape((32, 1920), name=\"reshape\") (x)\n",
        "\n",
        "    gru_1 =  Bidirectional(GRU(512, return_sequences=True, reset_after=True,dropout = 0.4,\n",
        "                  kernel_regularizer=regularizers.l2(REG)),\n",
        "                  name='bi_gru1')(reshaped)\n",
        "    x = Dropout(0.25)(gru_1)\n",
        "    #blstm_2 = Bidirectional(LSTM(512, return_sequences=True, dropout = 0.2,\n",
        "    #                kernel_regularizer=regularizers.l2(REG)))(blstm_1)\n",
        "    gru_2 =  Bidirectional(GRU(512, return_sequences=True,reset_after=True, dropout = 0.4,\n",
        "                  kernel_regularizer=regularizers.l2(REG)),\n",
        "                  name='bi_gru2')(gru_1)\n",
        "\n",
        "    x = Dropout(0.25)(gru_2)\n",
        "\n",
        "    outputs = Dense(len(char_list)+1, activation = 'softmax',\n",
        "                  kernel_regularizer=regularizers.l2(REG),\n",
        "                  name='dense1')(gru_2)\n",
        "\n",
        "    #model = Model(base_model.inputs, outputs)\n",
        "    #model.summary()\n",
        "\n",
        "\n",
        "    model = Model(img_input, outputs)\n",
        "    model.summary()\n",
        "\n",
        "\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLCYYZ2SCjyq"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbCZ9uenVizL",
        "outputId": "7c5a717a-f529-421b-ae35-eb3b08c3b54a"
      },
      "source": [
        "#my_model = make_model()\n",
        "REG = 0.0001\n",
        "my_model=DenseNettry()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tracking <tf.Variable 'conv1_scale/conv1_scale_gamma:0' shape=(64,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv1_scale/conv1_scale_beta:0' shape=(64,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv2_1_x1_scale/conv2_1_x1_scale_gamma:0' shape=(64,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv2_1_x1_scale/conv2_1_x1_scale_beta:0' shape=(64,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv2_1_x2_scale/conv2_1_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv2_1_x2_scale/conv2_1_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv2_2_x1_scale/conv2_2_x1_scale_gamma:0' shape=(96,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv2_2_x1_scale/conv2_2_x1_scale_beta:0' shape=(96,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv2_2_x2_scale/conv2_2_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv2_2_x2_scale/conv2_2_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv2_3_x1_scale/conv2_3_x1_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv2_3_x1_scale/conv2_3_x1_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv2_3_x2_scale/conv2_3_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv2_3_x2_scale/conv2_3_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv2_4_x1_scale/conv2_4_x1_scale_gamma:0' shape=(160,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv2_4_x1_scale/conv2_4_x1_scale_beta:0' shape=(160,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv2_4_x2_scale/conv2_4_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv2_4_x2_scale/conv2_4_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv2_5_x1_scale/conv2_5_x1_scale_gamma:0' shape=(192,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv2_5_x1_scale/conv2_5_x1_scale_beta:0' shape=(192,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv2_5_x2_scale/conv2_5_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv2_5_x2_scale/conv2_5_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv2_6_x1_scale/conv2_6_x1_scale_gamma:0' shape=(224,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv2_6_x1_scale/conv2_6_x1_scale_beta:0' shape=(224,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv2_6_x2_scale/conv2_6_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv2_6_x2_scale/conv2_6_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv2_blk_scale/conv2_blk_scale_gamma:0' shape=(256,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv2_blk_scale/conv2_blk_scale_beta:0' shape=(256,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_1_x1_scale/conv3_1_x1_scale_gamma:0' shape=(256,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_1_x1_scale/conv3_1_x1_scale_beta:0' shape=(256,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_1_x2_scale/conv3_1_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_1_x2_scale/conv3_1_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_2_x1_scale/conv3_2_x1_scale_gamma:0' shape=(288,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_2_x1_scale/conv3_2_x1_scale_beta:0' shape=(288,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_2_x2_scale/conv3_2_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_2_x2_scale/conv3_2_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_3_x1_scale/conv3_3_x1_scale_gamma:0' shape=(320,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_3_x1_scale/conv3_3_x1_scale_beta:0' shape=(320,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_3_x2_scale/conv3_3_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_3_x2_scale/conv3_3_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_4_x1_scale/conv3_4_x1_scale_gamma:0' shape=(352,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_4_x1_scale/conv3_4_x1_scale_beta:0' shape=(352,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_4_x2_scale/conv3_4_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_4_x2_scale/conv3_4_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_5_x1_scale/conv3_5_x1_scale_gamma:0' shape=(384,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_5_x1_scale/conv3_5_x1_scale_beta:0' shape=(384,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_5_x2_scale/conv3_5_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_5_x2_scale/conv3_5_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_6_x1_scale/conv3_6_x1_scale_gamma:0' shape=(416,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_6_x1_scale/conv3_6_x1_scale_beta:0' shape=(416,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_6_x2_scale/conv3_6_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_6_x2_scale/conv3_6_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_7_x1_scale/conv3_7_x1_scale_gamma:0' shape=(448,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_7_x1_scale/conv3_7_x1_scale_beta:0' shape=(448,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_7_x2_scale/conv3_7_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_7_x2_scale/conv3_7_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_8_x1_scale/conv3_8_x1_scale_gamma:0' shape=(480,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_8_x1_scale/conv3_8_x1_scale_beta:0' shape=(480,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_8_x2_scale/conv3_8_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_8_x2_scale/conv3_8_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_9_x1_scale/conv3_9_x1_scale_gamma:0' shape=(512,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_9_x1_scale/conv3_9_x1_scale_beta:0' shape=(512,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_9_x2_scale/conv3_9_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_9_x2_scale/conv3_9_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_10_x1_scale/conv3_10_x1_scale_gamma:0' shape=(544,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_10_x1_scale/conv3_10_x1_scale_beta:0' shape=(544,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_10_x2_scale/conv3_10_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_10_x2_scale/conv3_10_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_11_x1_scale/conv3_11_x1_scale_gamma:0' shape=(576,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_11_x1_scale/conv3_11_x1_scale_beta:0' shape=(576,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_11_x2_scale/conv3_11_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_11_x2_scale/conv3_11_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_12_x1_scale/conv3_12_x1_scale_gamma:0' shape=(608,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_12_x1_scale/conv3_12_x1_scale_beta:0' shape=(608,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_12_x2_scale/conv3_12_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_12_x2_scale/conv3_12_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv3_blk_scale/conv3_blk_scale_gamma:0' shape=(640,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv3_blk_scale/conv3_blk_scale_beta:0' shape=(640,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_1_x1_scale/conv4_1_x1_scale_gamma:0' shape=(640,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_1_x1_scale/conv4_1_x1_scale_beta:0' shape=(640,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_1_x2_scale/conv4_1_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_1_x2_scale/conv4_1_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_2_x1_scale/conv4_2_x1_scale_gamma:0' shape=(672,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_2_x1_scale/conv4_2_x1_scale_beta:0' shape=(672,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_2_x2_scale/conv4_2_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_2_x2_scale/conv4_2_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_3_x1_scale/conv4_3_x1_scale_gamma:0' shape=(704,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_3_x1_scale/conv4_3_x1_scale_beta:0' shape=(704,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_3_x2_scale/conv4_3_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_3_x2_scale/conv4_3_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_4_x1_scale/conv4_4_x1_scale_gamma:0' shape=(736,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_4_x1_scale/conv4_4_x1_scale_beta:0' shape=(736,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_4_x2_scale/conv4_4_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_4_x2_scale/conv4_4_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_5_x1_scale/conv4_5_x1_scale_gamma:0' shape=(768,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_5_x1_scale/conv4_5_x1_scale_beta:0' shape=(768,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_5_x2_scale/conv4_5_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_5_x2_scale/conv4_5_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_6_x1_scale/conv4_6_x1_scale_gamma:0' shape=(800,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_6_x1_scale/conv4_6_x1_scale_beta:0' shape=(800,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_6_x2_scale/conv4_6_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_6_x2_scale/conv4_6_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_7_x1_scale/conv4_7_x1_scale_gamma:0' shape=(832,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_7_x1_scale/conv4_7_x1_scale_beta:0' shape=(832,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_7_x2_scale/conv4_7_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_7_x2_scale/conv4_7_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_8_x1_scale/conv4_8_x1_scale_gamma:0' shape=(864,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_8_x1_scale/conv4_8_x1_scale_beta:0' shape=(864,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_8_x2_scale/conv4_8_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_8_x2_scale/conv4_8_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_9_x1_scale/conv4_9_x1_scale_gamma:0' shape=(896,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_9_x1_scale/conv4_9_x1_scale_beta:0' shape=(896,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_9_x2_scale/conv4_9_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_9_x2_scale/conv4_9_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_10_x1_scale/conv4_10_x1_scale_gamma:0' shape=(928,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_10_x1_scale/conv4_10_x1_scale_beta:0' shape=(928,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_10_x2_scale/conv4_10_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_10_x2_scale/conv4_10_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_11_x1_scale/conv4_11_x1_scale_gamma:0' shape=(960,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_11_x1_scale/conv4_11_x1_scale_beta:0' shape=(960,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_11_x2_scale/conv4_11_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_11_x2_scale/conv4_11_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_12_x1_scale/conv4_12_x1_scale_gamma:0' shape=(992,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_12_x1_scale/conv4_12_x1_scale_beta:0' shape=(992,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_12_x2_scale/conv4_12_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_12_x2_scale/conv4_12_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_13_x1_scale/conv4_13_x1_scale_gamma:0' shape=(1024,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_13_x1_scale/conv4_13_x1_scale_beta:0' shape=(1024,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_13_x2_scale/conv4_13_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_13_x2_scale/conv4_13_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_14_x1_scale/conv4_14_x1_scale_gamma:0' shape=(1056,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_14_x1_scale/conv4_14_x1_scale_beta:0' shape=(1056,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_14_x2_scale/conv4_14_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_14_x2_scale/conv4_14_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_15_x1_scale/conv4_15_x1_scale_gamma:0' shape=(1088,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_15_x1_scale/conv4_15_x1_scale_beta:0' shape=(1088,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_15_x2_scale/conv4_15_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_15_x2_scale/conv4_15_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_16_x1_scale/conv4_16_x1_scale_gamma:0' shape=(1120,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_16_x1_scale/conv4_16_x1_scale_beta:0' shape=(1120,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_16_x2_scale/conv4_16_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_16_x2_scale/conv4_16_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_17_x1_scale/conv4_17_x1_scale_gamma:0' shape=(1152,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_17_x1_scale/conv4_17_x1_scale_beta:0' shape=(1152,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_17_x2_scale/conv4_17_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_17_x2_scale/conv4_17_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_18_x1_scale/conv4_18_x1_scale_gamma:0' shape=(1184,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_18_x1_scale/conv4_18_x1_scale_beta:0' shape=(1184,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_18_x2_scale/conv4_18_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_18_x2_scale/conv4_18_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_19_x1_scale/conv4_19_x1_scale_gamma:0' shape=(1216,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_19_x1_scale/conv4_19_x1_scale_beta:0' shape=(1216,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_19_x2_scale/conv4_19_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_19_x2_scale/conv4_19_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_20_x1_scale/conv4_20_x1_scale_gamma:0' shape=(1248,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_20_x1_scale/conv4_20_x1_scale_beta:0' shape=(1248,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_20_x2_scale/conv4_20_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_20_x2_scale/conv4_20_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_21_x1_scale/conv4_21_x1_scale_gamma:0' shape=(1280,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_21_x1_scale/conv4_21_x1_scale_beta:0' shape=(1280,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_21_x2_scale/conv4_21_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_21_x2_scale/conv4_21_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_22_x1_scale/conv4_22_x1_scale_gamma:0' shape=(1312,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_22_x1_scale/conv4_22_x1_scale_beta:0' shape=(1312,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_22_x2_scale/conv4_22_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_22_x2_scale/conv4_22_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_23_x1_scale/conv4_23_x1_scale_gamma:0' shape=(1344,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_23_x1_scale/conv4_23_x1_scale_beta:0' shape=(1344,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_23_x2_scale/conv4_23_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_23_x2_scale/conv4_23_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_24_x1_scale/conv4_24_x1_scale_gamma:0' shape=(1376,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_24_x1_scale/conv4_24_x1_scale_beta:0' shape=(1376,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_24_x2_scale/conv4_24_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_24_x2_scale/conv4_24_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv4_blk_scale/conv4_blk_scale_gamma:0' shape=(1408,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv4_blk_scale/conv4_blk_scale_beta:0' shape=(1408,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_1_x1_scale/conv5_1_x1_scale_gamma:0' shape=(1408,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_1_x1_scale/conv5_1_x1_scale_beta:0' shape=(1408,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_1_x2_scale/conv5_1_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_1_x2_scale/conv5_1_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_2_x1_scale/conv5_2_x1_scale_gamma:0' shape=(1440,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_2_x1_scale/conv5_2_x1_scale_beta:0' shape=(1440,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_2_x2_scale/conv5_2_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_2_x2_scale/conv5_2_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_3_x1_scale/conv5_3_x1_scale_gamma:0' shape=(1472,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_3_x1_scale/conv5_3_x1_scale_beta:0' shape=(1472,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_3_x2_scale/conv5_3_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_3_x2_scale/conv5_3_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_4_x1_scale/conv5_4_x1_scale_gamma:0' shape=(1504,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_4_x1_scale/conv5_4_x1_scale_beta:0' shape=(1504,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_4_x2_scale/conv5_4_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_4_x2_scale/conv5_4_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_5_x1_scale/conv5_5_x1_scale_gamma:0' shape=(1536,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_5_x1_scale/conv5_5_x1_scale_beta:0' shape=(1536,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_5_x2_scale/conv5_5_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_5_x2_scale/conv5_5_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_6_x1_scale/conv5_6_x1_scale_gamma:0' shape=(1568,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_6_x1_scale/conv5_6_x1_scale_beta:0' shape=(1568,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_6_x2_scale/conv5_6_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_6_x2_scale/conv5_6_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_7_x1_scale/conv5_7_x1_scale_gamma:0' shape=(1600,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_7_x1_scale/conv5_7_x1_scale_beta:0' shape=(1600,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_7_x2_scale/conv5_7_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_7_x2_scale/conv5_7_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_8_x1_scale/conv5_8_x1_scale_gamma:0' shape=(1632,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_8_x1_scale/conv5_8_x1_scale_beta:0' shape=(1632,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_8_x2_scale/conv5_8_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_8_x2_scale/conv5_8_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_9_x1_scale/conv5_9_x1_scale_gamma:0' shape=(1664,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_9_x1_scale/conv5_9_x1_scale_beta:0' shape=(1664,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_9_x2_scale/conv5_9_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_9_x2_scale/conv5_9_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_10_x1_scale/conv5_10_x1_scale_gamma:0' shape=(1696,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_10_x1_scale/conv5_10_x1_scale_beta:0' shape=(1696,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_10_x2_scale/conv5_10_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_10_x2_scale/conv5_10_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_11_x1_scale/conv5_11_x1_scale_gamma:0' shape=(1728,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_11_x1_scale/conv5_11_x1_scale_beta:0' shape=(1728,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_11_x2_scale/conv5_11_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_11_x2_scale/conv5_11_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_12_x1_scale/conv5_12_x1_scale_gamma:0' shape=(1760,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_12_x1_scale/conv5_12_x1_scale_beta:0' shape=(1760,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_12_x2_scale/conv5_12_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_12_x2_scale/conv5_12_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_13_x1_scale/conv5_13_x1_scale_gamma:0' shape=(1792,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_13_x1_scale/conv5_13_x1_scale_beta:0' shape=(1792,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_13_x2_scale/conv5_13_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_13_x2_scale/conv5_13_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_14_x1_scale/conv5_14_x1_scale_gamma:0' shape=(1824,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_14_x1_scale/conv5_14_x1_scale_beta:0' shape=(1824,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_14_x2_scale/conv5_14_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_14_x2_scale/conv5_14_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_15_x1_scale/conv5_15_x1_scale_gamma:0' shape=(1856,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_15_x1_scale/conv5_15_x1_scale_beta:0' shape=(1856,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_15_x2_scale/conv5_15_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_15_x2_scale/conv5_15_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_16_x1_scale/conv5_16_x1_scale_gamma:0' shape=(1888,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_16_x1_scale/conv5_16_x1_scale_beta:0' shape=(1888,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_16_x2_scale/conv5_16_x2_scale_gamma:0' shape=(128,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_16_x2_scale/conv5_16_x2_scale_beta:0' shape=(128,) dtype=float32> beta\n",
            "tracking <tf.Variable 'conv5_blk_scale/conv5_blk_scale_gamma:0' shape=(1920,) dtype=float32> gamma\n",
            "tracking <tf.Variable 'conv5_blk_scale/conv5_blk_scale_beta:0' shape=(1920,) dtype=float32> beta\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "data (InputLayer)               (None, 32, 128, 1)   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_zeropadding (ZeroPadding2 (None, 38, 134, 1)   0           data[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 16, 64, 64)   3136        conv1_zeropadding[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 16, 64, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv1_scale (Scale)             (None, 16, 64, 64)   128         conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "relu1 (Activation)              (None, 16, 64, 64)   0           conv1_scale[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "pool1_zeropadding (ZeroPadding2 (None, 18, 66, 64)   0           relu1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "pool1 (MaxPooling2D)            (None, 8, 32, 64)    0           pool1_zeropadding[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_x1_bn (BatchNormalizati (None, 8, 32, 64)    256         pool1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_x1_scale (Scale)        (None, 8, 32, 64)    128         conv2_1_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu2_1_x1 (Activation)         (None, 8, 32, 64)    0           conv2_1_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_x1 (Conv2D)             (None, 8, 32, 128)   8192        relu2_1_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_x2_bn (BatchNormalizati (None, 8, 32, 128)   512         conv2_1_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_x2_scale (Scale)        (None, 8, 32, 128)   256         conv2_1_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu2_1_x2 (Activation)         (None, 8, 32, 128)   0           conv2_1_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_1_x2 (Conv2D)             (None, 8, 32, 32)    36864       relu2_1_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 8, 32, 96)    0           pool1[0][0]                      \n",
            "                                                                 conv2_1_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_x1_bn (BatchNormalizati (None, 8, 32, 96)    384         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_x1_scale (Scale)        (None, 8, 32, 96)    192         conv2_2_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu2_2_x1 (Activation)         (None, 8, 32, 96)    0           conv2_2_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_x1 (Conv2D)             (None, 8, 32, 128)   12288       relu2_2_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_x2_bn (BatchNormalizati (None, 8, 32, 128)   512         conv2_2_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_x2_scale (Scale)        (None, 8, 32, 128)   256         conv2_2_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu2_2_x2 (Activation)         (None, 8, 32, 128)   0           conv2_2_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_2_x2 (Conv2D)             (None, 8, 32, 32)    36864       relu2_2_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 8, 32, 128)   0           concatenate_1[0][0]              \n",
            "                                                                 conv2_2_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_x1_bn (BatchNormalizati (None, 8, 32, 128)   512         concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_x1_scale (Scale)        (None, 8, 32, 128)   256         conv2_3_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu2_3_x1 (Activation)         (None, 8, 32, 128)   0           conv2_3_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_x1 (Conv2D)             (None, 8, 32, 128)   16384       relu2_3_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_x2_bn (BatchNormalizati (None, 8, 32, 128)   512         conv2_3_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_x2_scale (Scale)        (None, 8, 32, 128)   256         conv2_3_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu2_3_x2 (Activation)         (None, 8, 32, 128)   0           conv2_3_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_3_x2 (Conv2D)             (None, 8, 32, 32)    36864       relu2_3_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 8, 32, 160)   0           concatenate_2[0][0]              \n",
            "                                                                 conv2_3_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_4_x1_bn (BatchNormalizati (None, 8, 32, 160)   640         concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_4_x1_scale (Scale)        (None, 8, 32, 160)   320         conv2_4_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu2_4_x1 (Activation)         (None, 8, 32, 160)   0           conv2_4_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_4_x1 (Conv2D)             (None, 8, 32, 128)   20480       relu2_4_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_4_x2_bn (BatchNormalizati (None, 8, 32, 128)   512         conv2_4_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_4_x2_scale (Scale)        (None, 8, 32, 128)   256         conv2_4_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu2_4_x2 (Activation)         (None, 8, 32, 128)   0           conv2_4_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_4_x2 (Conv2D)             (None, 8, 32, 32)    36864       relu2_4_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 8, 32, 192)   0           concatenate_3[0][0]              \n",
            "                                                                 conv2_4_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_5_x1_bn (BatchNormalizati (None, 8, 32, 192)   768         concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_5_x1_scale (Scale)        (None, 8, 32, 192)   384         conv2_5_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu2_5_x1 (Activation)         (None, 8, 32, 192)   0           conv2_5_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_5_x1 (Conv2D)             (None, 8, 32, 128)   24576       relu2_5_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_5_x2_bn (BatchNormalizati (None, 8, 32, 128)   512         conv2_5_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_5_x2_scale (Scale)        (None, 8, 32, 128)   256         conv2_5_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu2_5_x2 (Activation)         (None, 8, 32, 128)   0           conv2_5_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_5_x2 (Conv2D)             (None, 8, 32, 32)    36864       relu2_5_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 8, 32, 224)   0           concatenate_4[0][0]              \n",
            "                                                                 conv2_5_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_6_x1_bn (BatchNormalizati (None, 8, 32, 224)   896         concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_6_x1_scale (Scale)        (None, 8, 32, 224)   448         conv2_6_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu2_6_x1 (Activation)         (None, 8, 32, 224)   0           conv2_6_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_6_x1 (Conv2D)             (None, 8, 32, 128)   28672       relu2_6_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_6_x2_bn (BatchNormalizati (None, 8, 32, 128)   512         conv2_6_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_6_x2_scale (Scale)        (None, 8, 32, 128)   256         conv2_6_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu2_6_x2 (Activation)         (None, 8, 32, 128)   0           conv2_6_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_6_x2 (Conv2D)             (None, 8, 32, 32)    36864       relu2_6_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 8, 32, 256)   0           concatenate_5[0][0]              \n",
            "                                                                 conv2_6_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_blk_bn (BatchNormalizatio (None, 8, 32, 256)   1024        concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2_blk_scale (Scale)         (None, 8, 32, 256)   512         conv2_blk_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "relu2_blk (Activation)          (None, 8, 32, 256)   0           conv2_blk_scale[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2_blk (Conv2D)              (None, 8, 32, 256)   65536       relu2_blk[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "pool2 (AveragePooling2D)        (None, 4, 32, 256)   0           conv2_blk[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_x1_bn (BatchNormalizati (None, 4, 32, 256)   1024        pool2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_x1_scale (Scale)        (None, 4, 32, 256)   512         conv3_1_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_1_x1 (Activation)         (None, 4, 32, 256)   0           conv3_1_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_x1 (Conv2D)             (None, 4, 32, 128)   32768       relu3_1_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_x2_bn (BatchNormalizati (None, 4, 32, 128)   512         conv3_1_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_x2_scale (Scale)        (None, 4, 32, 128)   256         conv3_1_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_1_x2 (Activation)         (None, 4, 32, 128)   0           conv3_1_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_1_x2 (Conv2D)             (None, 4, 32, 32)    36864       relu3_1_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 4, 32, 288)   0           pool2[0][0]                      \n",
            "                                                                 conv3_1_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_x1_bn (BatchNormalizati (None, 4, 32, 288)   1152        concatenate_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_x1_scale (Scale)        (None, 4, 32, 288)   576         conv3_2_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_2_x1 (Activation)         (None, 4, 32, 288)   0           conv3_2_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_x1 (Conv2D)             (None, 4, 32, 128)   36864       relu3_2_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_x2_bn (BatchNormalizati (None, 4, 32, 128)   512         conv3_2_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_x2_scale (Scale)        (None, 4, 32, 128)   256         conv3_2_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_2_x2 (Activation)         (None, 4, 32, 128)   0           conv3_2_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_2_x2 (Conv2D)             (None, 4, 32, 32)    36864       relu3_2_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 4, 32, 320)   0           concatenate_7[0][0]              \n",
            "                                                                 conv3_2_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_x1_bn (BatchNormalizati (None, 4, 32, 320)   1280        concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_x1_scale (Scale)        (None, 4, 32, 320)   640         conv3_3_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_3_x1 (Activation)         (None, 4, 32, 320)   0           conv3_3_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_x1 (Conv2D)             (None, 4, 32, 128)   40960       relu3_3_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_x2_bn (BatchNormalizati (None, 4, 32, 128)   512         conv3_3_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_x2_scale (Scale)        (None, 4, 32, 128)   256         conv3_3_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_3_x2 (Activation)         (None, 4, 32, 128)   0           conv3_3_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_3_x2 (Conv2D)             (None, 4, 32, 32)    36864       relu3_3_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 4, 32, 352)   0           concatenate_8[0][0]              \n",
            "                                                                 conv3_3_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_x1_bn (BatchNormalizati (None, 4, 32, 352)   1408        concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_x1_scale (Scale)        (None, 4, 32, 352)   704         conv3_4_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_4_x1 (Activation)         (None, 4, 32, 352)   0           conv3_4_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_x1 (Conv2D)             (None, 4, 32, 128)   45056       relu3_4_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_x2_bn (BatchNormalizati (None, 4, 32, 128)   512         conv3_4_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_x2_scale (Scale)        (None, 4, 32, 128)   256         conv3_4_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_4_x2 (Activation)         (None, 4, 32, 128)   0           conv3_4_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_4_x2 (Conv2D)             (None, 4, 32, 32)    36864       relu3_4_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 4, 32, 384)   0           concatenate_9[0][0]              \n",
            "                                                                 conv3_4_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_5_x1_bn (BatchNormalizati (None, 4, 32, 384)   1536        concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_5_x1_scale (Scale)        (None, 4, 32, 384)   768         conv3_5_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_5_x1 (Activation)         (None, 4, 32, 384)   0           conv3_5_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_5_x1 (Conv2D)             (None, 4, 32, 128)   49152       relu3_5_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_5_x2_bn (BatchNormalizati (None, 4, 32, 128)   512         conv3_5_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_5_x2_scale (Scale)        (None, 4, 32, 128)   256         conv3_5_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_5_x2 (Activation)         (None, 4, 32, 128)   0           conv3_5_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_5_x2 (Conv2D)             (None, 4, 32, 32)    36864       relu3_5_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 4, 32, 416)   0           concatenate_10[0][0]             \n",
            "                                                                 conv3_5_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_6_x1_bn (BatchNormalizati (None, 4, 32, 416)   1664        concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_6_x1_scale (Scale)        (None, 4, 32, 416)   832         conv3_6_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_6_x1 (Activation)         (None, 4, 32, 416)   0           conv3_6_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_6_x1 (Conv2D)             (None, 4, 32, 128)   53248       relu3_6_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_6_x2_bn (BatchNormalizati (None, 4, 32, 128)   512         conv3_6_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_6_x2_scale (Scale)        (None, 4, 32, 128)   256         conv3_6_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_6_x2 (Activation)         (None, 4, 32, 128)   0           conv3_6_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_6_x2 (Conv2D)             (None, 4, 32, 32)    36864       relu3_6_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 4, 32, 448)   0           concatenate_11[0][0]             \n",
            "                                                                 conv3_6_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_7_x1_bn (BatchNormalizati (None, 4, 32, 448)   1792        concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_7_x1_scale (Scale)        (None, 4, 32, 448)   896         conv3_7_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_7_x1 (Activation)         (None, 4, 32, 448)   0           conv3_7_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_7_x1 (Conv2D)             (None, 4, 32, 128)   57344       relu3_7_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_7_x2_bn (BatchNormalizati (None, 4, 32, 128)   512         conv3_7_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_7_x2_scale (Scale)        (None, 4, 32, 128)   256         conv3_7_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_7_x2 (Activation)         (None, 4, 32, 128)   0           conv3_7_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_7_x2 (Conv2D)             (None, 4, 32, 32)    36864       relu3_7_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 4, 32, 480)   0           concatenate_12[0][0]             \n",
            "                                                                 conv3_7_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_8_x1_bn (BatchNormalizati (None, 4, 32, 480)   1920        concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_8_x1_scale (Scale)        (None, 4, 32, 480)   960         conv3_8_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_8_x1 (Activation)         (None, 4, 32, 480)   0           conv3_8_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_8_x1 (Conv2D)             (None, 4, 32, 128)   61440       relu3_8_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_8_x2_bn (BatchNormalizati (None, 4, 32, 128)   512         conv3_8_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_8_x2_scale (Scale)        (None, 4, 32, 128)   256         conv3_8_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_8_x2 (Activation)         (None, 4, 32, 128)   0           conv3_8_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_8_x2 (Conv2D)             (None, 4, 32, 32)    36864       relu3_8_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 4, 32, 512)   0           concatenate_13[0][0]             \n",
            "                                                                 conv3_8_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_9_x1_bn (BatchNormalizati (None, 4, 32, 512)   2048        concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_9_x1_scale (Scale)        (None, 4, 32, 512)   1024        conv3_9_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_9_x1 (Activation)         (None, 4, 32, 512)   0           conv3_9_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_9_x1 (Conv2D)             (None, 4, 32, 128)   65536       relu3_9_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_9_x2_bn (BatchNormalizati (None, 4, 32, 128)   512         conv3_9_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_9_x2_scale (Scale)        (None, 4, 32, 128)   256         conv3_9_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu3_9_x2 (Activation)         (None, 4, 32, 128)   0           conv3_9_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_9_x2 (Conv2D)             (None, 4, 32, 32)    36864       relu3_9_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 4, 32, 544)   0           concatenate_14[0][0]             \n",
            "                                                                 conv3_9_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv3_10_x1_bn (BatchNormalizat (None, 4, 32, 544)   2176        concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_10_x1_scale (Scale)       (None, 4, 32, 544)   1088        conv3_10_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu3_10_x1 (Activation)        (None, 4, 32, 544)   0           conv3_10_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_10_x1 (Conv2D)            (None, 4, 32, 128)   69632       relu3_10_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3_10_x2_bn (BatchNormalizat (None, 4, 32, 128)   512         conv3_10_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3_10_x2_scale (Scale)       (None, 4, 32, 128)   256         conv3_10_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu3_10_x2 (Activation)        (None, 4, 32, 128)   0           conv3_10_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_10_x2 (Conv2D)            (None, 4, 32, 32)    36864       relu3_10_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 4, 32, 576)   0           concatenate_15[0][0]             \n",
            "                                                                 conv3_10_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3_11_x1_bn (BatchNormalizat (None, 4, 32, 576)   2304        concatenate_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_11_x1_scale (Scale)       (None, 4, 32, 576)   1152        conv3_11_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu3_11_x1 (Activation)        (None, 4, 32, 576)   0           conv3_11_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_11_x1 (Conv2D)            (None, 4, 32, 128)   73728       relu3_11_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3_11_x2_bn (BatchNormalizat (None, 4, 32, 128)   512         conv3_11_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3_11_x2_scale (Scale)       (None, 4, 32, 128)   256         conv3_11_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu3_11_x2 (Activation)        (None, 4, 32, 128)   0           conv3_11_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_11_x2 (Conv2D)            (None, 4, 32, 32)    36864       relu3_11_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 4, 32, 608)   0           concatenate_16[0][0]             \n",
            "                                                                 conv3_11_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3_12_x1_bn (BatchNormalizat (None, 4, 32, 608)   2432        concatenate_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_12_x1_scale (Scale)       (None, 4, 32, 608)   1216        conv3_12_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu3_12_x1 (Activation)        (None, 4, 32, 608)   0           conv3_12_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_12_x1 (Conv2D)            (None, 4, 32, 128)   77824       relu3_12_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3_12_x2_bn (BatchNormalizat (None, 4, 32, 128)   512         conv3_12_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3_12_x2_scale (Scale)       (None, 4, 32, 128)   256         conv3_12_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu3_12_x2 (Activation)        (None, 4, 32, 128)   0           conv3_12_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_12_x2 (Conv2D)            (None, 4, 32, 32)    36864       relu3_12_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 4, 32, 640)   0           concatenate_17[0][0]             \n",
            "                                                                 conv3_12_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3_blk_bn (BatchNormalizatio (None, 4, 32, 640)   2560        concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv3_blk_scale (Scale)         (None, 4, 32, 640)   1280        conv3_blk_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "relu3_blk (Activation)          (None, 4, 32, 640)   0           conv3_blk_scale[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv3_blk (Conv2D)              (None, 4, 32, 640)   409600      relu3_blk[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "pool3 (AveragePooling2D)        (None, 2, 32, 640)   0           conv3_blk[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_x1_bn (BatchNormalizati (None, 2, 32, 640)   2560        pool3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_x1_scale (Scale)        (None, 2, 32, 640)   1280        conv4_1_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_1_x1 (Activation)         (None, 2, 32, 640)   0           conv4_1_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_x1 (Conv2D)             (None, 2, 32, 128)   81920       relu4_1_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_x2_bn (BatchNormalizati (None, 2, 32, 128)   512         conv4_1_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_x2_scale (Scale)        (None, 2, 32, 128)   256         conv4_1_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_1_x2 (Activation)         (None, 2, 32, 128)   0           conv4_1_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_1_x2 (Conv2D)             (None, 2, 32, 32)    36864       relu4_1_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 2, 32, 672)   0           pool3[0][0]                      \n",
            "                                                                 conv4_1_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_x1_bn (BatchNormalizati (None, 2, 32, 672)   2688        concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_x1_scale (Scale)        (None, 2, 32, 672)   1344        conv4_2_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_2_x1 (Activation)         (None, 2, 32, 672)   0           conv4_2_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_x1 (Conv2D)             (None, 2, 32, 128)   86016       relu4_2_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_x2_bn (BatchNormalizati (None, 2, 32, 128)   512         conv4_2_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_x2_scale (Scale)        (None, 2, 32, 128)   256         conv4_2_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_2_x2 (Activation)         (None, 2, 32, 128)   0           conv4_2_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_2_x2 (Conv2D)             (None, 2, 32, 32)    36864       relu4_2_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_20 (Concatenate)    (None, 2, 32, 704)   0           concatenate_19[0][0]             \n",
            "                                                                 conv4_2_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_x1_bn (BatchNormalizati (None, 2, 32, 704)   2816        concatenate_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_x1_scale (Scale)        (None, 2, 32, 704)   1408        conv4_3_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_3_x1 (Activation)         (None, 2, 32, 704)   0           conv4_3_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_x1 (Conv2D)             (None, 2, 32, 128)   90112       relu4_3_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_x2_bn (BatchNormalizati (None, 2, 32, 128)   512         conv4_3_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_x2_scale (Scale)        (None, 2, 32, 128)   256         conv4_3_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_3_x2 (Activation)         (None, 2, 32, 128)   0           conv4_3_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_3_x2 (Conv2D)             (None, 2, 32, 32)    36864       relu4_3_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_21 (Concatenate)    (None, 2, 32, 736)   0           concatenate_20[0][0]             \n",
            "                                                                 conv4_3_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_x1_bn (BatchNormalizati (None, 2, 32, 736)   2944        concatenate_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_x1_scale (Scale)        (None, 2, 32, 736)   1472        conv4_4_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_4_x1 (Activation)         (None, 2, 32, 736)   0           conv4_4_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_x1 (Conv2D)             (None, 2, 32, 128)   94208       relu4_4_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_x2_bn (BatchNormalizati (None, 2, 32, 128)   512         conv4_4_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_x2_scale (Scale)        (None, 2, 32, 128)   256         conv4_4_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_4_x2 (Activation)         (None, 2, 32, 128)   0           conv4_4_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_4_x2 (Conv2D)             (None, 2, 32, 32)    36864       relu4_4_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_22 (Concatenate)    (None, 2, 32, 768)   0           concatenate_21[0][0]             \n",
            "                                                                 conv4_4_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_x1_bn (BatchNormalizati (None, 2, 32, 768)   3072        concatenate_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_x1_scale (Scale)        (None, 2, 32, 768)   1536        conv4_5_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_5_x1 (Activation)         (None, 2, 32, 768)   0           conv4_5_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_x1 (Conv2D)             (None, 2, 32, 128)   98304       relu4_5_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_x2_bn (BatchNormalizati (None, 2, 32, 128)   512         conv4_5_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_x2_scale (Scale)        (None, 2, 32, 128)   256         conv4_5_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_5_x2 (Activation)         (None, 2, 32, 128)   0           conv4_5_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_5_x2 (Conv2D)             (None, 2, 32, 32)    36864       relu4_5_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_23 (Concatenate)    (None, 2, 32, 800)   0           concatenate_22[0][0]             \n",
            "                                                                 conv4_5_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_x1_bn (BatchNormalizati (None, 2, 32, 800)   3200        concatenate_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_x1_scale (Scale)        (None, 2, 32, 800)   1600        conv4_6_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_6_x1 (Activation)         (None, 2, 32, 800)   0           conv4_6_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_x1 (Conv2D)             (None, 2, 32, 128)   102400      relu4_6_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_x2_bn (BatchNormalizati (None, 2, 32, 128)   512         conv4_6_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_x2_scale (Scale)        (None, 2, 32, 128)   256         conv4_6_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_6_x2 (Activation)         (None, 2, 32, 128)   0           conv4_6_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_6_x2 (Conv2D)             (None, 2, 32, 32)    36864       relu4_6_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 2, 32, 832)   0           concatenate_23[0][0]             \n",
            "                                                                 conv4_6_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_7_x1_bn (BatchNormalizati (None, 2, 32, 832)   3328        concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_7_x1_scale (Scale)        (None, 2, 32, 832)   1664        conv4_7_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_7_x1 (Activation)         (None, 2, 32, 832)   0           conv4_7_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_7_x1 (Conv2D)             (None, 2, 32, 128)   106496      relu4_7_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_7_x2_bn (BatchNormalizati (None, 2, 32, 128)   512         conv4_7_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_7_x2_scale (Scale)        (None, 2, 32, 128)   256         conv4_7_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_7_x2 (Activation)         (None, 2, 32, 128)   0           conv4_7_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_7_x2 (Conv2D)             (None, 2, 32, 32)    36864       relu4_7_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 2, 32, 864)   0           concatenate_24[0][0]             \n",
            "                                                                 conv4_7_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_8_x1_bn (BatchNormalizati (None, 2, 32, 864)   3456        concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_8_x1_scale (Scale)        (None, 2, 32, 864)   1728        conv4_8_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_8_x1 (Activation)         (None, 2, 32, 864)   0           conv4_8_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_8_x1 (Conv2D)             (None, 2, 32, 128)   110592      relu4_8_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_8_x2_bn (BatchNormalizati (None, 2, 32, 128)   512         conv4_8_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_8_x2_scale (Scale)        (None, 2, 32, 128)   256         conv4_8_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_8_x2 (Activation)         (None, 2, 32, 128)   0           conv4_8_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_8_x2 (Conv2D)             (None, 2, 32, 32)    36864       relu4_8_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_26 (Concatenate)    (None, 2, 32, 896)   0           concatenate_25[0][0]             \n",
            "                                                                 conv4_8_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_9_x1_bn (BatchNormalizati (None, 2, 32, 896)   3584        concatenate_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_9_x1_scale (Scale)        (None, 2, 32, 896)   1792        conv4_9_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_9_x1 (Activation)         (None, 2, 32, 896)   0           conv4_9_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_9_x1 (Conv2D)             (None, 2, 32, 128)   114688      relu4_9_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_9_x2_bn (BatchNormalizati (None, 2, 32, 128)   512         conv4_9_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_9_x2_scale (Scale)        (None, 2, 32, 128)   256         conv4_9_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu4_9_x2 (Activation)         (None, 2, 32, 128)   0           conv4_9_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_9_x2 (Conv2D)             (None, 2, 32, 32)    36864       relu4_9_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_27 (Concatenate)    (None, 2, 32, 928)   0           concatenate_26[0][0]             \n",
            "                                                                 conv4_9_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv4_10_x1_bn (BatchNormalizat (None, 2, 32, 928)   3712        concatenate_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_10_x1_scale (Scale)       (None, 2, 32, 928)   1856        conv4_10_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_10_x1 (Activation)        (None, 2, 32, 928)   0           conv4_10_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_10_x1 (Conv2D)            (None, 2, 32, 128)   118784      relu4_10_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_10_x2_bn (BatchNormalizat (None, 2, 32, 128)   512         conv4_10_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_10_x2_scale (Scale)       (None, 2, 32, 128)   256         conv4_10_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_10_x2 (Activation)        (None, 2, 32, 128)   0           conv4_10_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_10_x2 (Conv2D)            (None, 2, 32, 32)    36864       relu4_10_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_28 (Concatenate)    (None, 2, 32, 960)   0           concatenate_27[0][0]             \n",
            "                                                                 conv4_10_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_11_x1_bn (BatchNormalizat (None, 2, 32, 960)   3840        concatenate_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_11_x1_scale (Scale)       (None, 2, 32, 960)   1920        conv4_11_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_11_x1 (Activation)        (None, 2, 32, 960)   0           conv4_11_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_11_x1 (Conv2D)            (None, 2, 32, 128)   122880      relu4_11_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_11_x2_bn (BatchNormalizat (None, 2, 32, 128)   512         conv4_11_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_11_x2_scale (Scale)       (None, 2, 32, 128)   256         conv4_11_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_11_x2 (Activation)        (None, 2, 32, 128)   0           conv4_11_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_11_x2 (Conv2D)            (None, 2, 32, 32)    36864       relu4_11_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_29 (Concatenate)    (None, 2, 32, 992)   0           concatenate_28[0][0]             \n",
            "                                                                 conv4_11_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_12_x1_bn (BatchNormalizat (None, 2, 32, 992)   3968        concatenate_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_12_x1_scale (Scale)       (None, 2, 32, 992)   1984        conv4_12_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_12_x1 (Activation)        (None, 2, 32, 992)   0           conv4_12_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_12_x1 (Conv2D)            (None, 2, 32, 128)   126976      relu4_12_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_12_x2_bn (BatchNormalizat (None, 2, 32, 128)   512         conv4_12_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_12_x2_scale (Scale)       (None, 2, 32, 128)   256         conv4_12_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_12_x2 (Activation)        (None, 2, 32, 128)   0           conv4_12_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_12_x2 (Conv2D)            (None, 2, 32, 32)    36864       relu4_12_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_30 (Concatenate)    (None, 2, 32, 1024)  0           concatenate_29[0][0]             \n",
            "                                                                 conv4_12_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_13_x1_bn (BatchNormalizat (None, 2, 32, 1024)  4096        concatenate_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_13_x1_scale (Scale)       (None, 2, 32, 1024)  2048        conv4_13_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_13_x1 (Activation)        (None, 2, 32, 1024)  0           conv4_13_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_13_x1 (Conv2D)            (None, 2, 32, 128)   131072      relu4_13_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_13_x2_bn (BatchNormalizat (None, 2, 32, 128)   512         conv4_13_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_13_x2_scale (Scale)       (None, 2, 32, 128)   256         conv4_13_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_13_x2 (Activation)        (None, 2, 32, 128)   0           conv4_13_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_13_x2 (Conv2D)            (None, 2, 32, 32)    36864       relu4_13_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_31 (Concatenate)    (None, 2, 32, 1056)  0           concatenate_30[0][0]             \n",
            "                                                                 conv4_13_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_14_x1_bn (BatchNormalizat (None, 2, 32, 1056)  4224        concatenate_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_14_x1_scale (Scale)       (None, 2, 32, 1056)  2112        conv4_14_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_14_x1 (Activation)        (None, 2, 32, 1056)  0           conv4_14_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_14_x1 (Conv2D)            (None, 2, 32, 128)   135168      relu4_14_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_14_x2_bn (BatchNormalizat (None, 2, 32, 128)   512         conv4_14_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_14_x2_scale (Scale)       (None, 2, 32, 128)   256         conv4_14_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_14_x2 (Activation)        (None, 2, 32, 128)   0           conv4_14_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_14_x2 (Conv2D)            (None, 2, 32, 32)    36864       relu4_14_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_32 (Concatenate)    (None, 2, 32, 1088)  0           concatenate_31[0][0]             \n",
            "                                                                 conv4_14_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_15_x1_bn (BatchNormalizat (None, 2, 32, 1088)  4352        concatenate_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_15_x1_scale (Scale)       (None, 2, 32, 1088)  2176        conv4_15_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_15_x1 (Activation)        (None, 2, 32, 1088)  0           conv4_15_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_15_x1 (Conv2D)            (None, 2, 32, 128)   139264      relu4_15_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_15_x2_bn (BatchNormalizat (None, 2, 32, 128)   512         conv4_15_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_15_x2_scale (Scale)       (None, 2, 32, 128)   256         conv4_15_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_15_x2 (Activation)        (None, 2, 32, 128)   0           conv4_15_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_15_x2 (Conv2D)            (None, 2, 32, 32)    36864       relu4_15_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_33 (Concatenate)    (None, 2, 32, 1120)  0           concatenate_32[0][0]             \n",
            "                                                                 conv4_15_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_16_x1_bn (BatchNormalizat (None, 2, 32, 1120)  4480        concatenate_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_16_x1_scale (Scale)       (None, 2, 32, 1120)  2240        conv4_16_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_16_x1 (Activation)        (None, 2, 32, 1120)  0           conv4_16_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_16_x1 (Conv2D)            (None, 2, 32, 128)   143360      relu4_16_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_16_x2_bn (BatchNormalizat (None, 2, 32, 128)   512         conv4_16_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_16_x2_scale (Scale)       (None, 2, 32, 128)   256         conv4_16_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_16_x2 (Activation)        (None, 2, 32, 128)   0           conv4_16_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_16_x2 (Conv2D)            (None, 2, 32, 32)    36864       relu4_16_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_34 (Concatenate)    (None, 2, 32, 1152)  0           concatenate_33[0][0]             \n",
            "                                                                 conv4_16_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_17_x1_bn (BatchNormalizat (None, 2, 32, 1152)  4608        concatenate_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_17_x1_scale (Scale)       (None, 2, 32, 1152)  2304        conv4_17_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_17_x1 (Activation)        (None, 2, 32, 1152)  0           conv4_17_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_17_x1 (Conv2D)            (None, 2, 32, 128)   147456      relu4_17_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_17_x2_bn (BatchNormalizat (None, 2, 32, 128)   512         conv4_17_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_17_x2_scale (Scale)       (None, 2, 32, 128)   256         conv4_17_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_17_x2 (Activation)        (None, 2, 32, 128)   0           conv4_17_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_17_x2 (Conv2D)            (None, 2, 32, 32)    36864       relu4_17_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, 2, 32, 1184)  0           concatenate_34[0][0]             \n",
            "                                                                 conv4_17_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_18_x1_bn (BatchNormalizat (None, 2, 32, 1184)  4736        concatenate_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_18_x1_scale (Scale)       (None, 2, 32, 1184)  2368        conv4_18_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_18_x1 (Activation)        (None, 2, 32, 1184)  0           conv4_18_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_18_x1 (Conv2D)            (None, 2, 32, 128)   151552      relu4_18_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_18_x2_bn (BatchNormalizat (None, 2, 32, 128)   512         conv4_18_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_18_x2_scale (Scale)       (None, 2, 32, 128)   256         conv4_18_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_18_x2 (Activation)        (None, 2, 32, 128)   0           conv4_18_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_18_x2 (Conv2D)            (None, 2, 32, 32)    36864       relu4_18_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_36 (Concatenate)    (None, 2, 32, 1216)  0           concatenate_35[0][0]             \n",
            "                                                                 conv4_18_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_19_x1_bn (BatchNormalizat (None, 2, 32, 1216)  4864        concatenate_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_19_x1_scale (Scale)       (None, 2, 32, 1216)  2432        conv4_19_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_19_x1 (Activation)        (None, 2, 32, 1216)  0           conv4_19_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_19_x1 (Conv2D)            (None, 2, 32, 128)   155648      relu4_19_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_19_x2_bn (BatchNormalizat (None, 2, 32, 128)   512         conv4_19_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_19_x2_scale (Scale)       (None, 2, 32, 128)   256         conv4_19_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_19_x2 (Activation)        (None, 2, 32, 128)   0           conv4_19_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_19_x2 (Conv2D)            (None, 2, 32, 32)    36864       relu4_19_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_37 (Concatenate)    (None, 2, 32, 1248)  0           concatenate_36[0][0]             \n",
            "                                                                 conv4_19_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_20_x1_bn (BatchNormalizat (None, 2, 32, 1248)  4992        concatenate_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_20_x1_scale (Scale)       (None, 2, 32, 1248)  2496        conv4_20_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_20_x1 (Activation)        (None, 2, 32, 1248)  0           conv4_20_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_20_x1 (Conv2D)            (None, 2, 32, 128)   159744      relu4_20_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_20_x2_bn (BatchNormalizat (None, 2, 32, 128)   512         conv4_20_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_20_x2_scale (Scale)       (None, 2, 32, 128)   256         conv4_20_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_20_x2 (Activation)        (None, 2, 32, 128)   0           conv4_20_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_20_x2 (Conv2D)            (None, 2, 32, 32)    36864       relu4_20_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_38 (Concatenate)    (None, 2, 32, 1280)  0           concatenate_37[0][0]             \n",
            "                                                                 conv4_20_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_21_x1_bn (BatchNormalizat (None, 2, 32, 1280)  5120        concatenate_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_21_x1_scale (Scale)       (None, 2, 32, 1280)  2560        conv4_21_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_21_x1 (Activation)        (None, 2, 32, 1280)  0           conv4_21_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_21_x1 (Conv2D)            (None, 2, 32, 128)   163840      relu4_21_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_21_x2_bn (BatchNormalizat (None, 2, 32, 128)   512         conv4_21_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_21_x2_scale (Scale)       (None, 2, 32, 128)   256         conv4_21_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_21_x2 (Activation)        (None, 2, 32, 128)   0           conv4_21_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_21_x2 (Conv2D)            (None, 2, 32, 32)    36864       relu4_21_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_39 (Concatenate)    (None, 2, 32, 1312)  0           concatenate_38[0][0]             \n",
            "                                                                 conv4_21_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_22_x1_bn (BatchNormalizat (None, 2, 32, 1312)  5248        concatenate_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_22_x1_scale (Scale)       (None, 2, 32, 1312)  2624        conv4_22_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_22_x1 (Activation)        (None, 2, 32, 1312)  0           conv4_22_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_22_x1 (Conv2D)            (None, 2, 32, 128)   167936      relu4_22_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_22_x2_bn (BatchNormalizat (None, 2, 32, 128)   512         conv4_22_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_22_x2_scale (Scale)       (None, 2, 32, 128)   256         conv4_22_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_22_x2 (Activation)        (None, 2, 32, 128)   0           conv4_22_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_22_x2 (Conv2D)            (None, 2, 32, 32)    36864       relu4_22_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_40 (Concatenate)    (None, 2, 32, 1344)  0           concatenate_39[0][0]             \n",
            "                                                                 conv4_22_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_23_x1_bn (BatchNormalizat (None, 2, 32, 1344)  5376        concatenate_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_23_x1_scale (Scale)       (None, 2, 32, 1344)  2688        conv4_23_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_23_x1 (Activation)        (None, 2, 32, 1344)  0           conv4_23_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_23_x1 (Conv2D)            (None, 2, 32, 128)   172032      relu4_23_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_23_x2_bn (BatchNormalizat (None, 2, 32, 128)   512         conv4_23_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_23_x2_scale (Scale)       (None, 2, 32, 128)   256         conv4_23_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_23_x2 (Activation)        (None, 2, 32, 128)   0           conv4_23_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_23_x2 (Conv2D)            (None, 2, 32, 32)    36864       relu4_23_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_41 (Concatenate)    (None, 2, 32, 1376)  0           concatenate_40[0][0]             \n",
            "                                                                 conv4_23_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_24_x1_bn (BatchNormalizat (None, 2, 32, 1376)  5504        concatenate_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_24_x1_scale (Scale)       (None, 2, 32, 1376)  2752        conv4_24_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_24_x1 (Activation)        (None, 2, 32, 1376)  0           conv4_24_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_24_x1 (Conv2D)            (None, 2, 32, 128)   176128      relu4_24_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_24_x2_bn (BatchNormalizat (None, 2, 32, 128)   512         conv4_24_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_24_x2_scale (Scale)       (None, 2, 32, 128)   256         conv4_24_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu4_24_x2 (Activation)        (None, 2, 32, 128)   0           conv4_24_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_24_x2 (Conv2D)            (None, 2, 32, 32)    36864       relu4_24_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_42 (Concatenate)    (None, 2, 32, 1408)  0           concatenate_41[0][0]             \n",
            "                                                                 conv4_24_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv4_blk_bn (BatchNormalizatio (None, 2, 32, 1408)  5632        concatenate_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv4_blk_scale (Scale)         (None, 2, 32, 1408)  2816        conv4_blk_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "relu4_blk (Activation)          (None, 2, 32, 1408)  0           conv4_blk_scale[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv4_blk (Conv2D)              (None, 2, 32, 1408)  1982464     relu4_blk[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "pool4 (AveragePooling2D)        (None, 1, 32, 1408)  0           conv4_blk[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_x1_bn (BatchNormalizati (None, 1, 32, 1408)  5632        pool4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_x1_scale (Scale)        (None, 1, 32, 1408)  2816        conv5_1_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_1_x1 (Activation)         (None, 1, 32, 1408)  0           conv5_1_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_x1 (Conv2D)             (None, 1, 32, 128)   180224      relu5_1_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_x2_bn (BatchNormalizati (None, 1, 32, 128)   512         conv5_1_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_x2_scale (Scale)        (None, 1, 32, 128)   256         conv5_1_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_1_x2 (Activation)         (None, 1, 32, 128)   0           conv5_1_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_1_x2 (Conv2D)             (None, 1, 32, 32)    36864       relu5_1_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_43 (Concatenate)    (None, 1, 32, 1440)  0           pool4[0][0]                      \n",
            "                                                                 conv5_1_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_x1_bn (BatchNormalizati (None, 1, 32, 1440)  5760        concatenate_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_x1_scale (Scale)        (None, 1, 32, 1440)  2880        conv5_2_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_2_x1 (Activation)         (None, 1, 32, 1440)  0           conv5_2_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_x1 (Conv2D)             (None, 1, 32, 128)   184320      relu5_2_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_x2_bn (BatchNormalizati (None, 1, 32, 128)   512         conv5_2_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_x2_scale (Scale)        (None, 1, 32, 128)   256         conv5_2_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_2_x2 (Activation)         (None, 1, 32, 128)   0           conv5_2_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_2_x2 (Conv2D)             (None, 1, 32, 32)    36864       relu5_2_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_44 (Concatenate)    (None, 1, 32, 1472)  0           concatenate_43[0][0]             \n",
            "                                                                 conv5_2_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_x1_bn (BatchNormalizati (None, 1, 32, 1472)  5888        concatenate_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_x1_scale (Scale)        (None, 1, 32, 1472)  2944        conv5_3_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_3_x1 (Activation)         (None, 1, 32, 1472)  0           conv5_3_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_x1 (Conv2D)             (None, 1, 32, 128)   188416      relu5_3_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_x2_bn (BatchNormalizati (None, 1, 32, 128)   512         conv5_3_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_x2_scale (Scale)        (None, 1, 32, 128)   256         conv5_3_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_3_x2 (Activation)         (None, 1, 32, 128)   0           conv5_3_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_3_x2 (Conv2D)             (None, 1, 32, 32)    36864       relu5_3_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_45 (Concatenate)    (None, 1, 32, 1504)  0           concatenate_44[0][0]             \n",
            "                                                                 conv5_3_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_4_x1_bn (BatchNormalizati (None, 1, 32, 1504)  6016        concatenate_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_4_x1_scale (Scale)        (None, 1, 32, 1504)  3008        conv5_4_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_4_x1 (Activation)         (None, 1, 32, 1504)  0           conv5_4_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_4_x1 (Conv2D)             (None, 1, 32, 128)   192512      relu5_4_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_4_x2_bn (BatchNormalizati (None, 1, 32, 128)   512         conv5_4_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_4_x2_scale (Scale)        (None, 1, 32, 128)   256         conv5_4_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_4_x2 (Activation)         (None, 1, 32, 128)   0           conv5_4_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_4_x2 (Conv2D)             (None, 1, 32, 32)    36864       relu5_4_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_46 (Concatenate)    (None, 1, 32, 1536)  0           concatenate_45[0][0]             \n",
            "                                                                 conv5_4_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_5_x1_bn (BatchNormalizati (None, 1, 32, 1536)  6144        concatenate_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_5_x1_scale (Scale)        (None, 1, 32, 1536)  3072        conv5_5_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_5_x1 (Activation)         (None, 1, 32, 1536)  0           conv5_5_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_5_x1 (Conv2D)             (None, 1, 32, 128)   196608      relu5_5_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_5_x2_bn (BatchNormalizati (None, 1, 32, 128)   512         conv5_5_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_5_x2_scale (Scale)        (None, 1, 32, 128)   256         conv5_5_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_5_x2 (Activation)         (None, 1, 32, 128)   0           conv5_5_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_5_x2 (Conv2D)             (None, 1, 32, 32)    36864       relu5_5_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_47 (Concatenate)    (None, 1, 32, 1568)  0           concatenate_46[0][0]             \n",
            "                                                                 conv5_5_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_6_x1_bn (BatchNormalizati (None, 1, 32, 1568)  6272        concatenate_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_6_x1_scale (Scale)        (None, 1, 32, 1568)  3136        conv5_6_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_6_x1 (Activation)         (None, 1, 32, 1568)  0           conv5_6_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_6_x1 (Conv2D)             (None, 1, 32, 128)   200704      relu5_6_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_6_x2_bn (BatchNormalizati (None, 1, 32, 128)   512         conv5_6_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_6_x2_scale (Scale)        (None, 1, 32, 128)   256         conv5_6_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_6_x2 (Activation)         (None, 1, 32, 128)   0           conv5_6_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_6_x2 (Conv2D)             (None, 1, 32, 32)    36864       relu5_6_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_48 (Concatenate)    (None, 1, 32, 1600)  0           concatenate_47[0][0]             \n",
            "                                                                 conv5_6_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_7_x1_bn (BatchNormalizati (None, 1, 32, 1600)  6400        concatenate_48[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_7_x1_scale (Scale)        (None, 1, 32, 1600)  3200        conv5_7_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_7_x1 (Activation)         (None, 1, 32, 1600)  0           conv5_7_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_7_x1 (Conv2D)             (None, 1, 32, 128)   204800      relu5_7_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_7_x2_bn (BatchNormalizati (None, 1, 32, 128)   512         conv5_7_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_7_x2_scale (Scale)        (None, 1, 32, 128)   256         conv5_7_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_7_x2 (Activation)         (None, 1, 32, 128)   0           conv5_7_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_7_x2 (Conv2D)             (None, 1, 32, 32)    36864       relu5_7_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_49 (Concatenate)    (None, 1, 32, 1632)  0           concatenate_48[0][0]             \n",
            "                                                                 conv5_7_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_8_x1_bn (BatchNormalizati (None, 1, 32, 1632)  6528        concatenate_49[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_8_x1_scale (Scale)        (None, 1, 32, 1632)  3264        conv5_8_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_8_x1 (Activation)         (None, 1, 32, 1632)  0           conv5_8_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_8_x1 (Conv2D)             (None, 1, 32, 128)   208896      relu5_8_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_8_x2_bn (BatchNormalizati (None, 1, 32, 128)   512         conv5_8_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_8_x2_scale (Scale)        (None, 1, 32, 128)   256         conv5_8_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_8_x2 (Activation)         (None, 1, 32, 128)   0           conv5_8_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_8_x2 (Conv2D)             (None, 1, 32, 32)    36864       relu5_8_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_50 (Concatenate)    (None, 1, 32, 1664)  0           concatenate_49[0][0]             \n",
            "                                                                 conv5_8_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_9_x1_bn (BatchNormalizati (None, 1, 32, 1664)  6656        concatenate_50[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_9_x1_scale (Scale)        (None, 1, 32, 1664)  3328        conv5_9_x1_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_9_x1 (Activation)         (None, 1, 32, 1664)  0           conv5_9_x1_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_9_x1 (Conv2D)             (None, 1, 32, 128)   212992      relu5_9_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_9_x2_bn (BatchNormalizati (None, 1, 32, 128)   512         conv5_9_x1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_9_x2_scale (Scale)        (None, 1, 32, 128)   256         conv5_9_x2_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "relu5_9_x2 (Activation)         (None, 1, 32, 128)   0           conv5_9_x2_scale[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_9_x2 (Conv2D)             (None, 1, 32, 32)    36864       relu5_9_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_51 (Concatenate)    (None, 1, 32, 1696)  0           concatenate_50[0][0]             \n",
            "                                                                 conv5_9_x2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv5_10_x1_bn (BatchNormalizat (None, 1, 32, 1696)  6784        concatenate_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_10_x1_scale (Scale)       (None, 1, 32, 1696)  3392        conv5_10_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu5_10_x1 (Activation)        (None, 1, 32, 1696)  0           conv5_10_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_10_x1 (Conv2D)            (None, 1, 32, 128)   217088      relu5_10_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_10_x2_bn (BatchNormalizat (None, 1, 32, 128)   512         conv5_10_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_10_x2_scale (Scale)       (None, 1, 32, 128)   256         conv5_10_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu5_10_x2 (Activation)        (None, 1, 32, 128)   0           conv5_10_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_10_x2 (Conv2D)            (None, 1, 32, 32)    36864       relu5_10_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_52 (Concatenate)    (None, 1, 32, 1728)  0           concatenate_51[0][0]             \n",
            "                                                                 conv5_10_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_11_x1_bn (BatchNormalizat (None, 1, 32, 1728)  6912        concatenate_52[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_11_x1_scale (Scale)       (None, 1, 32, 1728)  3456        conv5_11_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu5_11_x1 (Activation)        (None, 1, 32, 1728)  0           conv5_11_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_11_x1 (Conv2D)            (None, 1, 32, 128)   221184      relu5_11_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_11_x2_bn (BatchNormalizat (None, 1, 32, 128)   512         conv5_11_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_11_x2_scale (Scale)       (None, 1, 32, 128)   256         conv5_11_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu5_11_x2 (Activation)        (None, 1, 32, 128)   0           conv5_11_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_11_x2 (Conv2D)            (None, 1, 32, 32)    36864       relu5_11_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_53 (Concatenate)    (None, 1, 32, 1760)  0           concatenate_52[0][0]             \n",
            "                                                                 conv5_11_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_12_x1_bn (BatchNormalizat (None, 1, 32, 1760)  7040        concatenate_53[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_12_x1_scale (Scale)       (None, 1, 32, 1760)  3520        conv5_12_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu5_12_x1 (Activation)        (None, 1, 32, 1760)  0           conv5_12_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_12_x1 (Conv2D)            (None, 1, 32, 128)   225280      relu5_12_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_12_x2_bn (BatchNormalizat (None, 1, 32, 128)   512         conv5_12_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_12_x2_scale (Scale)       (None, 1, 32, 128)   256         conv5_12_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu5_12_x2 (Activation)        (None, 1, 32, 128)   0           conv5_12_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_12_x2 (Conv2D)            (None, 1, 32, 32)    36864       relu5_12_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_54 (Concatenate)    (None, 1, 32, 1792)  0           concatenate_53[0][0]             \n",
            "                                                                 conv5_12_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_13_x1_bn (BatchNormalizat (None, 1, 32, 1792)  7168        concatenate_54[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_13_x1_scale (Scale)       (None, 1, 32, 1792)  3584        conv5_13_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu5_13_x1 (Activation)        (None, 1, 32, 1792)  0           conv5_13_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_13_x1 (Conv2D)            (None, 1, 32, 128)   229376      relu5_13_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_13_x2_bn (BatchNormalizat (None, 1, 32, 128)   512         conv5_13_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_13_x2_scale (Scale)       (None, 1, 32, 128)   256         conv5_13_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu5_13_x2 (Activation)        (None, 1, 32, 128)   0           conv5_13_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_13_x2 (Conv2D)            (None, 1, 32, 32)    36864       relu5_13_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_55 (Concatenate)    (None, 1, 32, 1824)  0           concatenate_54[0][0]             \n",
            "                                                                 conv5_13_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_14_x1_bn (BatchNormalizat (None, 1, 32, 1824)  7296        concatenate_55[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_14_x1_scale (Scale)       (None, 1, 32, 1824)  3648        conv5_14_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu5_14_x1 (Activation)        (None, 1, 32, 1824)  0           conv5_14_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_14_x1 (Conv2D)            (None, 1, 32, 128)   233472      relu5_14_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_14_x2_bn (BatchNormalizat (None, 1, 32, 128)   512         conv5_14_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_14_x2_scale (Scale)       (None, 1, 32, 128)   256         conv5_14_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu5_14_x2 (Activation)        (None, 1, 32, 128)   0           conv5_14_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_14_x2 (Conv2D)            (None, 1, 32, 32)    36864       relu5_14_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_56 (Concatenate)    (None, 1, 32, 1856)  0           concatenate_55[0][0]             \n",
            "                                                                 conv5_14_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_15_x1_bn (BatchNormalizat (None, 1, 32, 1856)  7424        concatenate_56[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_15_x1_scale (Scale)       (None, 1, 32, 1856)  3712        conv5_15_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu5_15_x1 (Activation)        (None, 1, 32, 1856)  0           conv5_15_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_15_x1 (Conv2D)            (None, 1, 32, 128)   237568      relu5_15_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_15_x2_bn (BatchNormalizat (None, 1, 32, 128)   512         conv5_15_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_15_x2_scale (Scale)       (None, 1, 32, 128)   256         conv5_15_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu5_15_x2 (Activation)        (None, 1, 32, 128)   0           conv5_15_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_15_x2 (Conv2D)            (None, 1, 32, 32)    36864       relu5_15_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_57 (Concatenate)    (None, 1, 32, 1888)  0           concatenate_56[0][0]             \n",
            "                                                                 conv5_15_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_16_x1_bn (BatchNormalizat (None, 1, 32, 1888)  7552        concatenate_57[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_16_x1_scale (Scale)       (None, 1, 32, 1888)  3776        conv5_16_x1_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu5_16_x1 (Activation)        (None, 1, 32, 1888)  0           conv5_16_x1_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_16_x1 (Conv2D)            (None, 1, 32, 128)   241664      relu5_16_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_16_x2_bn (BatchNormalizat (None, 1, 32, 128)   512         conv5_16_x1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_16_x2_scale (Scale)       (None, 1, 32, 128)   256         conv5_16_x2_bn[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "relu5_16_x2 (Activation)        (None, 1, 32, 128)   0           conv5_16_x2_scale[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_16_x2 (Conv2D)            (None, 1, 32, 32)    36864       relu5_16_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_58 (Concatenate)    (None, 1, 32, 1920)  0           concatenate_57[0][0]             \n",
            "                                                                 conv5_16_x2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv5_blk_bn (BatchNormalizatio (None, 1, 32, 1920)  7680        concatenate_58[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv5_blk_scale (Scale)         (None, 1, 32, 1920)  3840        conv5_blk_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "relu5_blk (Activation)          (None, 1, 32, 1920)  0           conv5_blk_scale[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 32, 1920)     0           relu5_blk[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bi_gru1 (Bidirectional)         (None, 32, 1024)     7477248     reshape[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "bi_gru2 (Bidirectional)         (None, 32, 1024)     4724736     bi_gru1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense1 (Dense)                  (None, 32, 301)      308525      bi_gru2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 24,765,101\n",
            "Trainable params: 24,628,461\n",
            "Non-trainable params: 136,640\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Km2GyDuBI1sv"
      },
      "source": [
        "#This code cell holds the DenseNet model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cUvLNBIARz2"
      },
      "source": [
        "INPUT_SHAPE = (32, 128, 1) # (img_rows, img_cols, img_channel)\n",
        "\n",
        "REG = 0.0001\n",
        "from keras.layers import LSTM, Reshape, Input, Conv2D, MaxPool2D, Bidirectional\n",
        "from keras.applications import VGG16, ResNet50, MobileNet, Xception, DenseNet121, ResNet152V2\n",
        "\n",
        "def make_model():\n",
        "  #base_model = ResNet50(include_top=False, weights=None, input_tensor=None, input_shape=INPUT_SHAPE)\n",
        "  #base_model = ResNet152V2(include_top=False, weights=None, input_tensor=None, input_shape=INPUT_SHAPE)\n",
        "  base_model = DenseNet121(include_top=False, weights=None, input_tensor=None, input_shape=INPUT_SHAPE)\n",
        "\n",
        "  #model = Model(base_model.inputs, base_model.outputs)\n",
        "  base_model.summary()\n",
        "  # x = base_model.layers[51].output\n",
        "  # model = Model(base_model.inputs, x)\n",
        "  # model.summary()\n",
        "\n",
        "make_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2HoHROs09pk"
      },
      "source": [
        "INPUT_SHAPE = (32, 128, 1) # (img_rows, img_cols, img_channel)\n",
        "\n",
        "REG = 0.0001\n",
        "from keras.layers import LSTM, Reshape, Input, Conv2D, MaxPool2D, Bidirectional\n",
        "from keras.applications import VGG16, ResNet50, MobileNet, Xception, DenseNet121, ResNet152V2\n",
        "\n",
        "def make_model():\n",
        "  #base_model = ResNet50(include_top=False, weights=None, input_tensor=None, input_shape=INPUT_SHAPE)\n",
        "  #base_model = ResNet152V2(include_top=False, weights=None, input_tensor=None, input_shape=INPUT_SHAPE)\n",
        "  base_model = DenseNet121(include_top=False, weights=None, input_tensor=None, input_shape=INPUT_SHAPE)\n",
        "\n",
        "  #model = Model(base_model.inputs, base_model.outputs)\n",
        "  #model.summary()\n",
        "  #x = base_model.layers[60].output\n",
        "  x = base_model.output\n",
        "  x =  Reshape((32, 240), name=\"reshape\") (x)\n",
        "\n",
        "  #squeezed = Lambda(lambda x: K.squeeze(x, 1), name='squeeze')(reshaped)\n",
        "\n",
        "  # bidirectional LSTM layers with units=128\n",
        "  #blstm_1 = Bidirectional(LSTM(512, return_sequences=True, dropout = 0.2,\n",
        "  #                kernel_regularizer=regularizers.l2(REG)))(squeezed)\n",
        "  gru_1 =  Bidirectional(GRU(512, return_sequences=True, dropout = 0.4,\n",
        "                  kernel_regularizer=regularizers.l2(REG)),\n",
        "                  name='bi_gru1')(x)\n",
        "  #x = Dropout(0.5)(gru_1)\n",
        "  #blstm_2 = Bidirectional(LSTM(512, return_sequences=True, dropout = 0.2,\n",
        "  #                kernel_regularizer=regularizers.l2(REG)))(blstm_1)\n",
        "  gru_2 =  Bidirectional(GRU(512, return_sequences=True, dropout = 0.4,\n",
        "                  kernel_regularizer=regularizers.l2(REG)),\n",
        "                  name='bi_gru2')(gru_1)\n",
        "\n",
        "  #x = Dropout(0.5)(gru_2)\n",
        "\n",
        "  outputs = Dense(len(char_list)+1, activation = 'softmax',\n",
        "                  kernel_regularizer=regularizers.l2(REG),\n",
        "                  name='dense1')(gru_2)\n",
        "  #x = Dropout(0.25)(gru_2)\n",
        "  # model to be used at test time\n",
        "  model = Model(base_model.inputs, outputs)\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "\n",
        "my_model = make_model()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snAwzMnqJhD1"
      },
      "source": [
        "#This code cell holds the VGG_19 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TYg_ZFYmy1Q",
        "outputId": "efa41478-e69f-480e-c759-6eb5e90a25b4"
      },
      "source": [
        "INPUT_SHAPE = (64, 256, 1) # (img_rows, img_cols, img_channel)\n",
        "\n",
        "REG = 0.0001\n",
        "from keras.layers import LSTM, Reshape, Input, Conv2D, MaxPool2D, Bidirectional\n",
        "from keras.applications import VGG19, ResNet50, MobileNet, Xception, DenseNet201, ResNet152V2\n",
        "\n",
        "def make_model():\n",
        "  base_model = VGG19(include_top=False, weights=None, input_tensor=None, input_shape=INPUT_SHAPE)\n",
        "  x = base_model.layers[0].output\n",
        "  x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(x)\n",
        "  x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
        "  x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
        "\n",
        "  # Block 2\n",
        "  x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
        "  x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
        "  x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
        "\n",
        "  # Block 3\n",
        "  x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
        "  x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
        "  x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
        "  x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv4')(x)\n",
        "  x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
        "\n",
        "  # Block 4\n",
        "  x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
        "  x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
        "  x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
        "  x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv4')(x)\n",
        "  x = MaxPooling2D((2, 1), strides=(2, 1), name='block4_pool')(x)\n",
        "\n",
        "  # Block 5\n",
        "  x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
        "  x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
        "  x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
        "  x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv4')(x)\n",
        "  x = MaxPooling2D((2, 1), strides=(2, 1), name='block5_pool')(x)\n",
        "  reshaped =  Reshape((32, 1024), name=\"reshape\") (x)\n",
        "\n",
        "  gru_1 =  Bidirectional(GRU(512, return_sequences=True, reset_after=True,\n",
        "                  kernel_regularizer=regularizers.l2(REG)),\n",
        "                  name='bi_gru1')(reshaped)\n",
        "  x = Dropout(0.5)(gru_1)\n",
        "    #blstm_2 = Bidirectional(LSTM(512, return_sequences=True, dropout = 0.2,\n",
        "    #                kernel_regularizer=regularizers.l2(REG)))(blstm_1)\n",
        "  gru_2 =  Bidirectional(GRU(512, return_sequences=True, reset_after=True,\n",
        "                  kernel_regularizer=regularizers.l2(REG)),\n",
        "                  name='bi_gru2')(gru_1)\n",
        "\n",
        "  x = Dropout(0.5)(gru_2)\n",
        "\n",
        "  outputs = Dense(len(char_list)+1, activation = 'softmax',\n",
        "                  kernel_regularizer=regularizers.l2(REG),\n",
        "                  name='dense1')(gru_2)\n",
        "  model = Model(base_model.inputs, outputs)\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "\n",
        "  #x = base_model.layers[-6].output\n",
        "\n",
        "my_model = make_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 64, 256, 1)        0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 64, 256, 64)       640       \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 64, 256, 64)       36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 32, 128, 64)       0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 32, 128, 128)      73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 32, 128, 128)      147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 16, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 16, 64, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 16, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 16, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 16, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 8, 32, 256)        0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 8, 32, 512)        1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 8, 32, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 8, 32, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, 8, 32, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 4, 32, 512)        0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 4, 32, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 4, 32, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 4, 32, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv4 (Conv2D)        (None, 4, 32, 512)        2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 2, 32, 512)        0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 32, 1024)          0         \n",
            "_________________________________________________________________\n",
            "bi_gru1 (Bidirectional)      (None, 32, 1024)          4724736   \n",
            "_________________________________________________________________\n",
            "bi_gru2 (Bidirectional)      (None, 32, 1024)          4724736   \n",
            "_________________________________________________________________\n",
            "dense1 (Dense)               (None, 32, 301)           308525    \n",
            "=================================================================\n",
            "Total params: 29,781,229\n",
            "Trainable params: 29,781,229\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxToofGVJBzS"
      },
      "source": [
        "INPUT_SHAPE = (32, 128, 1) # (img_rows, img_cols, img_channel)\n",
        "\n",
        "REG = 0.0001\n",
        "from keras.layers import LSTM, Reshape, Input, Conv2D, MaxPool2D, Bidirectional\n",
        "from keras.applications import VGG19, ResNet50, MobileNet, Xception, DenseNet201, ResNet152V2\n",
        "\n",
        "def make_model():\n",
        "  #base_model = ResNet50(include_top=False, weights=None, input_tensor=None, input_shape=INPUT_SHAPE)\n",
        "  #base_model = ResNet152V2(include_top=False, weights=None, input_tensor=None, input_shape=INPUT_SHAPE)\n",
        "  base_model = VGG16(include_top=False, weights=None, input_tensor=None, input_shape=INPUT_SHAPE)\n",
        "\n",
        "  #model = Model(base_model.inputs, base_model.outputs)\n",
        "  #model.summary()\n",
        "  #x = base_model.layers[60].output\n",
        "  x = base_model.layers[-6].output\n",
        "  x =  Reshape((64, 512), name=\"reshape\") (x)\n",
        "\n",
        "  #squeezed = Lambda(lambda x: K.squeeze(x, 1), name='squeeze')(reshaped)\n",
        "\n",
        "  # bidirectional LSTM layers with units=128\n",
        "  #blstm_1 = Bidirectional(LSTM(512, return_sequences=True, dropout = 0.2,\n",
        "  #                kernel_regularizer=regularizers.l2(REG)))(squeezed)\n",
        "  gru_1 =  Bidirectional(GRU(512, return_sequences=True, dropout = 0.4,\n",
        "                  kernel_regularizer=regularizers.l2(REG)),\n",
        "                  name='bi_gru1')(x)\n",
        "  #x = Dropout(0.5)(gru_1)\n",
        "  #blstm_2 = Bidirectional(LSTM(512, return_sequences=True, dropout = 0.2,\n",
        "  #                kernel_regularizer=regularizers.l2(REG)))(blstm_1)\n",
        "  gru_2 =  Bidirectional(GRU(512, return_sequences=True, dropout = 0.4,\n",
        "                  kernel_regularizer=regularizers.l2(REG)),\n",
        "                  name='bi_gru2')(gru_1)\n",
        "\n",
        "  #x = Dropout(0.5)(gru_2)\n",
        "\n",
        "  outputs = Dense(len(char_list)+1, activation = 'softmax',\n",
        "                  kernel_regularizer=regularizers.l2(REG),\n",
        "                  name='dense1')(gru_2)\n",
        "  #x = Dropout(0.25)(gru_2)\n",
        "  # model to be used at test time\n",
        "  model = Model(base_model.inputs, outputs)\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "\n",
        "my_model = make_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aIAc2rAsxna"
      },
      "source": [
        "keras.utils.vis_utils.plot_model(model, show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DioCv0ZB1Agg"
      },
      "source": [
        "###THIS PART IS USED TO DEVELOP THE ARCHITECTURE OF THE PRE-TRAINED MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHZFjHXH07iW"
      },
      "source": [
        "from keras.models import load_model\n",
        "loaded_model= load_model('/content/drive/Shared drives/PolypDB/models/<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7efe461f6940>o-15000r-200e-100000t-20000v.hdf5'\n",
        ",  custom_objects={'<lambda>': lambda y_true, y_pred: y_pred} )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "go15uiwT4IaI"
      },
      "source": [
        "loaded_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CpFn_SM8Rjo"
      },
      "source": [
        "#remove the head of the pre-trained network before the 23rd layer and add new head\n",
        "REG = 0.0001\n",
        "l1=loaded_model.layers[61].output\n",
        "l1=Dense(len(char_list)+1, kernel_regularizer=regularizers.l2(REG), name='outputs')(l1)\n",
        "l1=Activation('softmax', name='softmax')(l1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "0-ppfcEgvEay",
        "outputId": "ab96ef46-d8a9-4c62-d837-71c4baac37ea"
      },
      "source": [
        "loaded_model.layers[60]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.wrappers.Bidirectional at 0x7f63301bf0f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T8IYWCn5m-7"
      },
      "source": [
        "for layer in loaded_model.layers[:-38]:\n",
        "    #print(layer)\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0ymdIUi9bjN"
      },
      "source": [
        "new_model= Model(inputs=loaded_model.input[0], outputs=l1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka2bVCsf9qms"
      },
      "source": [
        "LR_START = 0.0001\n",
        "LR_MAX = 0.0005\n",
        "LR_MIN = 0.0001\n",
        "LR_RAMPUP_EPOCHS = 5\n",
        "LR_SUSTAIN_EPOCHS = 0\n",
        "LR_EXP_DECAY = .9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTC_6r0bNJkn"
      },
      "source": [
        "import tensorflow as tf\n",
        "def lrfn(epoch):\n",
        "    if epoch < LR_RAMPUP_EPOCHS:\n",
        "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
        "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
        "        lr = LR_MAX\n",
        "    else:\n",
        "        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n",
        "    return lr\n",
        "\n",
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGI_043qfGAa"
      },
      "source": [
        "batch_size = 8\n",
        "epochs = 40\n",
        "e = str(epochs)\n",
        "#optimizer_name = 'adadelta'\n",
        "#opt =RMSprop(learning_rate=0.0001)\n",
        "opt = Adam(learning_rate=0.0001)\n",
        "#uncomment this two lines for the pre-trained model\n",
        "inputs = my_model.input\n",
        "outputs = my_model.output\n",
        "#inputs = new_model.input\n",
        "#outputs = new_model.output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fB8I5how47Jh"
      },
      "source": [
        "the_labels = Input(name='the_labels', shape=[max_label_len], dtype='float32')\n",
        "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
        "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
        "\n",
        "def ctc_lambda_func(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        "\n",
        "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
        "\n",
        "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([outputs, the_labels, input_length, label_length])\n",
        "\n",
        "#model to be used at training time\n",
        "model = Model(inputs=[inputs, the_labels, input_length, label_length], outputs=loss_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxx7F384gyHN"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDvELng282Fe"
      },
      "source": [
        "#grid search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6wCgjkC_85K"
      },
      "source": [
        "# Use scikit-learn to grid search the batch size and epochs\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(optimizer='adam'):\n",
        "\t# create model\n",
        "\tmodel = Model(inputs=[inputs, the_labels, input_length, label_length], outputs=loss_out)\n",
        "\t#model = Model(inputs=[inputs, the_labels, input_length, label_length], outputs=loss_out)\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=optimizer, metrics=['accuracy'])\n",
        "\treturn model\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "np.random.seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "3sKuxY82xoL-",
        "outputId": "05b9eeeb-d2d3-4417-a953-baebd4bc02aa"
      },
      "source": [
        "# split into input (X) and output (Y) variables\n",
        "train_data = ([X_train, y_train, train_input_length, train_label_length], [np.zeros(len(X_train))])\n",
        "X = [X_train, y_train, train_input_length, train_label_length]\n",
        "Y = np.zeros(len(X_train))\n",
        "len(X_train), len(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7496, 7496)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy0ZLHg4yFi8"
      },
      "source": [
        "# create model\n",
        "clf = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
        "# define the grid search parameters\n",
        "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
        "param_grid = dict(optimizer=optimizer)\n",
        "grid = GridSearchCV(estimator=clf, param_grid=param_grid, n_jobs=1, cv=3)\n",
        "grid_result = grid.fit(X, Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9LJ6KucfOqJ"
      },
      "source": [
        "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=opt, metrics=['accuracy'])\n",
        "#drive/My Drive/Colab Notebooks/Handwritten-Text-Recognition/\n",
        "filepath=\"/content/drive/Shared drives/PolypDB/AWR_Test 7/models/{}o-{}r-{}e-{}t-{}v.hdf5\".format(opt,\n",
        "                                                                        str(RECORDS_COUNT),\n",
        "                                                                        str(epochs),\n",
        "                                                                        str(X_train.shape[0]),\n",
        "                                                                        str(X_val.shape[0]))\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "callbacks_list = [checkpoint]\n",
        "#callbacks_list=[lr_callback]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDFikYPxmj7k",
        "outputId": "291ffcc0-689c-40eb-8bfc-1ed2758a882c"
      },
      "source": [
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta = 0.1,\n",
        "    patience = 2)\n",
        "\n",
        "history = model.fit(x=[X_train, y_train, train_input_length, train_label_length],\n",
        "                    y=np.zeros(len(X_train)),\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=([X_val, y_val, valid_input_length, valid_label_length], [np.zeros(len(X_val))]),\n",
        "                    verbose=2,\n",
        "                    callbacks=callbacks_list\n",
        "                    )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 29224 samples, validate on 3248 samples\n",
            "Epoch 1/40\n",
            " - 718s - loss: 17.1494 - accuracy: 3.4218e-05 - val_loss: 16.1575 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 16.15752, saving model to /content/drive/Shared drives/PolypDB/AWR_Test 7/models/<keras.optimizers.Adam object at 0x7f3c716e6850>o-8486r-40e-29224t-3248v.hdf5\n",
            "Epoch 2/40\n",
            " - 705s - loss: 16.0588 - accuracy: 0.0037 - val_loss: 15.6170 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00002: val_loss improved from 16.15752 to 15.61697, saving model to /content/drive/Shared drives/PolypDB/AWR_Test 7/models/<keras.optimizers.Adam object at 0x7f3c716e6850>o-8486r-40e-29224t-3248v.hdf5\n",
            "Epoch 3/40\n",
            " - 705s - loss: 15.2891 - accuracy: 0.0256 - val_loss: 14.6148 - val_accuracy: 0.0403\n",
            "\n",
            "Epoch 00003: val_loss improved from 15.61697 to 14.61477, saving model to /content/drive/Shared drives/PolypDB/AWR_Test 7/models/<keras.optimizers.Adam object at 0x7f3c716e6850>o-8486r-40e-29224t-3248v.hdf5\n",
            "Epoch 4/40\n",
            " - 702s - loss: 14.1685 - accuracy: 0.0543 - val_loss: 13.5345 - val_accuracy: 0.0690\n",
            "\n",
            "Epoch 00004: val_loss improved from 14.61477 to 13.53453, saving model to /content/drive/Shared drives/PolypDB/AWR_Test 7/models/<keras.optimizers.Adam object at 0x7f3c716e6850>o-8486r-40e-29224t-3248v.hdf5\n",
            "Epoch 5/40\n",
            " - 707s - loss: 13.0761 - accuracy: 0.0727 - val_loss: 12.3478 - val_accuracy: 0.0877\n",
            "\n",
            "Epoch 00005: val_loss improved from 13.53453 to 12.34778, saving model to /content/drive/Shared drives/PolypDB/AWR_Test 7/models/<keras.optimizers.Adam object at 0x7f3c716e6850>o-8486r-40e-29224t-3248v.hdf5\n",
            "Epoch 6/40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mr21XvBukBYL",
        "outputId": "ec627829-5eb3-47d6-aa0e-3b65c64e9b77"
      },
      "source": [
        "print(valid_input_length[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_Epc3XBfRHQ"
      },
      "source": [
        "# Train and validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DsiGXJbfZXY"
      },
      "source": [
        "# predict outputs on validation images\n",
        "prediction = my_model.predict(X_val[2:20])\n",
        "\n",
        "# use CTC decoder\n",
        "decoded = K.ctc_decode(prediction,\n",
        "                       input_length=np.ones(prediction.shape[0]) * prediction.shape[1],\n",
        "                       greedy=True)[0][0]\n",
        "\n",
        "out = K.get_value(decoded)\n",
        "\n",
        "# see the results\n",
        "for i, x in enumerate(out):\n",
        "    print(\"original_text =  \", valid_original_text[2+i])\n",
        "    print(\"predicted text = \", end = '')\n",
        "    for p in x:\n",
        "        if int(p) != -1:\n",
        "            print(char_list[int(p)], end = '')\n",
        "    plt.imshow(X_val[2+i].reshape(32,128), cmap=plt.cm.gray)\n",
        "    plt.show()\n",
        "    print('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaYmgiHRfvfu"
      },
      "source": [
        "# plot accuracy and loss\n",
        "def plotgraph(epochs, acc, val_acc):\n",
        "    # Plot training & validation accuracy values\n",
        "    plt.plot(epochs, acc, 'b')\n",
        "    plt.plot(epochs, val_acc, 'r')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Val'], loc='upper left')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gO9QRkT4ga6Z"
      },
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1,len(loss)+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qy0kAaHggdv6"
      },
      "source": [
        "plt.title('Model loss')\n",
        "plotgraph(epochs, loss, val_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHjAY0CrggpN"
      },
      "source": [
        "plt.title('Model accuracy')\n",
        "plotgraph(epochs, acc, val_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhN0HHdPgjmk"
      },
      "source": [
        "# get best model index\n",
        "minimum_val_loss = np.min(history.history['val_loss'])\n",
        "best_model_index = np.where(history.history['val_loss'] == minimum_val_loss)[0][0]\n",
        "\n",
        "best_loss = str(history.history['loss'][best_model_index])\n",
        "best_acc = str(history.history['accuracy'][best_model_index])\n",
        "best_val_loss = str(history.history['val_loss'][best_model_index])\n",
        "best_val_acc = str(history.history['val_accuracy'][best_model_index])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPAGVF91gB6U"
      },
      "source": [
        "# Test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIPJ3W3w4BZ3"
      },
      "source": [
        "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nl2NMjXM4ls1"
      },
      "source": [
        "!pip install keras==2.3.1\n",
        "!pip install tensorflow==2.1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsCoPuEbmSdh"
      },
      "source": [
        "from keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_jyhC_PgfvH",
        "outputId": "eae031a4-3400-430c-f2e1-fc8a9c17de63"
      },
      "source": [
        "#model.load_weights(\"/content/drive/Shared drives/PolypDB/AWR_Test 7/models/Best custom with 32x128 aug latest.hdf5\")\n",
        "model.load_weights(\"/content/drive/Shared drives/PolypDB/AWR_Test 7/models/Best VGG19 with 64x256 aug latest one one.hdf5\")\n",
        "# train_data = ([X_train, y_train, train_input_length, train_label_length], [np.zeros(len(X_train))])\n",
        "# valid_data = ([X_val, y_val, valid_input_length, valid_label_length], [np.zeros(len(X_val))])\n",
        "test_data = ([X_test, y_test, test_input_length, test_label_length], [np.zeros(len(X_test))])\n",
        "# scores1 = model.evaluate(x=train_data[0], y=train_data[1], verbose=1)\n",
        "# scores2 = model.evaluate(x=valid_data[0], y=valid_data[1], verbose=1)\n",
        "# scores3 = model.evaluate(x=test_data[0], y=test_data[1], verbose=1)\n",
        "\n",
        "# scores1 = model.evaluate([X_train, y_train, train_input_length, train_label_length], [np.zeros(len(X_train))], verbose=1)\n",
        "# scores2 = model.evaluate([X_val, y_val, valid_input_length, valid_label_length],[np.zeros(len(X_val))], verbose=1)\n",
        "scores3 = model.evaluate([X_test, y_test, test_input_length, test_label_length], [np.zeros(len(X_test))], verbose=1)\n",
        "\n",
        "# print(\"Train Accuracy = {:.2%}\". format(scores1[1]))\n",
        "# print(\"Train Loss = \", scores1[0])\n",
        "\n",
        "# print(\"Validation Accuracy = {:.2%}\". format(scores2[1]))\n",
        "# print(\"Validation Loss = \", scores2[0])\n",
        "\n",
        "print(\"Test Accuracy = {:.2%}\". format(scores3[1]))\n",
        "print(\"Test Loss = \", scores3[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1200/1200 [==============================] - 4s 3ms/step\n",
            "Test Accuracy = 77.25%\n",
            "Test Loss =  1.298891305923462\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGRDSTbgn_Oe"
      },
      "source": [
        "#this part is used for re-training from saved model file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNI7nAB2y6HE"
      },
      "source": [
        "from keras.models import load_model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVGOPjPBzANA"
      },
      "source": [
        "\n",
        "loaded_model = load_model(\"/content/drive/Shared drives/PolypDB/AWR_Test 7/models/Best VGG19 with 64x256 aug latest one one.hdf5\",  custom_objects={'<lambda>': lambda y_true, y_pred: y_pred} )\n",
        "#loaded_model = load_model(\"/content/drive/Shared drives/PolypDB/AWR_Test 7/models/Best densenet with 32x128 aug latest.hdf5\",  custom_objects={'<lambda>': lambda y_true, y_pred: y_pred, 'Scale' : Scale} )\n",
        "#model.load_weights(\"/content/drive/Shared drives/PolypDB/AWR_Test 7/models/<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7fef08e74780>o-8486r-50e-9622t-1202v.hdf5\")\n",
        "#train_data = ([X_train, y_train, train_input_length, train_label_length], [np.zeros(len(X_train))])\n",
        "#valid_data = ([X_val, y_val, valid_input_length, valid_label_length], [np.zeros(len(X_val))])\n",
        "#test_data = ([X_test, y_test, test_input_length, test_label_length], [np.zeros(len(X_test))])\n",
        "# scores1 = model.evaluate(x=train_data[0], y=train_data[1], verbose=1)\n",
        "# scores2 = model.evaluate(x=valid_data[0], y=valid_data[1], verbose=1)\n",
        "# scores3 = model.evaluate(x=test_data[0], y=test_data[1], verbose=1)\n",
        "\n",
        "#scores1 = model.evaluate([X_train, y_train, train_input_length, train_label_length], [np.zeros(len(X_train))], verbose=1)\n",
        "#scores2 = model.evaluate([X_val, y_val, valid_input_length, valid_label_length],[np.zeros(len(X_val))], verbose=1)\n",
        "#scores3 = loaded_model.evaluate([X_test, y_test, test_input_length, test_label_length], [np.zeros(len(X_test))], verbose=1)\n",
        "\n",
        "# print(\"Train Accuracy = {:.2%}\". format(scores1[1]))\n",
        "# print(\"Train Loss = \", scores1[0])\n",
        "\n",
        "# print(\"Validation Accuracy = {:.2%}\". format(scores2[1]))\n",
        "# print(\"Validation Loss = \", scores2[0])\n",
        "\n",
        "#print(\"Test Accuracy = {:.2%}\". format(scores3[1]))\n",
        "#print(\"Test Loss = \", scores3[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJZM1EG5L1z7"
      },
      "source": [
        "filepath=\"/content/drive/Shared drives/PolypDB/AWR_Test 7/models/{}o-{}r-{}e-{}t-{}v.hdf5\".format(opt,\n",
        "                                                                        str(RECORDS_COUNT),\n",
        "                                                                        str(epochs),\n",
        "                                                                        str(X_train.shape[0]),\n",
        "                                                                       str(X_val.shape[0]))\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "callbacks_list = [checkpoint]\n",
        "#callbacks_list=[lr_callback]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EnWtW_77L7iZ",
        "outputId": "cb43556c-4f4b-40aa-d2c7-cbc3bb947490"
      },
      "source": [
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta = 0.1,\n",
        "    patience = 2)\n",
        "\n",
        "\n",
        "history = loaded_model.fit(x=[X_train, y_train, train_input_length, train_label_length],\n",
        "                    y=np.zeros(len(X_train)),\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=([X_val, y_val, valid_input_length, valid_label_length], [np.zeros(len(X_val))]),\n",
        "                    verbose=2,\n",
        "                    callbacks=callbacks_list\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 29224 samples, validate on 3248 samples\n",
            "Epoch 1/40\n",
            " - 686s - loss: 0.1624 - accuracy: 0.9927 - val_loss: 0.2623 - val_accuracy: 0.9698\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.26234, saving model to /content/drive/Shared drives/PolypDB/AWR_Test 7/models/<keras.optimizers.Adam object at 0x7f043cca7b50>o-8486r-40e-29224t-3248v.hdf5\n",
            "Epoch 2/40\n",
            " - 679s - loss: 0.1681 - accuracy: 0.9914 - val_loss: 0.2283 - val_accuracy: 0.9806\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.26234 to 0.22831, saving model to /content/drive/Shared drives/PolypDB/AWR_Test 7/models/<keras.optimizers.Adam object at 0x7f043cca7b50>o-8486r-40e-29224t-3248v.hdf5\n",
            "Epoch 3/40\n",
            " - 676s - loss: 0.1604 - accuracy: 0.9932 - val_loss: 0.2448 - val_accuracy: 0.9720\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.22831\n",
            "Epoch 4/40\n",
            " - 674s - loss: 0.1585 - accuracy: 0.9939 - val_loss: 0.2606 - val_accuracy: 0.9723\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.22831\n",
            "Epoch 5/40\n",
            " - 673s - loss: 0.1575 - accuracy: 0.9923 - val_loss: 0.2930 - val_accuracy: 0.9587\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.22831\n",
            "Epoch 6/40\n",
            " - 671s - loss: 0.1677 - accuracy: 0.9904 - val_loss: 0.2626 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.22831\n",
            "Epoch 7/40\n",
            " - 671s - loss: 0.1589 - accuracy: 0.9924 - val_loss: 0.2789 - val_accuracy: 0.9658\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.22831\n",
            "Epoch 8/40\n",
            " - 672s - loss: 0.1669 - accuracy: 0.9909 - val_loss: 0.3068 - val_accuracy: 0.9689\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.22831\n",
            "Epoch 9/40\n",
            " - 672s - loss: 0.1726 - accuracy: 0.9893 - val_loss: 0.2637 - val_accuracy: 0.9735\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.22831\n",
            "Epoch 10/40\n",
            " - 671s - loss: 0.1631 - accuracy: 0.9924 - val_loss: 0.2477 - val_accuracy: 0.9763\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.22831\n",
            "Epoch 11/40\n",
            " - 671s - loss: 0.1562 - accuracy: 0.9943 - val_loss: 0.2380 - val_accuracy: 0.9803\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.22831\n",
            "Epoch 12/40\n",
            " - 670s - loss: 0.1556 - accuracy: 0.9926 - val_loss: 0.2569 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.22831\n",
            "Epoch 13/40\n",
            " - 675s - loss: 0.1564 - accuracy: 0.9926 - val_loss: 0.2529 - val_accuracy: 0.9729\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.22831\n",
            "Epoch 14/40\n",
            " - 672s - loss: 0.1542 - accuracy: 0.9927 - val_loss: 0.2253 - val_accuracy: 0.9797\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.22831 to 0.22526, saving model to /content/drive/Shared drives/PolypDB/AWR_Test 7/models/<keras.optimizers.Adam object at 0x7f043cca7b50>o-8486r-40e-29224t-3248v.hdf5\n",
            "Epoch 15/40\n",
            " - 672s - loss: 0.1561 - accuracy: 0.9927 - val_loss: 0.2622 - val_accuracy: 0.9732\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.22526\n",
            "Epoch 16/40\n",
            " - 669s - loss: 0.1657 - accuracy: 0.9899 - val_loss: 0.2765 - val_accuracy: 0.9667\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.22526\n",
            "Epoch 17/40\n",
            " - 677s - loss: 0.1614 - accuracy: 0.9911 - val_loss: 0.2817 - val_accuracy: 0.9652\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.22526\n",
            "Epoch 18/40\n",
            " - 669s - loss: 0.1610 - accuracy: 0.9923 - val_loss: 0.2328 - val_accuracy: 0.9806\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.22526\n",
            "Epoch 19/40\n",
            " - 668s - loss: 0.1647 - accuracy: 0.9914 - val_loss: 0.2391 - val_accuracy: 0.9794\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.22526\n",
            "Epoch 20/40\n",
            " - 670s - loss: 0.1557 - accuracy: 0.9926 - val_loss: 0.2638 - val_accuracy: 0.9735\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.22526\n",
            "Epoch 21/40\n",
            " - 671s - loss: 0.1616 - accuracy: 0.9908 - val_loss: 0.2704 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.22526\n",
            "Epoch 22/40\n",
            " - 672s - loss: 0.1547 - accuracy: 0.9950 - val_loss: 0.3114 - val_accuracy: 0.9597\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.22526\n",
            "Epoch 23/40\n",
            " - 672s - loss: 0.1560 - accuracy: 0.9933 - val_loss: 0.2393 - val_accuracy: 0.9778\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.22526\n",
            "Epoch 24/40\n",
            " - 671s - loss: 0.1553 - accuracy: 0.9932 - val_loss: 0.2533 - val_accuracy: 0.9748\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.22526\n",
            "Epoch 25/40\n",
            " - 673s - loss: 0.1629 - accuracy: 0.9907 - val_loss: 0.2350 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.22526\n",
            "Epoch 26/40\n",
            " - 667s - loss: 0.1505 - accuracy: 0.9943 - val_loss: 0.2483 - val_accuracy: 0.9754\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.22526\n",
            "Epoch 27/40\n",
            " - 666s - loss: 0.1548 - accuracy: 0.9929 - val_loss: 0.2501 - val_accuracy: 0.9754\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.22526\n",
            "Epoch 28/40\n",
            " - 663s - loss: 0.1555 - accuracy: 0.9920 - val_loss: 0.2764 - val_accuracy: 0.9643\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.22526\n",
            "Epoch 29/40\n",
            " - 664s - loss: 0.1496 - accuracy: 0.9950 - val_loss: 0.2592 - val_accuracy: 0.9754\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.22526\n",
            "Epoch 30/40\n",
            " - 662s - loss: 0.1519 - accuracy: 0.9931 - val_loss: 0.2483 - val_accuracy: 0.9744\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.22526\n",
            "Epoch 31/40\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-865916bb39f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_input_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_label_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3733\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3735\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3736\u001b[0m         expand_composites=True)\n\u001b[1;32m   3737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3733\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3735\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3736\u001b[0m         expand_composites=True)\n\u001b[1;32m   3737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7fJePlXCvK9"
      },
      "source": [
        "# predict outputs on test images\n",
        "predictions = my_model.predict(X_test[1:100])\n",
        "# use CTC decoder\n",
        "decoded = K.ctc_decode(predictions,\n",
        "                       input_length=np.ones(predictions.shape[0]) * predictions.shape[1],\n",
        "                       greedy=True)[0][0]\n",
        "\n",
        "out = K.get_value(decoded)\n",
        "\n",
        "# see the results\n",
        "for i, x in enumerate(out):\n",
        "    print(\"original_text =  \", test_original_text[1+i])\n",
        "    print(\"predicted text = \", end = '')\n",
        "    for p in x:\n",
        "        if int(p) != -1:\n",
        "            print(char_list[int(p)], end = '')\n",
        "    plt.imshow(X_test[1+i].reshape(32,128), cmap=plt.cm.gray)\n",
        "    plt.show()\n",
        "    print('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF1MSgbxgp3i"
      },
      "source": [
        "Using Jaro Distance & Ratio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PjFQPPAgLg0"
      },
      "source": [
        "pip install python-Levenshtein"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW458wBif59E"
      },
      "source": [
        "# load the saved best model weights\n",
        "my_model.load_weights(filepath)\n",
        "\n",
        "# predict outputs on validation images\n",
        "# use CTC decoder\n",
        "decoded = K.ctc_decode(prediction,\n",
        "                       input_length=np.ones(prediction.shape[0]) * prediction.shape[1],\n",
        "                       greedy=True)[0][0]\n",
        "out = K.get_value(decoded)\n",
        "\n",
        "import Levenshtein as lv\n",
        "\n",
        "total_jaro = 0\n",
        "total_rati = 0\n",
        "# see the results\n",
        "for i, x in enumerate(out):\n",
        "    letters=''\n",
        "    for p in x:\n",
        "        if int(p) != -1:\n",
        "            letters+=char_list[int(p)]\n",
        "    total_jaro+=lv.jaro(letters, valid_original_text[i])\n",
        "    total_rati+=lv.ratio(letters, valid_original_text[i])\n",
        "\n",
        "print('jaro :', total_jaro/len(out))\n",
        "print('ratio:', total_rati/len(out))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFBPdIuBgu1E"
      },
      "source": [
        "# Save History"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxitf32mgnTt"
      },
      "source": [
        "#drive/My Drive/Colab Notebooks/Handwritten-Text-Recognition/\n",
        "with open('drive/My Drive/AWR_Test 7/history.txt', 'a') as f:\n",
        "    new_data = '{},{},{},{},{},{},{},{},{},{}\\n'.format(filepath,\n",
        "                                                      opt,\n",
        "                                                      str(RECORDS_COUNT),\n",
        "                                                      e,\n",
        "                                                      str(X_train.shape[0]),\n",
        "                                                      str(X_val.shape[0]),\n",
        "                                                      best_loss,\n",
        "                                                      best_acc,\n",
        "                                                      best_val_loss,\n",
        "                                                      best_val_acc)\n",
        "    f.write(new_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gI8AnHa-hPoi"
      },
      "source": [
        "# More Reports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2480wwrg_zv"
      },
      "source": [
        "def recognized(x):\n",
        "  s=''\n",
        "  for p in x:\n",
        "    if int(p) != 300:\n",
        "      if int(p) != -1:\n",
        "        s += char_list[int(p)] + ''\n",
        "  return s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4D9PCq4Zjo2x"
      },
      "source": [
        "def wer(r, h):\n",
        "    \"\"\"\n",
        "    Calculation of WER with Levenshtein distance.\n",
        "    Works only for iterables up to 254 elements (uint8).\n",
        "    O(nm) time ans space complexity.\n",
        "    Parameters\n",
        "    ----------\n",
        "    r : list\n",
        "    h : list\n",
        "    Returns\n",
        "    -------\n",
        "    int\n",
        "    Examples\n",
        "    --------\n",
        "    >>> wer(\"who is there\".split(), \"is there\".split())\n",
        "    1\n",
        "    >>> wer(\"who is there\".split(), \"\".split())\n",
        "    3\n",
        "    >>> wer(\"\".split(), \"who is there\".split())\n",
        "    3\n",
        "    \"\"\"\n",
        "    # initialisation\n",
        "    d = np.zeros((len(r)+1)*(len(h)+1), dtype=np.uint8)\n",
        "    d = d.reshape((len(r)+1, len(h)+1))\n",
        "    for i in range(len(r)+1):\n",
        "        for j in range(len(h)+1):\n",
        "            if i == 0:\n",
        "                d[0][j] = j\n",
        "            elif j == 0:\n",
        "                d[i][0] = i\n",
        "\n",
        "    # computation++++++\n",
        "    for i in range(1, len(r)+1):\n",
        "        for j in range(1, len(h)+1):\n",
        "            if r[i-1] == h[j-1]:\n",
        "                d[i][j] = d[i-1][j-1]\n",
        "            else:\n",
        "                substitution = d[i-1][j-1] + 1\n",
        "                insertion = d[i][j-1] + 1\n",
        "                deletion = d[i-1][j] + 1\n",
        "                d[i][j] = min(substitution, insertion, deletion)\n",
        "    return d[len(r)][len(h)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXZQaC-ziYO7"
      },
      "source": [
        "def jaro_and_ratio(letters, original_text):\n",
        "  \"\"\"In computer science and statistics,\n",
        "  the Jaro–Winkler distance is a string metric measuring an edit distance\n",
        "  between two sequences. It is a variant proposed in 1990 by William E. Winkler\n",
        "  of the Jaro distance metric (1989, Matthew A. Jaro).\"\"\"\n",
        "  total_jar = 0\n",
        "  total_rati = 0\n",
        "\n",
        "  for i in range(len(letters)):\n",
        "    total_jar+=lv.jaro(letters[i], original_text[i])\n",
        "    total_rati+=lv.ratio(letters[i], original_text[i])\n",
        "\n",
        "  jaro = total_jar/len(letters)\n",
        "  ratio = total_rati/len(letters)\n",
        "  print(len(letters))\n",
        "  return jaro, ratio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5nfd0JcxLBn"
      },
      "source": [
        "import time\n",
        "def validate(x, y):\n",
        "  \"\"\" Validate neural network \"\"\"\n",
        "  numCharErr = 0\n",
        "  numCharTotal = 0\n",
        "  numWordOK = 0\n",
        "  numWordTotal = 0\n",
        "\n",
        "  totalCER = []\n",
        "  totalWER = []\n",
        "\n",
        "  start_time_total = time.time()\n",
        "\n",
        "  x_pred = my_model.predict(x)\n",
        "  #x_pred = model.predict(x)\n",
        "  x_deco = K.ctc_decode(x_pred , input_length=np.ones(x_pred.shape[0])*x_pred.shape[1], greedy=True)[0][0]\n",
        "\n",
        "  elapsed_time_total = (time.time()-start_time_total)/60\n",
        "  print('\\n\\ntotal elapsed time =',elapsed_time_total,' minutes')\n",
        "\n",
        "  x_reco = K.get_value(x_deco)\n",
        "  x_reco_txt = []\n",
        "  y_orig_txt = []\n",
        "  for i, j in enumerate(x_reco):\n",
        "    try:\n",
        "      x_reco_txt.append(recognized(j))\n",
        "      y_orig_txt.append(recognized(y[i]))\n",
        "    except:\n",
        "      continue\n",
        "\n",
        "  print('Ground truth ~> Recognized')\n",
        "  for i in range(len(x_reco_txt)):\n",
        "      numWordOK += 1 if y_orig_txt[i] == x_reco_txt[i] else 0\n",
        "      numWordTotal += 1\n",
        "      dist = editdistance.eval(x_reco_txt[i], y_orig_txt[i])\n",
        "      ## editdistance\n",
        "      currCER = dist/max(len(x_reco_txt[i]), len(y_orig_txt[i]))\n",
        "      totalCER.append(currCER)\n",
        "\n",
        "      currWER = wer(x_reco_txt[i].split(), y_orig_txt[i].split())\n",
        "      totalWER.append(currWER)\n",
        "\n",
        "      numCharErr += dist\n",
        "      numCharTotal += len(y_orig_txt[i])\n",
        "      with open(\"/content/drive/Shared drives/PolypDB/AWR_Test 7/out.txt\", 'a') as f:\n",
        "        print('[OK]' if dist == 0 else '[ERR:%d]' % dist, '\"' +\n",
        "              y_orig_txt[i] + '\"', '~>', '\"' + x_reco_txt[i] + '\"',file=f)\n",
        "\n",
        "      #if dist != 0:\n",
        "          #print('[ERR:%d]' % dist, '\"' + y_orig_txt[i] + '\"', '~>', '\"' + x_reco_txt[i] + '\"')\n",
        "      with tf.device('/gpu:0'):\n",
        "            #plt.imshow(x[i].reshape(64,256), cmap=plt.cm.gray)\n",
        "            #plt.show()\n",
        "            plt.imsave(\"/content/drive/Shared drives/PolypDB/AWR_Test 7/Best VGG19 with 64x256 aug/\" + 'AHWR'+str(i)+\".jpg\",x[i].reshape(64,256) )\n",
        "            print('\\n')\n",
        "      #print('' if dist == 0 else '[ERR:%d]' % dist, '\"' + y_orig_txt[i] + '\"', '~>', '\"' + x_reco_txt[i] + '\"')\n",
        "      #print( if dist != 0 '[ERR:%d]' % dist )\n",
        "      #with tf.device('/gpu:0'):\n",
        "        #plt.imshow(x[i].reshape(32,128), cmap=plt.cm.gray)\n",
        "        #plt.show()\n",
        "        #print('\\n')\n",
        "\n",
        "  # Print validation result\n",
        "  charErrorRate = sum(totalCER)/len(totalCER)\n",
        "  addressAccuracy = numWordOK / numWordTotal\n",
        "  wordErrorRate = sum(totalWER)/len(totalWER)\n",
        "  jaro, ratio = jaro_and_ratio(x_reco_txt, y_orig_txt)\n",
        "  print('Character error rate: %f%%. Address accuracy: %f%%. Word error rate: %f%%' %\n",
        "        (charErrorRate*100.0, addressAccuracy*100.0, wordErrorRate*100.0))\n",
        "  print('jaro: %f%% and ratio: %f%%' % (jaro*100.0, ratio*100.0))\n",
        "\n",
        "  return charErrorRate, addressAccuracy, wordErrorRate, jaro, ratio\n",
        "\n",
        "import editdistance\n",
        "#import Levenshtein as lv\n",
        "\n",
        "# Validate\n",
        "#print('Validate neural network')\n",
        "#charErrorRate, addressAccuracy, wordErrorRate, jaro, ratio = validate(X_val, y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43EvvHcGPPfu"
      },
      "source": [
        "import Levenshtein as lv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbzyuuk4SySW"
      },
      "source": [
        "pip install python-Levenshtein"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MV01tWXXbuVz",
        "outputId": "36377214-b4a9-4695-ebf9-fce7c06d76cd"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print('Test neural network')\n",
        "charErrorRate, addressAccuracy, wordErrorRate, jaro, ratio  = validate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test neural network\n",
            "\n",
            "\n",
            "total elapsed time = 0.047035741806030276  minutes\n",
            "Ground truth ~> Recognized\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1200\n",
            "Character error rate: 5.421164%. Address accuracy: 81.750000%. Word error rate: 18.250000%\n",
            "jaro: 96.866446% and ratio: 95.311905%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WG4-8qElyOgL"
      },
      "source": [
        "  model.add(Convolution2D(filters=512, kernel_size = KERNEL_SIZE,\n",
        "                 #strides=1,\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv5'))\n",
        "  model.add(Activation('relu', name='activation5'))\n",
        "  model.add(Dropout(0.5))\n",
        "  # Batch normalization layer\n",
        "  model.add(BatchNormalization())\n",
        "\n",
        "  model.add(Convolution2D(filters=512, kernel_size = KERNEL_SIZE,\n",
        "                 #strides=1,\n",
        "                 use_bias=True,\n",
        "                 padding='same', kernel_regularizer=regularizers.l2(REG), name='conv6'))\n",
        "  model.add(Activation('relu', name='activation6'))\n",
        "\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 1), name='pool4'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odow3AOBRlLE"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPQw3IyBRl6K"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd01sPIGRmbC"
      },
      "source": [
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block as defined in Figure 3\n",
        "\n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "\n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "\n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    # Save the input value. You'll need this later to add back to the main path.\n",
        "    X_shortcut = X\n",
        "\n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "\n",
        "    # Second component of main path (≈3 lines)\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path (≈2 lines)\n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZhciui5Rn0h"
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = (2,1)):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block as defined in Figure 4\n",
        "\n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "\n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "\n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "\n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path\n",
        "    X = Conv2D(F1, (1, 1), strides = s, name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Second component of main path (≈3 lines)\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "\n",
        "    # Third component of main path (≈2 lines)\n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "\n",
        "    ##### SHORTCUT PATH #### (≈2 lines)\n",
        "    X_shortcut = Conv2D(filters = F3, kernel_size = (1, 1), strides = s, padding = 'valid', name = conv_name_base + '1',\n",
        "                        kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "\n",
        "    return X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ek6uBUHFS01B"
      },
      "source": [
        "def ResNet50s(input_shape=(64, 64, 3), classes=6):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = (2,1))\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    # output layer\n",
        "\n",
        "\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDy3mH8MTljp"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dropout,Bidirectional, RNN,Reshape,Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D,MaxPooling2D, GlobalMaxPooling2D,Concatenate,GlobalAveragePooling2D,Lambda, GRU\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop, Adamax, Adadelta, Adagrad\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
        "import pydot\n",
        "from IPython.display import SVG\n",
        "\n",
        "#from resnets_utils import *\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "import scipy.misc\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow.keras.backend as K\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBR6NUSVdeMw"
      },
      "source": [
        "from keras.initializers import glorot_uniform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxh6I14tS6yo"
      },
      "source": [
        "model = ResNet50s(input_shape = (32, 128, 1), classes = 6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dws7TJJzFtc"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wuCMlIDzF88"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHT-ZuYmzGKJ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-78F_NhYzIFX"
      },
      "source": [
        "#### DenseNet121 implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R59Z5Kc7zGUK"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "KZm3JxBQ1cb0",
        "outputId": "85155071-998d-4e9c-80bb-f789b0f5e442"
      },
      "source": [
        "densemodel=DenseNettry()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-7511e7b304cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdensemodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDenseNettry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-28-34c3a341c580>\u001b[0m in \u001b[0;36mDenseNettry\u001b[0;34m(nb_dense_block, growth_rate, nb_filter, reduction, dropout_rate, weight_decay, classes, weights_path)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mblock_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_dense_block\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mstage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_filter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdense_blocktry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblock_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_filter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrowth_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# Add transition_block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-34c3a341c580>\u001b[0m in \u001b[0;36mdense_blocktry\u001b[0;34m(x, stage, nb_layers, nb_filter, growth_rate, dropout_rate, weight_decay, grow_nb_filters)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mbranch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_blocktry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcat_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbranch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrowth_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mconcat_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConcatenate\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconcat_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'concat_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbranch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgrow_nb_filters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 952\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1091\u001b[0;31m             inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    860\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2708\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2709\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2710\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2711\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2712\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/merge.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    517\u001b[0m             shape[axis] for shape in shape_set if shape[axis] is not None)\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_dims\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_merge_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 56, 56, 64), (None, 19, 19, 32)]"
          ]
        }
      ]
    }
  ]
}